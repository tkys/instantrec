# InstantRec UIå®Ÿè£…æŠ€è¡“ä»•æ§˜æ›¸

## ğŸ“‹ æ¦‚è¦

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€æ”¹å–„ã•ã‚ŒãŸUIãƒ¢ãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ç¾åœ¨ã®å®Ÿè£…ã¸ã®ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã‚’æ”¯æ´ã™ã‚‹ãŸã‚ã®æŠ€è¡“ä»•æ§˜æ›¸ã§ã™ã€‚å„ç”»é¢ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ“ä½œã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã€å®Ÿè£…ã™ã¹ãSwiftUIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’è©³ç´°ã«èª¬æ˜ã—ã¾ã™ã€‚

---

## ğŸ¯ Screen 1: Recording Screen (éŒ²éŸ³ç”»é¢)

### UI Elements & Actions

#### 1. **ãƒ¡ã‚¤ãƒ³ã‚¿ãƒƒãƒ—ã‚¨ãƒªã‚¢** (ç”»é¢å…¨ä½“)
```swift
// UI Component
struct RecordingTapArea: View {
    @EnvironmentObject var viewModel: RecordingViewModel
    
    var body: some View {
        Rectangle()
            .fill(Color.clear)
            .contentShape(Rectangle())
            .onTapGesture {
                handleRecordingTap()
            }
    }
}

// Action
func handleRecordingTap() {
    if viewModel.isRecording {
        stopRecording()
    } else {
        startRecording()
    }
}
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
- `AudioService.startRecording()` å‘¼ã³å‡ºã—
- `AVAudioSession` ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³
- ãƒã‚¤ã‚¯æ¨©é™ãƒã‚§ãƒƒã‚¯
- ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹ (`Timer.scheduledTimer`)
- éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–é–‹å§‹

#### 2. **éŒ²éŸ³ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼** (èµ¤ã„ç‚¹æ»…ãƒ‰ãƒƒãƒˆ)
```swift
// UI Component
struct RecordingIndicator: View {
    @State private var isAnimating = false
    
    var body: some View {
        Circle()
            .fill(Color.red)
            .frame(width: 24, height: 24)
            .opacity(isAnimating ? 1.0 : 0.7)
            .scaleEffect(isAnimating ? 1.05 : 1.0)
            .animation(.easeInOut(duration: 1.0).repeatForever(), value: isAnimating)
            .onAppear { isAnimating = true }
    }
}
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
- UIã®çŠ¶æ…‹æ›´æ–°ã®ã¿
- ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡

#### 3. **ã‚¿ã‚¤ãƒãƒ¼è¡¨ç¤º** (MM:SS)
```swift
// UI Component
struct RecordingTimer: View {
    @State private var elapsedTime: TimeInterval = 0
    @State private var timer: Timer?
    
    var body: some View {
        Text(formatTime(elapsedTime))
            .font(.system(size: 60, weight: .bold, design: .monospaced))
            .foregroundColor(.red)
    }
}

// Background Function
func startTimer() {
    timer = Timer.scheduledTimer(withTimeInterval: 1.0, repeats: true) { _ in
        elapsedTime += 1
    }
}
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
- 1ç§’é–“éš”ã§ã®ã‚¿ã‚¤ãƒãƒ¼æ›´æ–°
- UIçŠ¶æ…‹ã®åŒæœŸ

#### 4. **éŸ³å£°ãƒ¬ãƒ™ãƒ«ãƒ¡ãƒ¼ã‚¿ãƒ¼** (15æœ¬ãƒãƒ¼)
```swift
// UI Component
struct AudioLevelMeter: View {
    @EnvironmentObject var audioService: AudioService
    @State private var levels: [Float] = Array(repeating: 0.0, count: 15)
    
    var body: some View {
        HStack(spacing: 2) {
            ForEach(0..<15, id: \.self) { index in
                RoundedRectangle(cornerRadius: 2)
                    .fill(getBarColor(for: index))
                    .frame(width: 12)
                    .frame(height: getBarHeight(for: index))
                    .animation(.easeInOut(duration: 0.1), value: levels[index])
            }
        }
    }
}

// Background Functions
class AudioLevelMonitor: ObservableObject {
    @Published var currentLevel: Float = 0.0
    private var audioRecorder: AVAudioRecorder?
    private var levelTimer: Timer?
    
    func startMonitoring() {
        levelTimer = Timer.scheduledTimer(withTimeInterval: 0.05, repeats: true) { _ in
            self.audioRecorder?.updateMeters()
            let power = self.audioRecorder?.averagePower(forChannel: 0) ?? -160.0
            let normalizedLevel = self.normalizeAudioLevel(power)
            
            DispatchQueue.main.async {
                self.currentLevel = normalizedLevel
            }
        }
    }
    
    private func normalizeAudioLevel(_ power: Float) -> Float {
        // -160dB to 0dB ã‚’ 0.0 to 1.0 ã«æ­£è¦åŒ–
        let minDb: Float = -60.0
        let maxDb: Float = 0.0
        
        if power < minDb {
            return 0.0
        } else if power >= maxDb {
            return 1.0
        } else {
            return (power - minDb) / (maxDb - minDb)
        }
    }
}
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
- 50msé–“éš”ã§ã®éŸ³å£°ãƒ¬ãƒ™ãƒ«å–å¾—
- `AVAudioRecorder.updateMeters()` å‘¼ã³å‡ºã—
- dBãƒ¬ãƒ™ãƒ«ã®æ­£è¦åŒ–å‡¦ç†
- UIæ›´æ–°ã®ãŸã‚ã®çŠ¶æ…‹é…ä¿¡

#### 5. **åœæ­¢ãƒœã‚¿ãƒ³** (éŒ²éŸ³ä¸­ã®ã¿è¡¨ç¤º)
```swift
// UI Component
struct StopButton: View {
    let action: () -> Void
    
    var body: some View {
        Button(action: action) {
            HStack {
                Image(systemName: "stop.fill")
                Text("Stop Recording")
            }
            .font(.headline)
            .foregroundColor(.white)
            .padding(.horizontal, 48)
            .padding(.vertical, 16)
            .background(Color.red)
            .cornerRadius(25)
            .shadow(radius: 4)
        }
    }
}

// Action
func stopRecording() {
    audioService.stopRecording()
    viewModel.isRecording = false
    stopTimer()
    stopAudioLevelMonitoring()
}
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
- éŒ²éŸ³åœæ­¢å‡¦ç†
- ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†å¾…æ©Ÿ
- UIçŠ¶æ…‹ã®ãƒªã‚»ãƒƒãƒˆ
- ã‚¿ã‚¤ãƒãƒ¼ãƒ»ç›£è¦–ã®åœæ­¢

---

## ğŸ“ Screen 2: Recordings List (éŒ²éŸ³ä¸€è¦§ç”»é¢)

### UI Elements & Actions

#### 1. **Edit ãƒœã‚¿ãƒ³** (ãƒ˜ãƒƒãƒ€ãƒ¼å³ä¸Š)
```swift
// UI Component
struct EditButton: View {
    @Binding var editMode: EditMode
    
    var body: some View {
        Button(editMode == .active ? "Done" : "Edit") {
            withAnimation {
                editMode = editMode == .active ? .inactive : .active
            }
        }
    }
}

// State Management
@State private var editMode: EditMode = .inactive
@State private var selectedRecordings: Set<Recording.ID> = []
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
- EditModeçŠ¶æ…‹ã®åˆ‡ã‚Šæ›¿ãˆ
- é¸æŠçŠ¶æ…‹ã®åˆæœŸåŒ–
- UIè¦ç´ ã®è¡¨ç¤º/éè¡¨ç¤ºåˆ¶å¾¡

#### 2. **Quick Record ãƒœã‚¿ãƒ³**
```swift
// UI Component
struct QuickRecordButton: View {
    @EnvironmentObject var tabSelection: TabSelection
    
    var body: some View {
        Button(action: startQuickRecording) {
            HStack {
                Image(systemName: "mic.fill")
                Text("Quick Record")
            }
            .frame(maxWidth: .infinity)
            .padding()
            .background(Color.red)
            .foregroundColor(.white)
            .cornerRadius(12)
        }
    }
}

// Action
func startQuickRecording() {
    tabSelection.selectedTab = .recording
    
    // å°‘ã—é…å»¶ã—ã¦éŒ²éŸ³é–‹å§‹
    DispatchQueue.main.asyncAfter(deadline: .now() + 0.3) {
        recordingViewModel.startRecording()
    }
}
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
- ã‚¿ãƒ–åˆ‡ã‚Šæ›¿ãˆ
- éŒ²éŸ³ViewModel ã®çŠ¶æ…‹æ›´æ–°
- é…å»¶å®Ÿè¡Œã§ã®éŒ²éŸ³é–‹å§‹

#### 3. **éŒ²éŸ³ã‚«ãƒ¼ãƒ‰** (å€‹åˆ¥éŒ²éŸ³ã‚¢ã‚¤ãƒ†ãƒ )
```swift
// UI Component
struct RecordingCard: View {
    let recording: Recording
    @Binding var selectedRecordings: Set<Recording.ID>
    @EnvironmentObject var playbackManager: PlaybackManager
    @State private var isExpanded = false
    
    var body: some View {
        VStack(alignment: .leading, spacing: 12) {
            // Header
            HStack {
                VStack(alignment: .leading) {
                    Text(recording.displayName)
                        .font(.headline)
                    Text(recording.relativeTimeString)
                        .font(.caption)
                        .foregroundColor(.secondary)
                }
                
                Spacer()
                
                // Status Icons
                HStack(spacing: 12) {
                    SyncStatusIcon(status: recording.syncStatus)
                    TranscriptionStatusIcon(hasTranscription: recording.transcription != nil)
                    FavoriteButton(recording: recording)
                }
            }
            
            // Playback Controls
            PlaybackControls(recording: recording)
            
            // Transcription (Collapsible)
            if let transcription = recording.transcription {
                TranscriptionSection(transcription: transcription, isExpanded: $isExpanded)
            }
        }
        .padding()
        .background(Color(.systemGray6))
        .cornerRadius(12)
    }
}

// Supporting Components
struct SyncStatusIcon: View {
    let status: CloudSyncStatus
    
    var body: some View {
        switch status {
        case .uploading:
            Image(systemName: "cloud.arrow.up")
                .foregroundColor(.blue)
        case .synced:
            Image(systemName: "checkmark.circle")
                .foregroundColor(.green)
        case .failed:
            Image(systemName: "exclamationmark.triangle")
                .foregroundColor(.red)
        case .pending:
            Image(systemName: "clock")
                .foregroundColor(.orange)
        }
    }
}

struct TranscriptionStatusIcon: View {
    let hasTranscription: Bool
    
    var body: some View {
        if hasTranscription {
            Image(systemName: "text.bubble")
                .foregroundColor(.purple)
        }
    }
}
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
- éŒ²éŸ³ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
- åŒæœŸçŠ¶æ³ã®ç›£è¦–
- PlaybackManager ã¨ã®é€£æº

#### 4. **å†ç”Ÿã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«**
```swift
// UI Component
struct PlaybackControls: View {
    let recording: Recording
    @EnvironmentObject var playbackManager: PlaybackManager
    
    var body: some View {
        HStack(spacing: 12) {
            // Play/Pause Button
            Button(action: togglePlayback) {
                Image(systemName: isCurrentlyPlaying ? "pause.fill" : "play.fill")
                    .foregroundColor(.blue)
            }
            
            // Progress Bar
            ProgressView(value: playbackProgress, total: 1.0)
                .progressViewStyle(LinearProgressViewStyle(tint: .blue))
            
            // Time Display
            Text("\(currentTimeString) / \(totalTimeString)")
                .font(.caption)
                .foregroundColor(.secondary)
        }
    }
}

// Actions
func togglePlayback() {
    if playbackManager.currentRecording?.id == recording.id {
        playbackManager.togglePlayPause()
    } else {
        playbackManager.play(recording: recording)
    }
}
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
```swift
class PlaybackManager: ObservableObject {
    @Published var currentRecording: Recording?
    @Published var isPlaying = false
    @Published var currentTime: TimeInterval = 0
    @Published var duration: TimeInterval = 0
    
    private var audioPlayer: AVAudioPlayer?
    private var progressTimer: Timer?
    
    func play(recording: Recording) {
        // ä»–ã®å†ç”Ÿã‚’åœæ­¢
        stopCurrentPlayback()
        
        do {
            audioPlayer = try AVAudioPlayer(contentsOf: recording.fileURL)
            audioPlayer?.delegate = self
            currentRecording = recording
            duration = audioPlayer?.duration ?? 0
            
            audioPlayer?.play()
            isPlaying = true
            startProgressTimer()
        } catch {
            print("Playback error: \(error)")
        }
    }
    
    private func startProgressTimer() {
        progressTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
            self.currentTime = self.audioPlayer?.currentTime ?? 0
        }
    }
}
```

#### 5. **æ–‡å­—èµ·ã“ã—ã‚»ã‚¯ã‚·ãƒ§ãƒ³** (æŠ˜ã‚ŠãŸãŸã¿å¼)
```swift
// UI Component
struct TranscriptionSection: View {
    let transcription: String
    @Binding var isExpanded: Bool
    
    var body: some View {
        DisclosureGroup(
            isExpanded: $isExpanded,
            content: {
                Text(transcription)
                    .font(.caption)
                    .foregroundColor(.secondary)
                    .padding(.top, 8)
                    .textSelection(.enabled) // iOS 15+
            },
            label: {
                HStack {
                    Image(systemName: "doc.text")
                    Text("Transcription")
                    Spacer()
                }
                .font(.caption)
                .foregroundColor(.primary)
            }
        )
    }
}
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
- ãƒ†ã‚­ã‚¹ãƒˆé¸æŠãƒ»ã‚³ãƒ”ãƒ¼æ©Ÿèƒ½
- çŠ¶æ…‹ä¿å­˜ï¼ˆå±•é–‹/æŠ˜ã‚ŠãŸãŸã¿ï¼‰

#### 6. **ãŠæ°—ã«å…¥ã‚Šãƒœã‚¿ãƒ³**
```swift
// UI Component
struct FavoriteButton: View {
    let recording: Recording
    @Environment(\.modelContext) private var modelContext
    
    var body: some View {
        Button(action: toggleFavorite) {
            Image(systemName: recording.isFavorite ? "star.fill" : "star")
                .foregroundColor(recording.isFavorite ? .yellow : .gray)
        }
    }
}

// Action
func toggleFavorite() {
    recording.isFavorite.toggle()
    
    do {
        try modelContext.save()
    } catch {
        print("Failed to save favorite status: \(error)")
    }
}
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
- SwiftData ãƒ¢ãƒ‡ãƒ«ã®æ›´æ–°
- æ°¸ç¶šåŒ–å‡¦ç†
- UIçŠ¶æ…‹ã®å³åº§åæ˜ 

#### 7. **å‰Šé™¤æ“ä½œ** (ã‚¹ãƒ¯ã‚¤ãƒ—å‰Šé™¤)
```swift
// List Implementation
List {
    ForEach(recordings) { recording in
        RecordingCard(recording: recording)
    }
    .onDelete(perform: deleteRecordings)
}

// Action
func deleteRecordings(offsets: IndexSet) {
    withAnimation {
        for index in offsets {
            let recording = recordings[index]
            
            // ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
            deleteRecordingFile(recording)
            
            // ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å‰Šé™¤
            modelContext.delete(recording)
        }
        
        // ä¿å­˜
        try? modelContext.save()
    }
}
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
```swift
func deleteRecordingFile(_ recording: Recording) {
    do {
        try FileManager.default.removeItem(at: recording.fileURL)
        print("âœ… File deleted: \(recording.fileName)")
    } catch {
        print("âŒ Failed to delete file: \(error)")
    }
}
```

---

## âš™ï¸ Screen 3: Settings (è¨­å®šç”»é¢)

### UI Elements & Actions

#### 1. **é–‹å§‹ãƒ¢ãƒ¼ãƒ‰é¸æŠ** (Recording Behavior)
```swift
// UI Component
struct StartModeSelector: View {
    @StateObject private var settings = RecordingSettings.shared
    
    var body: some View {
        NavigationLink(destination: StartModeSelectionView()) {
            HStack {
                Text("Start Mode")
                Spacer()
                Text(settings.recordingStartMode.displayName)
                    .foregroundColor(.secondary)
                Image(systemName: "chevron.right")
                    .font(.caption)
                    .foregroundColor(.secondary)
            }
        }
    }
}

// Selection View
struct StartModeSelectionView: View {
    @StateObject private var settings = RecordingSettings.shared
    
    var body: some View {
        List(RecordingStartMode.allCases, id: \.self) { mode in
            Button(action: { selectMode(mode) }) {
                HStack {
                    VStack(alignment: .leading) {
                        Text(mode.displayName)
                            .foregroundColor(.primary)
                        Text(mode.description)
                            .font(.caption)
                            .foregroundColor(.secondary)
                    }
                    Spacer()
                    if settings.recordingStartMode == mode {
                        Image(systemName: "checkmark")
                            .foregroundColor(.blue)
                    }
                }
            }
        }
        .navigationTitle("Start Mode")
    }
}
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
```swift
func selectMode(_ mode: RecordingStartMode) {
    settings.recordingStartMode = mode
    settings.saveSettings()
    
    // ViewModelã«å¤‰æ›´ã‚’é€šçŸ¥
    NotificationCenter.default.post(
        name: .recordingSettingsChanged,
        object: nil
    )
}
```

#### 2. **éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰é¸æŠ** (Recording Behavior)
```swift
// UI Component
struct RecordingModeSelector: View {
    @StateObject private var settings = RecordingSettings.shared
    
    var body: some View {
        NavigationLink(destination: RecordingModeSelectionView()) {
            HStack {
                Text("Recording Mode")
                Spacer()
                Text(getCurrentModeDisplayName())
                    .foregroundColor(.secondary)
                Image(systemName: "chevron.right")
                    .font(.caption)
                    .foregroundColor(.secondary)
            }
        }
    }
}
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
```swift
enum RecordingMode: String, CaseIterable {
    case balance, conversation, narration, ambient, meeting
    
    var displayName: String {
        switch self {
        case .balance: return "Balance"
        case .conversation: return "Conversation"
        case .narration: return "Narration"
        case .ambient: return "Ambient"
        case .meeting: return "Meeting"
        }
    }
    
    var description: String {
        switch self {
        case .balance: return "Versatile mode for all situations"
        case .conversation: return "Makes human voices clearer"
        case .narration: return "High quality with minimal noise"
        case .ambient: return "Records all sounds faithfully"
        case .meeting: return "Optimized for multiple speakers"
        }
    }
}

func applyRecordingMode(_ mode: RecordingMode) {
    // AudioServiceã«è¨­å®šã‚’é©ç”¨
    audioService.setRecordingMode(mode)
    
    // è¨­å®šä¿å­˜
    settings.recordingMode = mode
    settings.saveSettings()
}
```

#### 3. **ãƒã‚¤ã‚ºãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³è¨­å®š** (Audio & AI)
```swift
// UI Component
struct NoiseReductionSelector: View {
    @StateObject private var settings = RecordingSettings.shared
    
    var body: some View {
        NavigationLink(destination: NoiseReductionSelectionView()) {
            HStack {
                Text("Noise Reduction")
                Spacer()
                Text(settings.noiseReductionLevel.displayName)
                    .foregroundColor(.secondary)
                Image(systemName: "chevron.right")
            }
        }
    }
}
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
```swift
enum NoiseReductionLevel: String, CaseIterable {
    case off, low, medium, high
    
    var displayName: String {
        switch self {
        case .off: return "Off"
        case .low: return "Low"
        case .medium: return "Medium"
        case .high: return "High"
        }
    }
}

func applyNoiseReduction(_ level: NoiseReductionLevel) {
    audioProcessingService.setNoiseReductionLevel(level)
    settings.noiseReductionLevel = level
    settings.saveSettings()
}
```

#### 4. **è‡ªå‹•æ–‡å­—èµ·ã“ã—ãƒˆã‚°ãƒ«** (Audio & AI)
```swift
// UI Component
struct AutoTranscriptionToggle: View {
    @StateObject private var settings = RecordingSettings.shared
    
    var body: some View {
        Toggle("Auto Transcription", isOn: $settings.autoTranscriptionEnabled)
            .onChange(of: settings.autoTranscriptionEnabled) { enabled in
                handleAutoTranscriptionChange(enabled)
            }
    }
}

// Dependent AI Model Setting
struct AIModelSelector: View {
    @StateObject private var settings = RecordingSettings.shared
    
    var body: some View {
        if settings.autoTranscriptionEnabled {
            NavigationLink(destination: AIModelSelectionView()) {
                HStack {
                    Text("AI Model")
                    Spacer()
                    Text(settings.whisperModel.displayName)
                        .foregroundColor(.secondary)
                    Image(systemName: "chevron.right")
                }
            }
        }
    }
}
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
```swift
func handleAutoTranscriptionChange(_ enabled: Bool) {
    settings.autoTranscriptionEnabled = enabled
    settings.saveSettings()
    
    if enabled {
        // WhisperKitã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–
        transcriptionService.initializeWhisperKit(model: settings.whisperModel)
    } else {
        // ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
        transcriptionService.deinitialize()
    }
}

// éŒ²éŸ³å®Œäº†æ™‚ã®è‡ªå‹•æ–‡å­—èµ·ã“ã—å‡¦ç†
func handleRecordingCompleted(_ recording: Recording) {
    if settings.autoTranscriptionEnabled {
        Task {
            do {
                let transcription = try await transcriptionService.transcribe(
                    audioURL: recording.fileURL,
                    model: settings.whisperModel
                )
                
                // çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                await MainActor.run {
                    recording.transcription = transcription
                    try? modelContext.save()
                }
            } catch {
                print("Auto transcription failed: \(error)")
            }
        }
    }
}
```

#### 5. **Google Drive é€£æº** (Cloud & Sync)
```swift
// UI Component
struct GoogleDriveSection: View {
    @StateObject private var driveService = GoogleDriveService.shared
    @StateObject private var settings = RecordingSettings.shared
    
    var body: some View {
        VStack(alignment: .leading, spacing: 0) {
            HStack {
                VStack(alignment: .leading) {
                    Text("Google Drive")
                    if let email = driveService.signedInUserEmail {
                        Text(email)
                            .font(.caption)
                            .foregroundColor(.secondary)
                    }
                }
                Spacer()
                Button(driveService.isSignedIn ? "Sign Out" : "Sign In") {
                    handleGoogleDriveAuth()
                }
                .foregroundColor(.blue)
            }
            
            if driveService.isSignedIn {
                Toggle("Automatic Backup", isOn: $settings.autoBackupEnabled)
                    .onChange(of: settings.autoBackupEnabled) { enabled in
                        handleAutoBackupChange(enabled)
                    }
            }
        }
    }
}
```

**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†:**
```swift
func handleGoogleDriveAuth() {
    if driveService.isSignedIn {
        // ã‚µã‚¤ãƒ³ã‚¢ã‚¦ãƒˆ
        driveService.signOut()
        settings.autoBackupEnabled = false
    } else {
        // ã‚µã‚¤ãƒ³ã‚¤ãƒ³
        Task {
            do {
                try await driveService.signIn()
                
                // ã‚µã‚¤ãƒ³ã‚¤ãƒ³æˆåŠŸæ™‚
                await MainActor.run {
                    settings.autoBackupEnabled = true
                }
            } catch {
                print("Sign in failed: \(error)")
            }
        }
    }
}

func handleAutoBackupChange(_ enabled: Bool) {
    settings.autoBackupEnabled = enabled
    settings.saveSettings()
    
    if enabled {
        // æœªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        uploadQueue.processQueue()
    }
}

// éŒ²éŸ³å®Œäº†æ™‚ã®è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
func handleRecordingForBackup(_ recording: Recording) {
    if settings.autoBackupEnabled && driveService.isSignedIn {
        uploadQueue.enqueue(recording)
    }
}
```

---

## ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ & çŠ¶æ…‹ç®¡ç†

### 1. **ä¸­å¤®çŠ¶æ…‹ç®¡ç†**
```swift
// Global State Manager
class AppStateManager: ObservableObject {
    @Published var currentTab: Tab = .recording
    @Published var isRecording = false
    @Published var currentRecording: Recording?
    
    // Singletons
    let audioService = AudioService.shared
    let playbackManager = PlaybackManager.shared
    let transcriptionService = WhisperKitTranscriptionService.shared
    let driveService = GoogleDriveService.shared
    let settings = RecordingSettings.shared
}

// App Entry Point
@main
struct InstantRecApp: App {
    let modelContainer: ModelContainer
    @StateObject private var appState = AppStateManager()
    
    var body: some Scene {
        WindowGroup {
            ContentView()
                .environmentObject(appState)
                .modelContainer(modelContainer)
        }
    }
}
```

### 2. **ã‚¿ãƒ–ãƒ™ãƒ¼ã‚¹ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³**
```swift
// Main Content View
struct ContentView: View {
    @EnvironmentObject var appState: AppStateManager
    
    var body: some View {
        TabView(selection: $appState.currentTab) {
            RecordingView()
                .tabItem {
                    Image(systemName: "mic")
                    Text("Record")
                }
                .tag(Tab.recording)
            
            RecordingListView()
                .tabItem {
                    Image(systemName: "list.bullet")
                    Text("List")
                }
                .tag(Tab.list)
            
            SettingsView()
                .tabItem {
                    Image(systemName: "gear")
                    Text("Settings")
                }
                .tag(Tab.settings)
        }
    }
}

enum Tab: String, CaseIterable {
    case recording, list, settings
}
```

### 3. **éŒ²éŸ³ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†**
```swift
class RecordingLifecycleManager: ObservableObject {
    @Published var currentState: RecordingState = .idle
    
    enum RecordingState {
        case idle
        case preparing
        case recording
        case stopping
        case processing
        case completed
        case failed(Error)
    }
    
    func startRecording() async {
        currentState = .preparing
        
        do {
            // 1. æ¨©é™ãƒã‚§ãƒƒã‚¯
            guard await checkMicrophonePermission() else {
                throw RecordingError.permissionDenied
            }
            
            // 2. ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®š
            try setupAudioSession()
            
            // 3. éŒ²éŸ³é–‹å§‹
            let recordingURL = try audioService.startRecording()
            
            // 4. æ–°ã—ã„ Recording ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ä½œæˆ
            let recording = Recording(fileURL: recordingURL)
            try modelContext.insert(recording)
            
            currentState = .recording
            
        } catch {
            currentState = .failed(error)
        }
    }
    
    func stopRecording() async {
        currentState = .stopping
        
        guard let recording = getCurrentRecording() else { return }
        
        do {
            // 1. éŒ²éŸ³åœæ­¢
            try audioService.stopRecording()
            
            // 2. ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
            try validateRecordingFile(recording.fileURL)
            
            // 3. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
            recording.updateDuration()
            recording.updateFileSize()
            
            currentState = .processing
            
            // 4. å¾Œå‡¦ç†ï¼ˆéåŒæœŸï¼‰
            Task {
                await performPostProcessing(recording)
                
                await MainActor.run {
                    currentState = .completed
                }
            }
            
        } catch {
            currentState = .failed(error)
        }
    }
    
    private func performPostProcessing(_ recording: Recording) async {
        // æ–‡å­—èµ·ã“ã—å‡¦ç†
        if settings.autoTranscriptionEnabled {
            await performTranscription(recording)
        }
        
        // ã‚¯ãƒ©ã‚¦ãƒ‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        if settings.autoBackupEnabled {
            await performBackup(recording)
        }
    }
}
```

---

## ğŸ› ï¸ ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°è¨ˆç”»

### Phase 1: ã‚¿ãƒ–ãƒ™ãƒ¼ã‚¹ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³å°å…¥
1. `NavigationStack` ã‹ã‚‰ `TabView` ã¸ã®ç§»è¡Œ
2. ç¾åœ¨ã®ç”»é¢é·ç§»ãƒ­ã‚¸ãƒƒã‚¯ã®é™¤å»
3. ã‚¿ãƒ–é–“ã®çŠ¶æ…‹å…±æœ‰å®Ÿè£…

### Phase 2: éŒ²éŸ³ç”»é¢ã®ç°¡ç´ åŒ–
1. RecordingModeãƒœã‚¿ãƒ³ã®é™¤å»
2. éŸ³å£°ãƒ¬ãƒ™ãƒ«ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®æ”¹å–„
3. ã‚¿ãƒƒãƒ—ã‚¨ãƒªã‚¢ã®æ‹¡å¤§

### Phase 3: éŒ²éŸ³ä¸€è¦§ã®æ©Ÿèƒ½å¼·åŒ–
1. ã‚«ãƒ¼ãƒ‰å‹ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®å®Ÿè£…
2. æ–‡å­—èµ·ã“ã—æŠ˜ã‚ŠãŸãŸã¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ 
3. Editæ©Ÿèƒ½ã®å®Ÿè£…

### Phase 4: è¨­å®šç”»é¢ã®å†æ§‹æˆ
1. ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸã‚»ã‚¯ã‚·ãƒ§ãƒ³
2. Progressive Disclosure ã®å®Ÿè£…
3. RecordingModeã®ç§»å‹•

### Phase 5: ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ã®æœ€é©åŒ–
1. è‡ªå‹•æ–‡å­—èµ·ã“ã—å‡¦ç†ã®çµ±åˆ
2. çŠ¶æ…‹ç®¡ç†ã®ä¸€å…ƒåŒ–
3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å¼·åŒ–

ã“ã®ä»•æ§˜æ›¸ã«ã‚ˆã‚Šã€ç¾åœ¨ã®å®Ÿè£…ã‹ã‚‰æ”¹å–„ã•ã‚ŒãŸUIã¸ã®æ®µéšçš„ãªãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚