import Foundation
import WhisperKit
import AVFoundation
import CoreMedia

/// WhisperKit ãƒ¢ãƒ‡ãƒ«é¸æŠåˆ—æŒ™å‹ï¼ˆä¸Šä½3ã¤ã®ã¿ï¼‰
enum WhisperKitModel: String, CaseIterable, Identifiable {
    var id: String { rawValue}
    
    // ä¸Šä½3ã¤ã®æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ï¼ˆå¤§â†’ä¸­â†’å°ã®é †ï¼‰
    case large = "large-v3"
    case medium = "medium"
    case small = "small"
    
    var displayName: String {
        switch self {
        case .medium: return "ãƒãƒ©ãƒ³ã‚¹ (1GB) - é«˜å“è³ª"
        case .small: return "æ¨™æº– (500MB) - æ¨å¥¨"
        case .large: return "é«˜ç²¾åº¦ (1.5GB) - æœ€é«˜å“è³ª"
       }
   }
    
    var description: String {
        switch self {
        case .medium: return "é«˜å“è³ªãªéŸ³å£°èªè­˜ã€ãƒ“ã‚¸ãƒã‚¹åˆ©ç”¨ã«æœ€é©"
        case .small: return "ç²¾åº¦ã¨é€Ÿåº¦ã®æœ€é©ãƒãƒ©ãƒ³ã‚¹ã€æ—¥å¸¸ä½¿ç”¨ã«æœ€é©"
        case .large: return "æœ€é«˜ç²¾åº¦ã€å°‚é–€ç”¨é€”ãƒ»é‡è¦ãªä¼šè­°å‘ã‘"
       }
   }
    
    var isRecommended: Bool {
        return true // å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ãŒæ¨å¥¨ï¼ˆä¸Šä½3ã¤ã®ã¿ãªã®ã§ï¼‰
   }
    
    var estimatedSize: String {
        switch self {
        case .medium: return "1GB"
        case .small: return "500MB"
        case .large: return "1.5GB"
       }
   }
    
    static var recommendedModels: [WhisperKitModel] {
        return allCases // å…¨ã¦ãŒæ¨å¥¨ãƒ¢ãƒ‡ãƒ«
   }
}

/// WhisperKitã‚’ä½¿ç”¨ã—ãŸé«˜ç²¾åº¦æ–‡å­—èµ·ã“ã—ã‚µãƒ¼ãƒ“ã‚¹
/// Apple Speech Frameworkã«ä»£ã‚ã‚‹ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ»é«˜ç²¾åº¦ãªéŸ³å£°èªè­˜å®Ÿè£…
class WhisperKitTranscriptionService: ObservableObject {
    
    // MARK: - Published Properties
    
    /// æ–‡å­—èµ·ã“ã—çµæœ
    @Published var transcriptionText: String = ""
    
    /// å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°
    @Published var isTranscribing: Bool = false
    
    /// ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    @Published var errorMessage: String?
    
    /// å‡¦ç†æ™‚é–“ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    @Published var processingTime: TimeInterval = 0.0
    
    /// åˆæœŸåŒ–çŠ¶æ…‹
    @Published var isInitialized: Bool = false
    
    /// ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆsmallã‚’æ¨å¥¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«å¾©å…ƒï¼‰
    @Published var selectedModel: WhisperKitModel = .small
    
    /// ä½¿ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ï¼ˆä¸Šä½3ã¤ã®ã¿ï¼‰
    @Published var availableModels: [WhisperKitModel] = WhisperKitModel.allCases
    
    /// ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
    @Published var downloadedModels: Set<WhisperKitModel> = [] // åˆæœŸçŠ¶æ…‹ã§ã¯ç©º
    
    /// ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã®ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
    @Published var downloadingModels: Set<WhisperKitModel> = []
    
    /// å„ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é€²æ—ï¼ˆ0.0ã€œ1.0ï¼‰
    @Published var downloadProgress: [WhisperKitModel: Float] = [:]
    
    /// ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ãŸãƒ¢ãƒ‡ãƒ«ä¸€è¦§
    @Published var downloadErrorModels: Set<WhisperKitModel> = []
    
    /// ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å‡ºåŠ›è¨­å®šï¼ˆå¸¸æ™‚æœ‰åŠ¹ï¼‰
    private let timestampsEnabled: Bool = true
    
    /// è©³ç´°ãƒ­ã‚°å‡ºåŠ›è¨­å®šï¼ˆãƒªãƒªãƒ¼ã‚¹ç‰ˆã§ã¯ç„¡åŠ¹åŒ–ï¼‰
    private let verboseLoggingEnabled: Bool = false
    
    /// æ–‡å­—èµ·ã“ã—é€²æ—çŠ¶æ…‹
    @Published var transcriptionProgress: Float = 0.0
    
    /// æ–‡å­—èµ·ã“ã—æ®µéšã®èª¬æ˜
    @Published var transcriptionStage: String = ""
    
    // æ¨å®šæ®‹ã‚Šæ™‚é–“æ©Ÿèƒ½å‰Šé™¤ï¼ˆä¸æ­£ç¢ºãªãŸã‚ï¼‰
    
    /// æœ€æ–°ã®æ–‡å­—èµ·ã“ã—ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ†ã‚­ã‚¹ãƒˆ
    @Published var lastTranscriptionTimestamps: String? = nil
    
    /// æœ€æ–°ã®æ–‡å­—èµ·ã“ã—ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿
    @Published var lastTranscriptionSegments: [TranscriptionSegment]? = nil
    
    /// æ–‡å­—èµ·ã“ã—è¨€èªè¨­å®š
    @Published var transcriptionLanguage: TranscriptionLanguage {
        didSet {
            saveLanguageSetting()
       }
   }
    
    // MARK: - Private Properties
    
    /// WhisperKitã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    private var whisperKit: WhisperKit?
    
    /// åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼
    private var initializationError: Error?
    
    // MARK: - Singleton
    
    static let shared = WhisperKitTranscriptionService()
    
    private init() {
        // è¨€èªè¨­å®šã‚’å¾©å…ƒï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯OSè¨€èªã‹ã‚‰æ¤œå‡ºï¼‰
        self.transcriptionLanguage = loadLanguageSetting()
        
        // æ°¸ç¶šåŒ–ã•ã‚ŒãŸãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ã‚’å¾©å…ƒ
        loadDownloadedModelsState()
        
        // åŒæ¢±ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•æ¤œå‡ºã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿çŠ¶æ…‹ã«è¿½åŠ 
        let bundledModels = getBundledModels()
        downloadedModels.formUnion(bundledModels)
        if !bundledModels.isEmpty {
            saveDownloadedModelsState()
            if verboseLoggingEnabled { print("ğŸ“¦ Bundled models registered as downloaded: \(bundledModels)")
       }
        
        Task {
            await initializeWhisperKit()
       }
   }
    
    // MARK: - Model State Persistence
    
    /// ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ã‚’UserDefaultsã‹ã‚‰å¾©å…ƒ
    private func loadDownloadedModelsState() {
        let defaults = UserDefaults.standard
        if let savedModels = defaults.array(forKey: "downloadedWhisperModels") as? [String] {
            downloadedModels = Set(savedModels.compactMap { WhisperKitModel(rawValue: $0)})
            if verboseLoggingEnabled { print("ğŸ“± Loaded downloaded models state: \(downloadedModels)")
       }
   }
    
    /// ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ã‚’UserDefaultsã«ä¿å­˜
    private func saveDownloadedModelsState() {
        let defaults = UserDefaults.standard
        let modelStrings = downloadedModels.map { $0.rawValue}
        defaults.set(modelStrings, forKey: "downloadedWhisperModels")
        if verboseLoggingEnabled { print("ğŸ’¾ Saved downloaded models state: \(downloadedModels)")
   }
    
    // MARK: - Language Settings Persistence
    
    /// è¨€èªè¨­å®šã‚’UserDefaultsã‹ã‚‰å¾©å…ƒ
    private func loadLanguageSetting() -> TranscriptionLanguage {
        let defaults = UserDefaults.standard
        
        if let savedLanguage = defaults.string(forKey: "transcriptionLanguage"),
           let language = TranscriptionLanguage(rawValue: savedLanguage) {
            if verboseLoggingEnabled { print("ğŸ—£ï¸ Loaded saved language setting: \(language.displayName)")
            return language
       } else {
            // åˆå›èµ·å‹•æ™‚ã¯OSè¨€èªã‹ã‚‰è‡ªå‹•æ¤œå‡º
            let detectedLanguage = TranscriptionLanguage.detectFromSystem()
            if verboseLoggingEnabled { print("ğŸ—£ï¸ Auto-detected language from system: \(detectedLanguage.displayName)")
            return detectedLanguage
       }
   }
    
    /// è¨€èªè¨­å®šã‚’UserDefaultsã«ä¿å­˜
    private func saveLanguageSetting() {
        let defaults = UserDefaults.standard
        defaults.set(transcriptionLanguage.rawValue, forKey: "transcriptionLanguage")
        if verboseLoggingEnabled { print("ğŸ’¾ Saved language setting: \(transcriptionLanguage.displayName)")
   }
    
    // MARK: - Bundled Model Support
    
    /// åŒæ¢±ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—
    private func getBundledModelPath(for model: WhisperKitModel) -> String? {
        // ã¾ãšæ­£ç¢ºãªãƒ¢ãƒ‡ãƒ«åã§æ¤œç´¢
        if let bundlePath = Bundle.main.path(forResource: model.rawValue, ofType: nil, inDirectory: "WhisperKitModels") {
            if verboseLoggingEnabled { print("ğŸ“¦ Found bundled model at: \(bundlePath)")
            return bundlePath
       }
        
        // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šutilsã§å¯¾å¿œåã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆsmall/medium/largeï¼‰
        let alternativeNames = ["small", "medium", "large", "base"]
        for altName in alternativeNames {
            if let bundlePath = Bundle.main.path(forResource: altName, ofType: nil, inDirectory: "WhisperKitModels") {
                if verboseLoggingEnabled { print("ğŸ“¦ Found bundled model with alternative name '\(altName)' for \(model.rawValue): \(bundlePath)")
                return bundlePath
           }
       }
        
        if verboseLoggingEnabled { print("ğŸ“¦ Bundled model not found for: \(model.rawValue)")
        return nil
   }
    
    /// åŒæ¢±ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
    private func getBundledModels() -> Set<WhisperKitModel> {
        var bundledModels: Set<WhisperKitModel> = []
        
        for model in WhisperKitModel.allCases {
            if getBundledModelPath(for: model) != nil {
                bundledModels.insert(model)
           }
       }
        
        if verboseLoggingEnabled { print("ğŸ“¦ Available bundled models: \(bundledModels)")
        return bundledModels
   }
    
    /// åŒæ¢±ãƒ¢ãƒ‡ãƒ«ã‚’WhisperKitã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    private func setupBundledModel(modelPath: String, modelName: String) async throws {
        let fileManager = FileManager.default
        
        // WhisperKitã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
        let documentsPath = fileManager.urls(for: .documentDirectory, in: .userDomainMask).first!
        let cacheDir = documentsPath.appendingPathComponent("whisperkitcache")
        let modelDir = cacheDir.appendingPathComponent(modelName)
        
        // æ—¢ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if fileManager.fileExists(atPath: modelDir.path) {
            if verboseLoggingEnabled { print("ğŸ“¦ Bundled model already exists in cache: \(modelDir.path)")
            return
       }
        
        // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        try fileManager.createDirectory(at: cacheDir, withIntermediateDirectories: true)
        
        // åŒæ¢±ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ«ãƒ€å…¨ä½“ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼
        let bundledURL = URL(fileURLWithPath: modelPath)
        
        if fileManager.fileExists(atPath: bundledURL.path) {
            // ãƒ•ã‚©ãƒ«ãƒ€ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’ã‚³ãƒ”ãƒ¼
            try fileManager.copyItem(at: bundledURL, to: modelDir)
            if verboseLoggingEnabled { print("ğŸ“¦ Bundled model copied to cache: \(modelDir.path)")
       } else {
            if verboseLoggingEnabled { print("âŒ Bundled model not found at: \(bundledURL.path)")
            throw NSError(domain: "BundledModelError", code: 1, userInfo: [NSLocalizedDescriptionKey: "Bundled model not found"])
       }
   }
    
    // MARK: - Initialization
    
    /// WhisperKitã‚’éåŒæœŸã§åˆæœŸåŒ–ï¼ˆåŒæ¢±ãƒ¢ãƒ‡ãƒ«å„ªå…ˆï¼‰
    @MainActor
    private func initializeWhisperKit() async {
        if verboseLoggingEnabled { print("ğŸ—£ï¸ Initializing WhisperKit with bundled model priority...")
        
        do {
            // åŒæ¢±ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ã‚’ç¢ºèª
            let bundledModelPath = getBundledModelPath(for: selectedModel)
            
            if let modelPath = bundledModelPath {
                if verboseLoggingEnabled { print("ğŸ“¦ Found bundled model at: \(modelPath)")
                if verboseLoggingEnabled { print("ğŸ”§ Attempting to initialize WhisperKit with bundled model path: \(modelPath)")
                
                // åŒæ¢±ãƒ¢ãƒ‡ãƒ«ç”¨ã®è¨­å®šã§åˆæœŸåŒ–ã‚’è©¦è¡Œ
                // ã¾ãšã€bundled modelã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚³ãƒ”ãƒ¼ã™ã‚‹æ–¹å¼ã‚’è©¦ã™
                try await setupBundledModel(modelPath: modelPath, modelName: selectedModel.rawValue)
                
                // é€šå¸¸ã®æ–¹å¼ã§åˆæœŸåŒ–ï¼ˆã‚³ãƒ”ãƒ¼å¾Œï¼‰
                let config = WhisperKitConfig(
                    model: selectedModel.rawValue,
                    verbose: true,
                    logLevel: .info,
                    prewarm: false,
                    load: true,
                    download: false  // ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸è¦ï¼ˆæ—¢ã«ã‚³ãƒ”ãƒ¼æ¸ˆã¿ï¼‰
                )
                
                whisperKit = try await WhisperKit(config)
                if verboseLoggingEnabled { print("âœ… WhisperKit initialized with bundled model: \(selectedModel.displayName)")
                
           } else {
                // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¾“æ¥ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ–¹å¼
                if verboseLoggingEnabled { print("ğŸ“¥ Bundled model not found, falling back to download method")
                if verboseLoggingEnabled { print("ğŸ”§ Initializing WhisperKit with download: \(selectedModel.rawValue)")
                
                let config = WhisperKitConfig(
                    model: selectedModel.rawValue,
                    verbose: true,
                    logLevel: .info,
                    prewarm: false,
                    load: true,
                    download: true
                )
                
                whisperKit = try await WhisperKit(config)
                if verboseLoggingEnabled { print("âœ… WhisperKit initialized with downloaded model: \(selectedModel.displayName)")
           }
            
            isInitialized = true
            initializationError = nil
            
            // ãƒ¢ãƒ‡ãƒ«ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã¨ã—ã¦ãƒãƒ¼ã‚¯
            downloadedModels.insert(selectedModel)
            saveDownloadedModelsState()
            
       } catch {
            if verboseLoggingEnabled { print("âŒ Failed to initialize WhisperKit with model \(selectedModel.rawValue): \(error)")
            initializationError = error
            isInitialized = false
            errorMessage = "éŸ³å£°èªè­˜ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ (\(selectedModel.displayName)): \(error.localizedDescription)"
            
            // åˆæœŸåŒ–å¤±æ•—æ™‚ã«smallãƒ¢ãƒ‡ãƒ«ã§ãƒªãƒˆãƒ©ã‚¤
            if selectedModel != .small {
                if verboseLoggingEnabled { print("ğŸ”„ Retrying with small model as fallback...")
                selectedModel = .small
                await initializeWhisperKitFallback()
           }
       }
   }
    
    /// ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆæœŸåŒ–ï¼ˆsmallãƒ¢ãƒ‡ãƒ«ï¼‰
    @MainActor
    private func initializeWhisperKitFallback() async {
        do {
            if verboseLoggingEnabled { print("ğŸ”§ Fallback: Initializing WhisperKit with small model")
            let config = WhisperKitConfig(
                model: "small",
                verbose: true,
                logLevel: .info,
                prewarm: false,
                load: true,
                download: true
            )
            
            whisperKit = try await WhisperKit(config)
            isInitialized = true
            initializationError = nil
            
            if verboseLoggingEnabled { print("âœ… WhisperKit fallback initialization successful with small model")
            
            // smallãƒ¢ãƒ‡ãƒ«ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã¨ã—ã¦ãƒãƒ¼ã‚¯
            downloadedModels.insert(.small)
            saveDownloadedModelsState()
            
       } catch {
            if verboseLoggingEnabled { print("âŒ WhisperKit fallback initialization also failed: \(error)")
            initializationError = error
            isInitialized = false
            errorMessage = "éŸ³å£°èªè­˜ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å«ã‚€ï¼‰: \(error.localizedDescription)"
       }
   }
    
    /// ç‰¹å®šã®ãƒ¢ãƒ‡ãƒ«ã§WhisperKitã‚’åˆæœŸåŒ–ï¼ˆãƒ¢ãƒ‡ãƒ«åˆ‡ã‚Šæ›¿ãˆç”¨ï¼‰
    @MainActor
    private func initializeWithSpecificModel(_ model: WhisperKitModel) async {
        if verboseLoggingEnabled { print("ğŸ—£ï¸ Initializing WhisperKit with specific model: \(model.rawValue)")
        
        do {
            let config = WhisperKitConfig(
                model: model.rawValue,
                verbose: verboseLoggingEnabled,
                logLevel: .info,
                prewarm: false,
                load: true,
                download: true
            )
            
            if verboseLoggingEnabled { print("ğŸ“¥ Starting WhisperKit initialization for \(model.displayName)...")
            whisperKit = try await WhisperKit(config)
            isInitialized = true
            initializationError = nil
            
            if verboseLoggingEnabled { print("âœ… WhisperKit initialized successfully with \(model.displayName)")
            
       } catch {
            if verboseLoggingEnabled { print("âŒ Failed to initialize WhisperKit with model \(model.rawValue): \(error)")
            initializationError = error
            isInitialized = false
            errorMessage = "éŸ³å£°èªè­˜ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: \(error.localizedDescription)"
       }
   }
    
    // MARK: - Transcription
    
    /// éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—
    /// - Parameter audioURL: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®URL
    func transcribeAudioFile(at audioURL: URL) async throws {
        if verboseLoggingEnabled { print("ğŸ—£ï¸ Starting WhisperKit transcription for file: \(audioURL.lastPathComponent)")
        
        await MainActor.run {
            isTranscribing = true
            transcriptionText = ""
            errorMessage = nil
            processingTime = 0.0
       }
        
        // é€²æ—ãƒªã‚»ãƒƒãƒˆ
        await resetProgress()
        
        let startTime = Date()
        
        // éŸ³å£°å‰å‡¦ç†ï¼šWhisperKitç”¨ã«éŸ³é‡ã‚’æœ€é©åŒ–
        let processedAudioURL = try await preprocessAudioForWhisperKit(audioURL)
        
        // åˆæœŸåŒ–ãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
        if !isInitialized {
            await updateTranscriptionProgress(0.02, stage: "ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
            if verboseLoggingEnabled { print("â³ WhisperKit not initialized, waiting for initialization...")
            
            // æœ€å¤§60ç§’ã¾ã§åˆæœŸåŒ–å®Œäº†ã‚’å¾…æ©Ÿï¼ˆåˆå›ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯¾å¿œï¼‰
            let maxWaitTime = 60.0
            let checkInterval = 0.5
            var totalWaitTime = 0.0
            
            while !isInitialized && totalWaitTime < maxWaitTime {
                try await Task.sleep(nanoseconds: UInt64(checkInterval * 1_000_000_000))
                totalWaitTime += checkInterval
                
                // é€²æ—è¡¨ç¤ºï¼ˆ5ç§’ãŠãï¼‰
                if Int(totalWaitTime) % 5 == 0 && totalWaitTime > 0 {
                    if verboseLoggingEnabled { print("â³ WhisperKit initializing... \(Int(totalWaitTime))s / \(Int(maxWaitTime))s (model download may be in progress)")
               }
                
                // åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã¯å³åº§ã«çµ‚äº†
                if let error = initializationError {
                    if verboseLoggingEnabled { print("âŒ WhisperKit initialization failed during wait: \(error)")
                    throw WhisperKitTranscriptionError.initializationFailed(error)
               }
           }
            
            // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒã‚§ãƒƒã‚¯
            if !isInitialized {
                if verboseLoggingEnabled { print("â° WhisperKit initialization timeout after \(totalWaitTime)s")
                throw WhisperKitTranscriptionError.initializationTimeout
           }
            
            if verboseLoggingEnabled { print("âœ… WhisperKit initialization completed after \(totalWaitTime)s wait")
       }
        
        // åˆæœŸåŒ–ãƒã‚§ãƒƒã‚¯
        guard isInitialized, let whisperKit = whisperKit else {
            if let error = initializationError {
                throw WhisperKitTranscriptionError.initializationFailed(error)
           } else {
                throw WhisperKitTranscriptionError.notInitialized
           }
       }
        
        // ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        guard FileManager.default.fileExists(atPath: audioURL.path) else {
            throw WhisperKitTranscriptionError.fileNotFound
       }
        
        do {
            // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
            await updateTranscriptionProgress(0.05, stage: "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
            let audioFileInfo = try await getAudioFileInfo(url: processedAudioURL)
            if verboseLoggingEnabled { print("ğŸµ Audio file info: duration=\(audioFileInfo.duration)s, format=\(audioFileInfo.format)")
            
            await updateTranscriptionProgress(0.10, stage: "éŸ³å£°è§£ææº–å‚™ä¸­...")
            
            // éŸ³å£°å“è³ªãƒã‚§ãƒƒã‚¯
            if audioFileInfo.duration < 1.0 {
                if verboseLoggingEnabled { print("âš ï¸ Audio file too short (\(audioFileInfo.duration)s), may cause music detection")
           }
            
            // WhisperKitã§æ–‡å­—èµ·ã“ã—å®Ÿè¡Œï¼ˆæ—¥æœ¬èªéŸ³å£°èªè­˜æœ€é©åŒ–è¨­å®šï¼‰
            await updateTranscriptionProgress(0.15, stage: "æ–‡å­—èµ·ã“ã—å®Ÿè¡Œä¸­...")
            if verboseLoggingEnabled { print("ğŸ¯ Starting transcription: \(selectedModel.displayName)")
            if verboseLoggingEnabled { print("ğŸ”§ Audio: \(String(format: "%.1f", audioFileInfo.duration))s, Model: \(selectedModel.rawValue)")
            if verboseLoggingEnabled { print("ğŸ”§ WhisperKit State: initialized=\(isInitialized), instance=\(whisperKit != nil)")
            
            // å‹•çš„è¨€èªè¨­å®šã§æ–‡å­—èµ·ã“ã—ï¼ˆè¨­å®šã•ã‚ŒãŸè¨€èªã‚’ä½¿ç”¨ï¼‰
            let selectedLanguage = transcriptionLanguage.whisperKitCode
            if verboseLoggingEnabled { print("ğŸ—£ï¸ Using language setting: \(transcriptionLanguage.displayName) (code: \(selectedLanguage ?? "auto"))")
            
            let transcription = try await whisperKit.transcribe(
                audioPath: processedAudioURL.path,
                decodeOptions: DecodingOptions(
                    verbose: true,              // è©³ç´°ãƒ­ã‚°æœ‰åŠ¹
                    task: .transcribe,          // ç¿»è¨³ã§ã¯ãªãè»¢å†™
                    language: selectedLanguage, // è¨­å®šã•ã‚ŒãŸè¨€èªï¼ˆnilã®å ´åˆã¯è‡ªå‹•æ¤œå‡ºï¼‰
                    temperature: 0.0,           // æ±ºå®šè«–çš„è¨­å®šã§æœ€é«˜ç²¾åº¦
                    temperatureIncrementOnFallback: 0.2,
                    temperatureFallbackCount: 5,
                    sampleLength: 224,
                    usePrefillPrompt: true,     // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½¿ç”¨
                    usePrefillCache: true,      // ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹ã§ä¸€è²«æ€§å‘ä¸Š
                    skipSpecialTokens: true,    // ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’WhisperKitãƒ¬ãƒ™ãƒ«ã§é™¤å»
                    withoutTimestamps: false    // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯å–å¾—ï¼ˆå¾Œå‡¦ç†ã§æ´»ç”¨ï¼‰
                )
            )
            
            let endTime = Date()
            let duration = endTime.timeIntervalSince(startTime)
            
            // çµæœã®å–å¾—ã¨å‡¦ç†
            await updateTranscriptionProgress(0.85, stage: "çµæœå‡¦ç†ä¸­...")
            if verboseLoggingEnabled { print("ğŸ“ Transcription completed: \(transcription.count) result(s)")
            
            let resultText: String
            if !transcription.isEmpty {
                let result = transcription.first!
                if verboseLoggingEnabled { print("ğŸ“ Segments: \(result.segments.count), Text length: \(result.text.count)")
                
                // æœ€åˆã®çµæœã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨
                let mainText = transcription.first?.text ?? ""
                if verboseLoggingEnabled { print("ğŸ” RAW WhisperKit output: '\(mainText)'")
                
                // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè©³ç´°ã‚‚ãƒ­ã‚°å‡ºåŠ›ï¼ˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å‰ï¼‰
                for (index, segment) in result.segments.enumerated() {
                    if verboseLoggingEnabled { print("ğŸ” Segment \(index) RAW: '\(segment.text)' (start: \(segment.start), end: \(segment.end))")
               }
                
                // éŸ³æ¥½åˆ¤å®šã®å¾Œå‡¦ç†æ”¹å–„
                let cleanedText = postProcessTranscriptionResult(mainText)
                if verboseLoggingEnabled { print("ğŸ” After postProcessing main text: '\(cleanedText)'")
                
                // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå˜ä½ã§æ”¹è¡Œã‚’å…¥ã‚Œã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æ•´å½¢ï¼ˆå¼·åŒ–ã•ã‚ŒãŸç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
                if cleanedText.isEmpty {
                    if verboseLoggingEnabled { print("ğŸ”§ Main text is empty after cleaning, trying to merge segments...")
                    let allSegmentTexts = transcription.flatMap { $0.segments}.compactMap { segment -> String? in
                        let rawSegmentText = segment.text.trimmingCharacters(in: CharacterSet.whitespacesAndNewlines)
                        let cleanedSegmentText = postProcessTranscriptionResult(rawSegmentText)
                        if verboseLoggingEnabled { print("ğŸ” Segment processing: '\(rawSegmentText)' -> '\(cleanedSegmentText)'")
                        return cleanedSegmentText.isEmpty ? nil : cleanedSegmentText
                   }
                    resultText = allSegmentTexts.joined(separator: "\n")
                    if verboseLoggingEnabled { print("ğŸ”§ Merged segment text with line breaks: '\(resultText)'")
               } else {
                    // ãƒ¡ã‚¤ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã‚‚ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå˜ä½ã§æ”¹è¡Œã‚’è¿½åŠ ï¼ˆå¼·åŒ–ã•ã‚ŒãŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
                    if let firstResult = transcription.first, !firstResult.segments.isEmpty {
                        let segmentTexts = firstResult.segments.compactMap { segment -> String? in
                            let rawSegmentText = segment.text.trimmingCharacters(in: CharacterSet.whitespacesAndNewlines)
                            let cleanedSegmentText = postProcessTranscriptionResult(rawSegmentText)
                            if verboseLoggingEnabled { print("ğŸ” Segment processing: '\(rawSegmentText)' -> '\(cleanedSegmentText)'")
                            return cleanedSegmentText.isEmpty ? nil : cleanedSegmentText
                       }
                        
                        if !segmentTexts.isEmpty {
                            resultText = segmentTexts.joined(separator: "\n")
                            if verboseLoggingEnabled { print("ğŸ”§ Formatted text with segment breaks: '\(resultText)'")
                       } else {
                            resultText = cleanedText
                       }
                   } else {
                        resultText = cleanedText
                   }
               }
           } else {
                if verboseLoggingEnabled { print("âŒ No transcription results returned")
                resultText = ""
           }
            
            // ç©ºã¾ãŸã¯ç„¡åŠ¹ãªçµæœã®å ´åˆã®å†è©¦è¡Œãƒ­ã‚¸ãƒƒã‚¯
            let finalResultText: String
            if (resultText.isEmpty || isOnlySpecialTokens(resultText)) && audioFileInfo.duration > 2.0 {
                if verboseLoggingEnabled { print("ğŸ”„ Empty or invalid result detected, attempting retry with speech-focused settings...")
                if verboseLoggingEnabled { print("ğŸ”„ Original result: '\(resultText)'")
                finalResultText = try await retryWithSpeechFocusedSettings(audioURL: audioURL, whisperKit: whisperKit)
           } else {
                finalResultText = resultText
           }
            
            // å®Œäº†çŠ¶æ…‹ã®æ›´æ–°
            await updateTranscriptionProgress(1.0, stage: "å®Œäº†")
            
            // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ‡ãƒ¼ã‚¿ã®è‡ªå‹•ä¿å­˜ï¼ˆUIè¨­å®šã«é–¢ã‚ã‚‰ãšå¸¸æ™‚å®Ÿè¡Œï¼‰
            let timestampedText = getTimestampedText(from: transcription)
            let segmentData = extractSegmentData(from: transcription)
            
            await MainActor.run {
                self.transcriptionText = finalResultText
                self.processingTime = duration
                self.isTranscribing = false
                
                // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ‡ãƒ¼ã‚¿ã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«ä¿å­˜ï¼ˆå¾Œã§Recordingãƒ¢ãƒ‡ãƒ«ã«é€£æºï¼‰
                self.lastTranscriptionTimestamps = timestampedText
                self.lastTranscriptionSegments = segmentData
           }
            
            if verboseLoggingEnabled { print("âœ… Transcription completed in \(String(format: "%.2f", duration))s (\(finalResultText.count) chars)")
            
       } catch {
            let endTime = Date()
            let duration = endTime.timeIntervalSince(startTime)
            
            if verboseLoggingEnabled { print("âŒ WhisperKit transcription failed after \(String(format: "%.2f", duration))s: \(error)")
            if verboseLoggingEnabled { print("ğŸ” Error details: \(error)")
            if verboseLoggingEnabled { print("ğŸ” Audio file: \(audioURL.path)")
            if verboseLoggingEnabled { print("ğŸ” WhisperKit state: initialized=\(isInitialized), model=\(selectedModel.rawValue)")
            
            await resetProgress()
            
            await MainActor.run {
                self.errorMessage = error.localizedDescription
                self.isTranscribing = false
           }
            
            throw WhisperKitTranscriptionError.transcriptionFailed(error)
       }
   }
    
    // MARK: - Audio Preprocessing
    
    /// WhisperKitç”¨ã«éŸ³å£°ã‚’å‰å‡¦ç†ï¼ˆéŸ³é‡æœ€é©åŒ–ï¼‰
    private func preprocessAudioForWhisperKit(_ audioURL: URL) async throws -> URL {
        if verboseLoggingEnabled { print("ğŸšï¸ Preprocessing audio for WhisperKit optimization...")
        
        // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        let tempDir = FileManager.default.temporaryDirectory
        let processedFileName = "whisperkit_\(audioURL.lastPathComponent)"
        let processedURL = tempDir.appendingPathComponent(processedFileName)
        
        // æ—¢å­˜ã®å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤
        if FileManager.default.fileExists(atPath: processedURL.path) {
            try FileManager.default.removeItem(at: processedURL)
       }
        
        // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        let audioFile = try AVAudioFile(forReading: audioURL)
        let format = audioFile.processingFormat
        
        // ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’å–å¾—
        let frameCount = AVAudioFrameCount(audioFile.length)
        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: frameCount) else {
            throw WhisperKitTranscriptionError.transcriptionFailed(
                NSError(domain: "AudioPreprocessing", code: 1, userInfo: [NSLocalizedDescriptionKey: "Cannot create audio buffer"])
            )
       }
        
        // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        try audioFile.read(into: buffer)
        
        // éŸ³é‡è§£æ
        let volumeAnalysis = analyzeAudioVolume(buffer)
        if verboseLoggingEnabled { print("ğŸšï¸ Audio analysis: peak=\(volumeAnalysis.peak), rms=\(volumeAnalysis.rms), dynamic_range=\(volumeAnalysis.dynamicRange)")
        
        // WhisperKitç”¨æœ€é©åŒ–
        let optimizedBuffer = optimizeAudioForWhisperKit(buffer, analysis: volumeAnalysis)
        
        // å‡¦ç†æ¸ˆã¿éŸ³å£°ã‚’ä¿å­˜
        let outputFile = try AVAudioFile(forWriting: processedURL, settings: audioFile.fileFormat.settings)
        try outputFile.write(from: optimizedBuffer)
        
        if verboseLoggingEnabled { print("ğŸšï¸ Audio preprocessing completed: \(processedURL.lastPathComponent)")
        return processedURL
   }
    
    /// éŸ³å£°ã®éŸ³é‡ã‚’è§£æ
    private func analyzeAudioVolume(_ buffer: AVAudioPCMBuffer) -> (peak: Float, rms: Float, dynamicRange: Float) {
        guard let channelData = buffer.floatChannelData else {
            return (peak: 0.0, rms: 0.0, dynamicRange: 0.0)
       }
        
        let frameLength = Int(buffer.frameLength)
        let channelCount = Int(buffer.format.channelCount)
        
        var maxPeak: Float = 0.0
        var sumSquares: Float = 0.0
        var minPeak: Float = 1.0
        
        for channel in 0..<channelCount {
            let data = channelData[channel]
            for frame in 0..<frameLength {
                let sample = abs(data[frame])
                maxPeak = max(maxPeak, sample)
                minPeak = min(minPeak, sample > 0.001 ? sample : minPeak)
                sumSquares += sample * sample
           }
       }
        
        let rms = sqrt(sumSquares / Float(frameLength * channelCount))
        let dynamicRange = maxPeak > 0 && minPeak > 0 ? 20 * log10(maxPeak / minPeak) : 0
        
        return (peak: maxPeak, rms: rms, dynamicRange: dynamicRange)
   }
    
    /// WhisperKitç”¨ã«éŸ³å£°ã‚’æœ€é©åŒ–
    private func optimizeAudioForWhisperKit(_ buffer: AVAudioPCMBuffer, analysis: (peak: Float, rms: Float, dynamicRange: Float)) -> AVAudioPCMBuffer {
        guard let inputChannelData = buffer.floatChannelData,
              let optimizedBuffer = AVAudioPCMBuffer(pcmFormat: buffer.format, frameCapacity: buffer.frameCapacity) else {
            return buffer
       }
        
        optimizedBuffer.frameLength = buffer.frameLength
        guard let outputChannelData = optimizedBuffer.floatChannelData else {
            return buffer
       }
        
        // WhisperKitæœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        let targetRMS: Float = 0.15        // WhisperKitã«é©ã—ãŸéŸ³é‡ãƒ¬ãƒ™ãƒ«
        let targetPeak: Float = 0.7        // ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°å›é¿
        let compressionRatio: Float = 2.0  // å‹•çš„ç¯„å›²åœ§ç¸®
        
        // ã‚²ã‚¤ãƒ³è¨ˆç®—
        let rmsGain = analysis.rms > 0.001 ? targetRMS / analysis.rms : 1.0
        let peakGain = analysis.peak > 0.001 ? targetPeak / analysis.peak : 1.0
        let finalGain = min(rmsGain, peakGain) // ä¿å®ˆçš„ãªã‚²ã‚¤ãƒ³é¸æŠ
        
        if verboseLoggingEnabled { print("ğŸšï¸ WhisperKit optimization: rms_gain=\(rmsGain), peak_gain=\(peakGain), final_gain=\(finalGain)")
        
        let frameLength = Int(buffer.frameLength)
        let channelCount = Int(buffer.format.channelCount)
        
        for channel in 0..<channelCount {
            let inputData = inputChannelData[channel]
            let outputData = outputChannelData[channel]
            
            for frame in 0..<frameLength {
                let inputSample = inputData[frame]
                
                // ã‚²ã‚¤ãƒ³é©ç”¨
                var amplifiedSample = inputSample * finalGain
                
                // ã‚½ãƒ•ãƒˆã‚³ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ï¼ˆWhisperKitç”¨å‹•çš„ç¯„å›²æœ€é©åŒ–ï¼‰
                let threshold: Float = 0.5
                if abs(amplifiedSample) > threshold {
                    let excess = abs(amplifiedSample) - threshold
                    let compressedExcess = excess / compressionRatio
                    amplifiedSample = (amplifiedSample > 0 ? 1 : -1) * (threshold + compressedExcess)
               }
                
                // ã‚½ãƒ•ãƒˆã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ï¼ˆè‡ªç„¶ãªéŸ³è³ªç¶­æŒï¼‰
                outputData[frame] = tanh(amplifiedSample * 0.8) // 80%ã§å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³
           }
       }
        
        return optimizedBuffer
   }
    
    // MARK: - Helper Methods
    
    /// æ–‡å­—èµ·ã“ã—çµæœã®å¾Œå‡¦ç†ï¼ˆéŸ³æ¥½åˆ¤å®šã‚¨ãƒ©ãƒ¼ã¨ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã®ä¿®æ­£ï¼‰
    private func postProcessTranscriptionResult(_ text: String) -> String {
        let trimmedText = text.trimmingCharacters(in: CharacterSet.whitespacesAndNewlines)
        
        // ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’é™¤å»
        var cleanedText = removeSpecialTokens(from: trimmedText)
        
        // éŸ³æ¥½ã¨ã—ã¦èª¤åˆ¤å®šã•ã‚ŒãŸå ´åˆã®å‡¦ç†
        let musicPatterns = [
            "(éŸ³æ¥½)", "[éŸ³æ¥½]", "â™ª", "â™«", "â™ªâ™«", "(Music)", "[Music]",
            "(BGM)", "[BGM]", "(èƒŒæ™¯éŸ³æ¥½)", "[èƒŒæ™¯éŸ³æ¥½]"
        ]
        
        // éŸ³æ¥½ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿ã®å ´åˆã¯ç©ºæ–‡å­—ã‚’è¿”ã™ï¼ˆå†å‡¦ç†å¯¾è±¡ï¼‰
        for pattern in musicPatterns {
            if cleanedText == pattern {
                if verboseLoggingEnabled { print("ğŸµ Music pattern detected: '\(pattern)' - treating as empty for retry")
                return ""
           }
       }
        
        // éŸ³æ¥½ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å«ã‚€å ´åˆã¯é™¤å»
        for pattern in musicPatterns {
            cleanedText = cleanedText.replacingOccurrences(of: pattern, with: "")
       }
        
        // å‰å¾Œã®ç©ºç™½ã‚’å†åº¦é™¤å»
        cleanedText = cleanedText.trimmingCharacters(in: CharacterSet.whitespacesAndNewlines)
        
        // ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿ã®å ´åˆã¯ç©ºæ–‡å­—ã‚’è¿”ã™
        if isOnlySpecialTokens(cleanedText) {
            if verboseLoggingEnabled { print("ğŸ·ï¸ Only special tokens detected, treating as empty")
            return ""
       }
        
        // ç©ºã®çµæœã®å ´åˆã¯ãƒ­ã‚°å‡ºåŠ›
        if cleanedText.isEmpty && !trimmedText.isEmpty {
            if verboseLoggingEnabled { print("ğŸ”§ Text cleaned to empty: original='\(trimmedText)' -> cleaned='\(cleanedText)'")
       }
        
        return cleanedText
   }
    
    /// ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’é™¤å»
    private func removeSpecialTokens(from text: String) -> String {
        var cleanedText = text
        
        // WhisperKitç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆåŒ…æ‹¬çš„ãªè¨€èªã‚¿ã‚°é™¤å»ï¼‰
        let specialTokenPatterns = [
            "<\\|startoftranscript\\|>",
            "<\\|endoftext\\|>",
            "<\\|ja\\|>",                // æ—¥æœ¬èªã‚¿ã‚°
            "<\\|en\\|>",                // è‹±èªã‚¿ã‚°  
            "<\\|zh\\|>",                // ä¸­å›½èªã‚¿ã‚°
            "<\\|ko\\|>",                // éŸ“å›½èªã‚¿ã‚°
            "<\\|[a-z]{2}\\|>",          // ãã®ä»–ã®è¨€èªã‚¿ã‚°ï¼ˆ2æ–‡å­—ï¼‰
            "<\\|transcribe\\|>",        // è»¢å†™ã‚¿ã‚°
            "<\\|translate\\|>",         // ç¿»è¨³ã‚¿ã‚°
            "<\\|\\d+\\.\\d+\\|>",       // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ— <|0.00|>
            "<\\|notimestamps\\|>",
            "<\\|nospeech\\|>",
            "<\\|music\\|>",
            "<\\|silence\\|>",
            "<\\|[^>]+\\|>"              // ãã®ä»–ã®ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆåŒ…æ‹¬çš„ï¼‰
        ]
        
        // æ­£è¦è¡¨ç¾ã§ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’é™¤å»
        for pattern in specialTokenPatterns {
            cleanedText = cleanedText.replacingOccurrences(
                of: pattern,
                with: "",
                options: .regularExpression
            )
       }
        
        // é€£ç¶šã™ã‚‹ç‰¹æ®Šè¨˜å·ã‚‚é™¤å»ï¼ˆå¤šé‡ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
        let additionalCleanupPatterns = [
            "<[^>]*>",                   // HTMLé¢¨ã‚¿ã‚°
            "\\([^)]*transcribe[^)]*\\)", // æ‹¬å¼§å†…ã®transcribe
            "\\[[^]]*transcribe[^]]*\\]", // è§’æ‹¬å¼§å†…ã®transcribe
            "\\s*<\\|.*?\\|>\\s*"        // å‰å¾Œã®ç©ºç™½ã‚‚å«ã‚€ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³
        ]
        
        for pattern in additionalCleanupPatterns {
            cleanedText = cleanedText.replacingOccurrences(
                of: pattern,
                with: "",
                options: .regularExpression
            )
       }
        
        // é€£ç¶šã™ã‚‹ç©ºç™½ã‚’å˜ä¸€ã‚¹ãƒšãƒ¼ã‚¹ã«å¤‰æ›
        cleanedText = cleanedText.replacingOccurrences(
            of: "\\s+",
            with: " ",
            options: .regularExpression
        )
        
        // ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¿½åŠ 
        if text != cleanedText && !text.isEmpty {
            if verboseLoggingEnabled { print("ğŸ”§ Token filter: '\(text)' -> '\(cleanedText)'")
       }
        
        return cleanedText.trimmingCharacters(in: CharacterSet.whitespacesAndNewlines)
   }
    
    /// ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿ã‹ã©ã†ã‹ã‚’åˆ¤å®š
    private func isOnlySpecialTokens(_ text: String) -> Bool {
        let cleanedText = removeSpecialTokens(from: text)
        return cleanedText.isEmpty
   }
    
    /// éŸ³å£°ç‰¹åŒ–è¨­å®šã§ã®å†è©¦è¡Œ
    private func retryWithSpeechFocusedSettings(audioURL: URL, whisperKit: WhisperKit) async throws -> String {
        if verboseLoggingEnabled { print("ğŸ¯ Retrying with speech-focused settings to avoid music detection")
        
        let retryTranscription = try await whisperKit.transcribe(
            audioPath: audioURL.path,
            decodeOptions: DecodingOptions(
                verbose: true,              // è©³ç´°ãƒ­ã‚°ï¼ˆéå»è¨­å®šï¼‰
                task: .transcribe,          // è»¢å†™ã‚’æ˜ç¤º
                language: "ja",             // æ—¥æœ¬èªã‚’å¼·åˆ¶
                temperature: 0.3,           // å°‘ã—é«˜ã„æ¸©åº¦ã§å¤šæ§˜æ€§ç¢ºä¿ï¼ˆéå»è¨­å®šï¼‰
                temperatureIncrementOnFallback: 0.2,
                temperatureFallbackCount: 3,
                sampleLength: 224,
                usePrefillPrompt: true,     // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½¿ç”¨
                usePrefillCache: false,     // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ã§æ–°é®®ãªçµæœï¼ˆéå»è¨­å®šï¼‰
                skipSpecialTokens: true,    // ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³é™¤å»ï¼ˆéå»è¨­å®šï¼‰
                withoutTimestamps: true     // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãªã—ã§ã‚¯ãƒªãƒ¼ãƒ³ï¼ˆéå»è¨­å®šï¼‰
            )
        )
        
        // å†è©¦è¡Œçµæœã®å‡¦ç†
        if !retryTranscription.isEmpty {
            let retryText = retryTranscription.first?.text ?? ""
            if verboseLoggingEnabled { print("ğŸ” Retry RAW output: '\(retryText)'")
            
            // ãƒªãƒˆãƒ©ã‚¤çµæœã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè©³ç´°ã‚‚ãƒ­ã‚°å‡ºåŠ›ï¼ˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å‰å¾Œï¼‰
            if let retryResult = retryTranscription.first {
                for (index, segment) in retryResult.segments.enumerated() {
                    let rawSegmentText = segment.text
                    let cleanedSegmentText = postProcessTranscriptionResult(rawSegmentText)
                    if verboseLoggingEnabled { print("ğŸ” Retry Segment \(index) RAW: '\(rawSegmentText)' -> CLEANED: '\(cleanedSegmentText)' (start: \(segment.start), end: \(segment.end))")
               }
           }
            
            let cleanedRetryText = postProcessTranscriptionResult(retryText)
            if verboseLoggingEnabled { print("ğŸ”„ Retry result: '\(cleanedRetryText)'")
            return cleanedRetryText
       }
        
        if verboseLoggingEnabled { print("ğŸ”„ Retry also returned empty result")
        return ""
   }
    
    /// éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
    private func getAudioFileInfo(url: URL) async throws -> (duration: TimeInterval, format: String) {
        let asset = AVURLAsset(url: url)
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã®åŸºæœ¬æƒ…å ±ã‚’éåŒæœŸã§å–å¾—
        let duration = try await asset.load(.duration)
        let durationSeconds = CMTimeGetSeconds(duration)
        
        // ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼æƒ…å ±ã‚’å–å¾—
        let tracks = try await asset.loadTracks(withMediaType: .audio)
        let timeScale = try await tracks.first?.load(.naturalTimeScale) ?? 44100
        let format = timeScale.description
        
        return (duration: durationSeconds, format: format)
   }
    
    /// å®Ÿè¡Œä¸­ã®æ–‡å­—èµ·ã“ã—ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
    func cancelTranscription() {
        // WhisperKitã§ã¯ç¾åœ¨ã‚­ãƒ£ãƒ³ã‚»ãƒ«æ©Ÿèƒ½ã¯åˆ¶é™çš„
        // ã‚¿ã‚¹ã‚¯ã®å®Œäº†ã‚’å¾…ã¤ã‹ã€æ–°ã—ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§å¯¾å¿œ
        
        DispatchQueue.main.async {
            self.isTranscribing = false
            self.errorMessage = "æ–‡å­—èµ·ã“ã—ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ"
       }
        
        if verboseLoggingEnabled { print("â¹ï¸ WhisperKit transcription cancelled")
   }
    
    /// å†åˆæœŸåŒ–ï¼ˆã‚¨ãƒ©ãƒ¼å›å¾©ç”¨ï¼‰
    func reinitialize() async {
        await MainActor.run {
            self.isInitialized = false
            self.whisperKit = nil
       }
        
        await initializeWhisperKit()
   }
    
    /// å¤±æ•—ã—ãŸæ–‡å­—èµ·ã“ã—ã®å†è©¦è¡Œï¼ˆåˆæœŸåŒ–å®Œäº†å¾Œï¼‰
    func retryTranscription(audioURL: URL) async throws {
        if verboseLoggingEnabled { print("ğŸ”„ Retrying transcription for: \(audioURL.lastPathComponent)")
        
        // æ—¢ã«åˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ç›´æ¥å®Ÿè¡Œ
        if isInitialized {
            try await transcribeAudioFile(at: audioURL)
            return
       }
        
        // åˆæœŸåŒ–ãŒå¿…è¦ãªå ´åˆã¯å†åˆæœŸåŒ–ã—ã¦ã‹ã‚‰å®Ÿè¡Œ
        if verboseLoggingEnabled { print("ğŸ”„ Reinitializing WhisperKit for retry...")
        await reinitialize()
        
        if isInitialized {
            try await transcribeAudioFile(at: audioURL)
       } else {
            throw WhisperKitTranscriptionError.initializationFailed(
                NSError(domain: "WhisperKitTranscriptionService", 
                       code: -1, 
                       userInfo: [NSLocalizedDescriptionKey: "å†åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ"])
            )
       }
   }
    
    /// ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›´ã—ã¦å†åˆæœŸåŒ–
    func changeModel(to model: WhisperKitModel) async {
        if verboseLoggingEnabled { print("ğŸ”„ Changing model from \(selectedModel.rawValue) to \(model.rawValue)")
        
        // åŒã˜ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯ä½•ã‚‚ã—ãªã„
        if selectedModel == model {
            if verboseLoggingEnabled { print("âš ï¸ Model \(model.rawValue) is already selected")
            return
       }
        
        // æ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
        let isAlreadyDownloaded = await MainActor.run { downloadedModels.contains(model)}
        
        await MainActor.run {
            self.selectedModel = model
            self.isInitialized = false
            self.whisperKit = nil
            
            if !isAlreadyDownloaded {
                // æœªãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã®å ´åˆã®ã¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çŠ¶æ…‹ã«è¨­å®š
                self.downloadingModels.insert(model)
                self.downloadErrorModels.remove(model)
                self.downloadProgress[model] = 0.0
                if verboseLoggingEnabled { print("ğŸ“¥ Starting download for model: \(model.displayName)")
           } else {
                // æ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®å ´åˆ
                self.downloadingModels.remove(model)
                if verboseLoggingEnabled { print("âœ… Model \(model.displayName) already downloaded, initializing...")
           }
       }
        
        // æœªãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã®å ´åˆã®ã¿é€²æ—æ¨å®šã‚’å®Ÿè¡Œ
        if !isAlreadyDownloaded {
            await estimateDownloadProgress(for: model)
       }
        
        // å°‚ç”¨ã®åˆæœŸåŒ–é–¢æ•°ã‚’ä½¿ç”¨
        await initializeWithSpecificModel(model)
        
        // åˆæœŸåŒ–çµæœã«åŸºã¥ã„ã¦çŠ¶æ…‹ã‚’æ›´æ–°
        await MainActor.run {
            if self.isInitialized {
                self.downloadedModels.insert(model)
                self.downloadingModels.remove(model)
                self.downloadProgress[model] = 1.0
                self.saveDownloadedModelsState()
                if verboseLoggingEnabled { print("âœ… Model \(model.rawValue) successfully initialized")
           } else {
                self.downloadingModels.remove(model)
                self.downloadErrorModels.insert(model)
                self.downloadProgress[model] = 0.0
                if verboseLoggingEnabled { print("âŒ Model \(model.rawValue) initialization failed")
           }
       }
   }
    
    /// ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é€²æ—ã®å®Ÿæ¸¬æ¨å®š
    private func estimateDownloadProgress(for model: WhisperKitModel) async {
        if verboseLoggingEnabled { print("ğŸ“¥ Starting model download estimation for \(model.displayName)")
        
        // æ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
        if await isModelCached(model) {
            if verboseLoggingEnabled { print("âœ… Model \(model.displayName) already cached, skipping download")
            await MainActor.run {
                self.downloadProgress[model] = 1.0
                self.downloadedModels.insert(model)
                self.downloadingModels.remove(model)
           }
            return
       }
        
        // ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãƒ™ãƒ¼ã‚¹ã®æ¨å®šæ™‚é–“ï¼ˆå®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ï¼‰
        let estimatedDuration: TimeInterval = {
            switch model {
            case .small: return 15.0    // 500MB: ç´„15ç§’
            case .medium: return 45.0   // 1GB: ç´„45ç§’
            case .large: return 90.0    // 1.5GB: ç´„90ç§’
           }
       }()
        
        let totalSteps = 20
        let stepDuration = estimatedDuration / Double(totalSteps)
        
        for step in 1...totalSteps {
            let progress = Float(step) / Float(totalSteps)
            
            await MainActor.run {
                // ã‚ˆã‚Šè‡ªç„¶ãªé€²æ—ã‚«ãƒ¼ãƒ–ï¼ˆæœ€åˆã¯é€Ÿãã€å¾ŒåŠã¯é…ãï¼‰
                let adjustedProgress = naturalProgressCurve(progress)
                self.downloadProgress[model] = adjustedProgress * 0.95 // 95%ã¾ã§è¡¨ç¤ºï¼ˆå®Œäº†ã¯åˆ¥é€”ï¼‰
                
                if verboseLoggingEnabled { print("ğŸ“Š Download progress for \(model.displayName): \(Int(adjustedProgress * 100))%")
           }
            
            try? await Task.sleep(nanoseconds: UInt64(stepDuration * 1_000_000_000))
       }
        
        if verboseLoggingEnabled { print("ğŸ“¥ Download estimation completed for \(model.displayName)")
   }
    
    /// ã‚ˆã‚Šè‡ªç„¶ãªé€²æ—ã‚«ãƒ¼ãƒ–ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚‰ã—ã„å‹•ãï¼‰
    private func naturalProgressCurve(_ linearProgress: Float) -> Float {
        // Så­—ã‚«ãƒ¼ãƒ–: æœ€åˆã¨æœ€å¾Œã¯é…ãã€ä¸­é–“ã¯é€Ÿã„
        let x = linearProgress
        return x * x * (3.0 - 2.0 * x)
   }
    
    /// ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    private func isModelCached(_ model: WhisperKitModel) async -> Bool {
        // WhisperKitã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒã‚§ãƒƒã‚¯
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first!
        let whisperKitPath = documentsPath.appendingPathComponent("whisperkitcache")
        let modelPath = whisperKitPath.appendingPathComponent(model.rawValue)
        
        // ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        var isDirectory: ObjCBool = false
        let exists = FileManager.default.fileExists(atPath: modelPath.path, isDirectory: &isDirectory)
        
        if exists && isDirectory.boolValue {
            // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹å ´åˆã€å†…å®¹ã‚’ãƒã‚§ãƒƒã‚¯
            do {
                let contents = try FileManager.default.contentsOfDirectory(atPath: modelPath.path)
                let hasMLFiles = contents.contains { $0.hasSuffix(".mlmodelc") || $0.hasSuffix(".bin")}
                
                if hasMLFiles {
                    if verboseLoggingEnabled { print("âœ… Model \(model.displayName) found in cache at \(modelPath.path)")
                    return true
               }
           } catch {
                if verboseLoggingEnabled { print("âš ï¸ Error checking model cache: \(error)")
           }
       }
        
        if verboseLoggingEnabled { print("ğŸ“¥ Model \(model.displayName) not found in cache, download required")
        return false
   }
    
    // MARK: - Timestamp Processing
    
    /// ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ†ã‚­ã‚¹ãƒˆã®ç”Ÿæˆ
    func getTimestampedText(from transcription: [TranscriptionResult]) -> String {
        guard timestampsEnabled, !transcription.isEmpty else {
            let mainText = transcription.first?.text ?? ""
            return postProcessTranscriptionResult(mainText)
       }
        
        let result = transcription.first!
        var timestampedText = ""
        
        for segment in result.segments {
            let startTime = formatTimestamp(Double(segment.start))
            let endTime = formatTimestamp(Double(segment.end))
            let rawText = segment.text.trimmingCharacters(in: .whitespacesAndNewlines)
            let cleanedText = postProcessTranscriptionResult(rawText)
            
            if !cleanedText.isEmpty {
                timestampedText += "[\(startTime) - \(endTime)] \(cleanedText)\n"
           }
       }
        
        return timestampedText.trimmingCharacters(in: .whitespacesAndNewlines)
   }
    
    /// ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆç§’ â†’ mm:ss.SSSï¼‰
    func formatTimestamp(_ seconds: Double) -> String {
        let totalSeconds = Int(seconds)
        let minutes = totalSeconds / 60
        let remainingSeconds = totalSeconds % 60
        let milliseconds = Int((seconds - Double(totalSeconds)) * 1000)
        
        return String(format: "%02d:%02d.%03d", minutes, remainingSeconds, milliseconds)
   }
    
    /// ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãªã—ãƒ†ã‚­ã‚¹ãƒˆã®å–å¾—
    func getPlainText(from transcription: [TranscriptionResult]) -> String {
        guard !transcription.isEmpty else { return ""}
        
        let result = transcription.first!
        let segments = result.segments.compactMap { segment -> String? in
            let rawText = segment.text.trimmingCharacters(in: .whitespacesAndNewlines)
            let cleanedText = postProcessTranscriptionResult(rawText)
            return cleanedText.isEmpty ? nil : cleanedText
       }
        
        return segments.joined(separator: " ")
   }
    
    /// ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
    func extractSegmentData(from transcription: [TranscriptionResult]) -> [TranscriptionSegment] {
        guard !transcription.isEmpty else { return []}
        
        let result = transcription.first!
        let segments = result.segments.compactMap { segment -> TranscriptionSegment? in
            let rawText = segment.text.trimmingCharacters(in: .whitespacesAndNewlines)
            let cleanedText = postProcessTranscriptionResult(rawText)
            
            // ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã«ç©ºã«ãªã£ãŸå ´åˆã¯é™¤å¤–
            guard !cleanedText.isEmpty else {
                if verboseLoggingEnabled { print("ğŸ” Segment filtered out: '\(rawText)' -> empty")
                return nil
           }
            
            return TranscriptionSegment(
                startTime: Double(segment.start),
                endTime: Double(segment.end),
                text: cleanedText
            )
       }
        
        if verboseLoggingEnabled { print("ğŸ“Š Extracted \(segments.count) segments with timestamps (after filtering)")
        return segments
   }
    
    /// ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’JSONæ–‡å­—åˆ—ã«å¤‰æ›
    func segmentsToJSON(_ segments: [TranscriptionSegment]) -> String? {
        do {
            let jsonData = try JSONEncoder().encode(segments)
            return String(data: jsonData, encoding: .utf8)
       } catch {
            if verboseLoggingEnabled { print("âŒ Failed to encode segments to JSON: \(error)")
            return nil
       }
   }
    
    /// JSONæ–‡å­—åˆ—ã‹ã‚‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
    func segmentsFromJSON(_ jsonString: String) -> [TranscriptionSegment] {
        guard let jsonData = jsonString.data(using: .utf8) else { return []}
        
        do {
            let segments = try JSONDecoder().decode([TranscriptionSegment].self, from: jsonData)
            return segments
       } catch {
            if verboseLoggingEnabled { print("âŒ Failed to decode segments from JSON: \(error)")
            return []
       }
   }
    
    /// ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è¨­å®šï¼ˆå¸¸æ™‚æœ‰åŠ¹ã®ãŸã‚è¨­å®šä¸è¦ï¼‰
    // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯å¸¸ã«ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜ã•ã‚Œã€è¡¨ç¤ºåˆ¶å¾¡ã¯åˆ¥é€”UIå±¤ã§è¡Œã†
    
    /// ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®šï¼ˆæœ¬ç•ªæœ€é©åŒ–æ¸ˆã¿ï¼‰
    // è©³ç´°ãƒ­ã‚°ã¯é–‹ç™ºæ™‚ã®ã¿å¿…è¦ã«å¿œã˜ã¦æœ‰åŠ¹åŒ–
    
    // MARK: - Progress Management
    
    /// æ–‡å­—èµ·ã“ã—é€²æ—ã®æ›´æ–°ï¼ˆæ™‚é–“äºˆæ¸¬å‰Šé™¤ï¼‰
    @MainActor
    private func updateTranscriptionProgress(_ progress: Float, stage: String) {
        self.transcriptionProgress = max(0.0, min(1.0, progress))
        self.transcriptionStage = stage
        
        if verboseLoggingEnabled { print("ğŸ“Š Progress: \(Int(progress * 100))% - \(stage)")
   }
    
    // å‡¦ç†æ™‚é–“æ¨å®šæ©Ÿèƒ½å‰Šé™¤ï¼ˆä¸æ­£ç¢ºãªãŸã‚ï¼‰
    
    /// é€²æ—ã®ãƒªã‚»ãƒƒãƒˆ
    @MainActor
    private func resetProgress() {
        self.transcriptionProgress = 0.0
        self.transcriptionStage = ""
        
        // å‰å›ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
        self.lastTranscriptionTimestamps = nil
        self.lastTranscriptionSegments = nil
   }
}


// MARK: - Data Structures

/// æ–‡å­—èµ·ã“ã—ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿
struct TranscriptionSegment: Codable, Identifiable {
    let id = UUID()
    let startTime: Double      // é–‹å§‹æ™‚é–“ï¼ˆç§’ï¼‰
    let endTime: Double        // çµ‚äº†æ™‚é–“ï¼ˆç§’ï¼‰
    let text: String          // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
    let confidence: Float?    // ä¿¡é ¼åº¦ï¼ˆå°†æ¥æ‹¡å¼µç”¨ï¼‰
    
    init(startTime: Double, endTime: Double, text: String, confidence: Float? = nil) {
        self.startTime = startTime
        self.endTime = endTime
        self.text = text
        self.confidence = confidence
   }
}

// MARK: - Error Types

enum WhisperKitTranscriptionError: LocalizedError {
    case notInitialized
    case initializationFailed(Error)
    case initializationTimeout
    case fileNotFound
    case transcriptionFailed(Error)
    case modelNotAvailable
    
    var errorDescription: String? {
        switch self {
        case .notInitialized:
            return "WhisperKitãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        case .initializationFailed(let error):
            return "WhisperKitåˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: \(error.localizedDescription)"
        case .initializationTimeout:
            return "WhisperKitåˆæœŸåŒ–ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰"
        case .fileNotFound:
            return "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        case .transcriptionFailed(let error):
            return "æ–‡å­—èµ·ã“ã—å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: \(error.localizedDescription)"
        case .modelNotAvailable:
            return "æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
       }
   }
}

