import Foundation
import WhisperKit
import AVFoundation
import CoreMedia

/// WhisperKit ãƒ¢ãƒ‡ãƒ«é¸æŠåˆ—æŒ™å‹
enum WhisperKitModel: String, CaseIterable {
    case tiny = "tiny"
    case base = "base"
    case small = "small"
    case medium = "medium"
    case large = "large-v3"
    
    var displayName: String {
        switch self {
        case .tiny: return "Tiny (43MB) - é«˜é€Ÿ"
        case .base: return "Base (145MB) - ãƒãƒ©ãƒ³ã‚¹"
        case .small: return "Small (~500MB) - é«˜ç²¾åº¦"
        case .medium: return "Medium (~1GB) - éå¸¸ã«é«˜ç²¾åº¦"
        case .large: return "Large-v3 (1.5GB) - æœ€é«˜ç²¾åº¦"
        }
    }
    
    var description: String {
        switch self {
        case .tiny: return "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†å‘ã‘ã€æœ€é«˜é€Ÿåº¦"
        case .base: return "é€Ÿåº¦ã¨ç²¾åº¦ã®ãƒãƒ©ãƒ³ã‚¹ã€æ¨å¥¨è¨­å®š"
        case .small: return "ã‚ˆã‚Šé«˜ã„ç²¾åº¦ã€ä¸­ç¨‹åº¦ã®é€Ÿåº¦"
        case .medium: return "éå¸¸ã«é«˜ç²¾åº¦ã€å‡¦ç†æ™‚é–“é•·ã‚"
        case .large: return "æœ€é«˜ç²¾åº¦ã€å°‚é–€ç”¨é€”ã€å‡¦ç†æ™‚é–“æœ€é•·"
        }
    }
    
    // å°†æ¥ã®ãƒ¢ãƒ‡ãƒ«å¤‰æ›´æ©Ÿèƒ½ã®ãŸã‚ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
    // ç¾åœ¨ã¯baseãƒ¢ãƒ‡ãƒ«å›ºå®š
}

/// WhisperKitã‚’ä½¿ç”¨ã—ãŸé«˜ç²¾åº¦æ–‡å­—èµ·ã“ã—ã‚µãƒ¼ãƒ“ã‚¹
/// Apple Speech Frameworkã«ä»£ã‚ã‚‹ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ»é«˜ç²¾åº¦ãªéŸ³å£°èªè­˜å®Ÿè£…
class WhisperKitTranscriptionService: ObservableObject {
    
    // MARK: - Published Properties
    
    /// æ–‡å­—èµ·ã“ã—çµæœ
    @Published var transcriptionText: String = ""
    
    /// å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°
    @Published var isTranscribing: Bool = false
    
    /// ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    @Published var errorMessage: String?
    
    /// å‡¦ç†æ™‚é–“ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    @Published var processingTime: TimeInterval = 0.0
    
    /// åˆæœŸåŒ–çŠ¶æ…‹
    @Published var isInitialized: Bool = false
    
    /// ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«
    @Published var selectedModel: WhisperKitModel = .base
    
    /// ä½¿ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§
    @Published var availableModels: [WhisperKitModel] = WhisperKitModel.allCases
    
    // MARK: - Private Properties
    
    /// WhisperKitã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    private var whisperKit: WhisperKit?
    
    /// åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼
    private var initializationError: Error?
    
    // MARK: - Singleton
    
    static let shared = WhisperKitTranscriptionService()
    
    private init() {
        Task {
            await initializeWhisperKit()
        }
    }
    
    // MARK: - Initialization
    
    /// WhisperKitã‚’éåŒæœŸã§åˆæœŸåŒ–
    @MainActor
    private func initializeWhisperKit() async {
        print("ğŸ—£ï¸ Initializing WhisperKit...")
        
        do {
            // é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§WhisperKitã‚’åˆæœŸåŒ–
            print("ğŸ”§ Initializing WhisperKit with model: \(selectedModel.rawValue)")
            
            // WhisperKitConfigã§ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã—ã¦åˆæœŸåŒ–
            let config = WhisperKitConfig(model: selectedModel.rawValue)
            whisperKit = try await WhisperKit(config)
            isInitialized = true
            initializationError = nil
            
            print("âœ… WhisperKit initialized successfully with \(selectedModel.displayName)")
            
        } catch {
            print("âŒ Failed to initialize WhisperKit with model \(selectedModel.rawValue): \(error)")
            initializationError = error
            isInitialized = false
            errorMessage = "éŸ³å£°èªè­˜ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ (\(selectedModel.displayName)): \(error.localizedDescription)"
        }
    }
    
    // MARK: - Transcription
    
    /// éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—
    /// - Parameter audioURL: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®URL
    func transcribeAudioFile(at audioURL: URL) async throws {
        print("ğŸ—£ï¸ Starting WhisperKit transcription for file: \(audioURL.lastPathComponent)")
        
        await MainActor.run {
            isTranscribing = true
            transcriptionText = ""
            errorMessage = nil
            processingTime = 0.0
        }
        
        let startTime = Date()
        
        // åˆæœŸåŒ–ãƒã‚§ãƒƒã‚¯
        guard isInitialized, let whisperKit = whisperKit else {
            if let error = initializationError {
                throw WhisperKitTranscriptionError.initializationFailed(error)
            } else {
                throw WhisperKitTranscriptionError.notInitialized
            }
        }
        
        // ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        guard FileManager.default.fileExists(atPath: audioURL.path) else {
            throw WhisperKitTranscriptionError.fileNotFound
        }
        
        do {
            // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
            let audioFileInfo = try await getAudioFileInfo(url: audioURL)
            print("ğŸµ Audio file info: duration=\(audioFileInfo.duration)s, format=\(audioFileInfo.format)")
            
            // WhisperKitã§æ–‡å­—èµ·ã“ã—å®Ÿè¡Œï¼ˆæ—¥æœ¬èªæœ€é©åŒ–è¨­å®šï¼‰
            print("ğŸ¯ Starting WhisperKit transcription with Japanese optimization")
            
            // æ—¥æœ¬èªç‰¹åŒ–ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
            let transcription = try await whisperKit.transcribe(
                audioPath: audioURL.path,
                decodeOptions: DecodingOptions(
                    verbose: true,
                    task: .transcribe,
                    language: "ja",  // æ—¥æœ¬èªã‚³ãƒ¼ãƒ‰ "japanese" ã‹ã‚‰ "ja" ã«å¤‰æ›´
                    temperature: 0.0,
                    temperatureIncrementOnFallback: 0.2,
                    temperatureFallbackCount: 5,
                    sampleLength: 224,
                    usePrefillPrompt: true,
                    usePrefillCache: true,
                    skipSpecialTokens: true,
                    withoutTimestamps: false  // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æœ‰åŠ¹åŒ–ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                )
            )
            
            let endTime = Date()
            let duration = endTime.timeIntervalSince(startTime)
            
            // çµæœã®å–å¾—ã¨è©³ç´°ãƒ‡ãƒãƒƒã‚°
            print("ğŸ” Transcription results count: \(transcription.count)")
            
            let resultText: String
            if !transcription.isEmpty {
                for (index, result) in transcription.enumerated() {
                    print("ğŸ” Result \(index): '\(result.text)' (length: \(result.text.count))")
                    print("ğŸ” Result \(index) segments count: \(result.segments.count)")
                    
                    // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã”ã¨ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¢ºèª
                    for (segIndex, segment) in result.segments.enumerated() {
                        print("ğŸ” Segment \(segIndex): '\(segment.text)' (start: \(segment.start), end: \(segment.end))")
                    }
                }
                
                // æœ€åˆã®çµæœã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨
                let mainText = transcription.first?.text ?? ""
                
                // ç©ºã®å ´åˆã€å…¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
                if mainText.isEmpty {
                    print("ğŸ”§ Main text is empty, trying to merge segments...")
                    let allSegmentTexts = transcription.flatMap { $0.segments }.map { $0.text }
                    resultText = allSegmentTexts.joined(separator: " ")
                    print("ğŸ”§ Merged segment text: '\(resultText)'")
                } else {
                    resultText = mainText
                }
            } else {
                print("âŒ No transcription results returned")
                resultText = ""
            }
            
            await MainActor.run {
                self.transcriptionText = resultText
                self.processingTime = duration
                self.isTranscribing = false
            }
            
            print("âœ… WhisperKit transcription completed in \(String(format: "%.2f", duration))s")
            print("ğŸ“ Result: '\(resultText)' (\(resultText.count) characters)")
            
        } catch {
            let endTime = Date()
            let duration = endTime.timeIntervalSince(startTime)
            
            print("âŒ WhisperKit transcription failed after \(String(format: "%.2f", duration))s: \(error)")
            
            await MainActor.run {
                self.errorMessage = error.localizedDescription
                self.isTranscribing = false
            }
            
            throw WhisperKitTranscriptionError.transcriptionFailed(error)
        }
    }
    
    // MARK: - Helper Methods
    
    /// éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
    private func getAudioFileInfo(url: URL) async throws -> (duration: TimeInterval, format: String) {
        let asset = AVURLAsset(url: url)
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã®åŸºæœ¬æƒ…å ±ã‚’éåŒæœŸã§å–å¾—
        let duration = try await asset.load(.duration)
        let durationSeconds = CMTimeGetSeconds(duration)
        
        // ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼æƒ…å ±ã‚’å–å¾—
        let tracks = try await asset.loadTracks(withMediaType: .audio)
        let timeScale = try await tracks.first?.load(.naturalTimeScale) ?? 44100
        let format = timeScale.description
        
        return (duration: durationSeconds, format: format)
    }
    
    /// å®Ÿè¡Œä¸­ã®æ–‡å­—èµ·ã“ã—ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
    func cancelTranscription() {
        // WhisperKitã§ã¯ç¾åœ¨ã‚­ãƒ£ãƒ³ã‚»ãƒ«æ©Ÿèƒ½ã¯åˆ¶é™çš„
        // ã‚¿ã‚¹ã‚¯ã®å®Œäº†ã‚’å¾…ã¤ã‹ã€æ–°ã—ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§å¯¾å¿œ
        
        DispatchQueue.main.async {
            self.isTranscribing = false
            self.errorMessage = "æ–‡å­—èµ·ã“ã—ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ"
        }
        
        print("â¹ï¸ WhisperKit transcription cancelled")
    }
    
    /// å†åˆæœŸåŒ–ï¼ˆã‚¨ãƒ©ãƒ¼å›å¾©ç”¨ï¼‰
    func reinitialize() async {
        await MainActor.run {
            self.isInitialized = false
            self.whisperKit = nil
        }
        
        await initializeWhisperKit()
    }
    
    /// ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›´ã—ã¦å†åˆæœŸåŒ–
    func changeModel(to model: WhisperKitModel) async {
        print("ğŸ”„ Changing model from \(selectedModel.rawValue) to \(model.rawValue)")
        
        await MainActor.run {
            self.selectedModel = model
            self.isInitialized = false
            self.whisperKit = nil
            self.transcriptionText = ""
            self.errorMessage = nil
        }
        
        await initializeWhisperKit()
    }
}


// MARK: - Error Types

enum WhisperKitTranscriptionError: LocalizedError {
    case notInitialized
    case initializationFailed(Error)
    case fileNotFound
    case transcriptionFailed(Error)
    case modelNotAvailable
    
    var errorDescription: String? {
        switch self {
        case .notInitialized:
            return "WhisperKitãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        case .initializationFailed(let error):
            return "WhisperKitåˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: \(error.localizedDescription)"
        case .fileNotFound:
            return "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        case .transcriptionFailed(let error):
            return "æ–‡å­—èµ·ã“ã—å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: \(error.localizedDescription)"
        case .modelNotAvailable:
            return "æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
        }
    }
}