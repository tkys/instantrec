
import Foundation
import AVFoundation
import UIKit

/// éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰å®šç¾©
enum RecordingMode: String, CaseIterable {
    case conversation = "conversation"     // ä¼šè©±ç‰¹åŒ–
    case ambient = "ambient"              // ç’°å¢ƒéŸ³å…¨ä½“
    case voiceOver = "voiceOver"          // ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŒ²éŸ³
    case meeting = "meeting"              // ä¼šè­°éŒ²éŸ³
    case balanced = "balanced"            // ãƒãƒ©ãƒ³ã‚¹å‹
    
    var displayName: String {
        switch self {
        case .conversation: return "ä¼šè©±ãƒ¢ãƒ¼ãƒ‰"
        case .ambient: return "ç’°å¢ƒéŸ³ãƒ¢ãƒ¼ãƒ‰"
        case .voiceOver: return "ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰"
        case .meeting: return "ä¼šè­°ãƒ¢ãƒ¼ãƒ‰"
        case .balanced: return "ãƒãƒ©ãƒ³ã‚¹ãƒ¢ãƒ¼ãƒ‰"
        }
    }
    
    var audioSessionMode: AVAudioSession.Mode {
        switch self {
        case .conversation: return .voiceChat
        case .ambient: return .default
        case .voiceOver: return .measurement
        case .meeting: return .videoRecording
        case .balanced: return .default
        }
    }
    
    var description: String {
        switch self {
        case .conversation: return "äººã®å£°ã‚’æ˜ç­ã«éŒ²éŸ³ã€èƒŒæ™¯ãƒã‚¤ã‚ºæŠ‘åˆ¶"
        case .ambient: return "ã™ã¹ã¦ã®éŸ³ã‚’å¿ å®Ÿã«éŒ²éŸ³ã€è‡ªç„¶ãªéŸ³éŸ¿"
        case .voiceOver: return "é«˜å“è³ªãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŒ²éŸ³ã€ãƒã‚¤ã‚ºæœ€å°åŒ–"
        case .meeting: return "è¤‡æ•°è©±è€…å¯¾å¿œã€ä¼šè­°å®¤éŸ³éŸ¿æœ€é©åŒ–"
        case .balanced: return "éŸ³å£°ã¨ç’°å¢ƒéŸ³ã®ä¸¡ç«‹ã€æ±ç”¨çš„"
        }
    }
}

class AudioService: ObservableObject {
    var audioRecorder: AVAudioRecorder?
    var audioPlayer: AVAudioPlayer?
    @Published var permissionGranted = false
    @Published var audioLevel: Float = 0.0
    
    // ãƒ­ã‚°å‡ºåŠ›åˆ¶å¾¡ç”¨ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    private var adaptiveGainLogCount = 0
    
    // ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
    private let memoryMonitor = MemoryMonitorService.shared
    
    // ãƒ‡ãƒãƒƒã‚°ç”¨: éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’ç›´æ¥è¨­å®š
    func setTestAudioLevel(_ level: Float) {
        DispatchQueue.main.async {
            self.audioLevel = max(0.0, min(1.0, level))
        }
    }
    
    // ãƒ‡ãƒãƒƒã‚°ç”¨: AudioEngineéŒ²éŸ³æ™‚ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆéŸ³å£°ãƒ¬ãƒ™ãƒ«
    private var simulatedAudioTimer: Timer?
    
    func startSimulatedAudioForTesting() {
        stopSimulatedAudioForTesting()
        
        simulatedAudioTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            guard let self = self, self.isEngineRecording else { return }
            
            // ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆéŸ³å£°ãƒ¬ãƒ™ãƒ«ï¼ˆå®Ÿéš›ã®ãƒã‚¤ã‚¯ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            let simulatedLevel = Float.random(in: 0.1...0.8)
            DispatchQueue.main.async {
                self.audioLevel = simulatedLevel
                print("ğŸ§ª Simulated AudioEngine level: \(String(format: "%.3f", simulatedLevel))")
            }
        }
        
        print("ğŸ§ª Started simulated audio for AudioEngine testing")
    }
    
    func stopSimulatedAudioForTesting() {
        simulatedAudioTimer?.invalidate()
        simulatedAudioTimer = nil
    }
    
    /// ãƒã‚¤ã‚¯å…¥åŠ›ã®å¼·åˆ¶ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³
    private func forceMicrophoneActivation() throws {
        guard let inputNode = inputNode else {
            throw NSError(domain: "AudioService", code: -4, userInfo: [NSLocalizedDescriptionKey: "Input node not available"])
        }
        
        print("ğŸ¤ Forcing microphone activation...")
        
        // inputNodeã®å…¥åŠ›ã‚’æœ‰åŠ¹åŒ–
        let inputFormat = inputNode.inputFormat(forBus: 0)
        
        // ä¸€æ™‚çš„ãªTapã‚’è¨­å®šã—ã¦ãƒã‚¤ã‚¯å…¥åŠ›ã‚’æ´»æ€§åŒ–
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: inputFormat) { _, _ in
            // ä½•ã‚‚ã—ãªã„ï¼ˆã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ç›®çš„ã®ã¿ï¼‰
        }
        
        // çŸ­æ™‚é–“å¾…æ©Ÿã—ã¦ã‹ã‚‰Tapã‚’å‰Šé™¤
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) {
            inputNode.removeTap(onBus: 0)
            print("ğŸ¤ Microphone activation tap removed")
        }
        
        print("ğŸ¤ Microphone activation initiated")
    }
    @Published var isBackgroundRecordingEnabled = false
    
    // AVAudioEngineé–¢é€£
    private var audioEngine: AVAudioEngine?
    private var inputNode: AVAudioInputNode?
    private var voiceIsolationNode: AVAudioUnitEQ?
    private var recordingFile: AVAudioFile?
    private var isEngineRecording = false
    @Published var voiceIsolationEnabled = false  // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç„¡åŠ¹ï¼ˆEQã«ã‚ˆã‚‹éŸ³å£°é™¤å»å•é¡Œã®ãŸã‚ï¼‰
    @Published var noiseReductionLevel: Float = 0.6
    
    // ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ç®¡ç†
    private var backgroundTaskID: UIBackgroundTaskIdentifier = .invalid
    
    // éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚¿ã‚¤ãƒãƒ¼
    private var levelTimer: Timer?
    
    // ãƒ‡ãƒãƒƒã‚°ç”¨ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    private var audioLevelUpdateCounter: Int = 0
    private var bufferCounter: Int = 0
    private var amplificationLogCount: Int = 0
    
    init() {
        // åˆæœŸåŒ–æ™‚ã¯AudioSessionè¨­å®šã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰
        setupAudioSessionInterruptionHandling()
        setupAudioEngine()
    }
    
    // MARK: - AVAudioEngine Setup
    
    /// AVAudioEngineã¨Voice Isolationã®åˆæœŸåŒ–
    private func setupAudioEngine() {
        print("ğŸ›ï¸ Setting up AVAudioEngine with Voice Isolation")
        
        audioEngine = AVAudioEngine()
        
        guard let engine = audioEngine else {
            print("âŒ Failed to create AVAudioEngine")
            return
        }
        
        inputNode = engine.inputNode
        print("ğŸ›ï¸ AudioEngine input node: \(String(describing: inputNode))")
        
        // inputNodeã®åˆæœŸãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ç¢ºèª
        if let inputNode = inputNode {
            let initialInputFormat = inputNode.inputFormat(forBus: 0)
            print("ğŸ›ï¸ Initial input format: \(initialInputFormat)")
        }
        
        // Voice Isolationç”¨EQãƒãƒ¼ãƒ‰ã‚’ä½œæˆ
        setupVoiceIsolationNode()
        
        print("âœ… AVAudioEngine setup completed")
    }
    
    /// Voice Isolationç”¨ã®EQãƒãƒ¼ãƒ‰ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    private func setupVoiceIsolationNode() {
        guard let engine = audioEngine else { return }
        
        // EQãƒãƒ¼ãƒ‰ã‚’ä½œæˆï¼ˆVoice Isolationã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        voiceIsolationNode = AVAudioUnitEQ(numberOfBands: 10)
        
        guard let eqNode = voiceIsolationNode else {
            print("âŒ Failed to create EQ node for voice isolation")
            return
        }
        
        // éŸ³å£°å‘¨æ³¢æ•°å¸¯åŸŸï¼ˆ300Hz-3400Hzï¼‰ã®å¼·èª¿è¨­å®š
        configureVoiceIsolationEQ(eqNode)
        
        // ãƒãƒ¼ãƒ‰ã‚’ã‚¨ãƒ³ã‚¸ãƒ³ã«è¿½åŠ 
        engine.attach(eqNode)
        
        print("âœ… Voice Isolation EQ node configured")
    }
    
    /// Voice Isolation EQã®è¨­å®š
    private func configureVoiceIsolationEQ(_ eqNode: AVAudioUnitEQ) {
        let bands = eqNode.bands
        
        // 10ãƒãƒ³ãƒ‰EQã§éŸ³å£°å¼·èª¿è¨­å®š
        for (index, band) in bands.enumerated() {
            switch index {
            case 0: // 60Hz - ä½å‘¨æ³¢ãƒã‚¤ã‚ºã‚«ãƒƒãƒˆ
                band.frequency = 60
                band.gain = -12
                band.bandwidth = 1.0
                band.filterType = .highPass
                
            case 1: // 120Hz - ä½å‘¨æ³¢ãƒã‚¤ã‚ºã‚«ãƒƒãƒˆ
                band.frequency = 120
                band.gain = -8
                band.bandwidth = 1.0
                band.filterType = .bandPass
                
            case 2: // 250Hz - éŸ³å£°å¸¯åŸŸå‰ã®èª¿æ•´
                band.frequency = 250
                band.gain = 2
                band.bandwidth = 1.0
                band.filterType = .bandPass
                
            case 3: // 500Hz - åŸºæœ¬éŸ³å£°å‘¨æ³¢æ•°å¼·èª¿
                band.frequency = 500
                band.gain = 4
                band.bandwidth = 1.0
                band.filterType = .bandPass
                
            case 4: // 1kHz - ä¸»è¦éŸ³å£°å‘¨æ³¢æ•°å¼·èª¿
                band.frequency = 1000
                band.gain = 6
                band.bandwidth = 1.0
                band.filterType = .bandPass
                
            case 5: // 2kHz - å­éŸ³ã®æ˜ç­ã•å‘ä¸Š
                band.frequency = 2000
                band.gain = 5
                band.bandwidth = 1.0
                band.filterType = .bandPass
                
            case 6: // 3kHz - éŸ³å£°æ˜ç­åº¦å‘ä¸Š
                band.frequency = 3000
                band.gain = 3
                band.bandwidth = 1.0
                band.filterType = .bandPass
                
            case 7: // 4kHz - é«˜å‘¨æ³¢éŸ³å£°èª¿æ•´
                band.frequency = 4000
                band.gain = 1
                band.bandwidth = 1.0
                band.filterType = .bandPass
                
            case 8: // 8kHz - ä¸è¦ãªé«˜å‘¨æ³¢ã‚«ãƒƒãƒˆ
                band.frequency = 8000
                band.gain = -6
                band.bandwidth = 1.0
                band.filterType = .bandPass
                
            case 9: // 16kHz - é«˜å‘¨æ³¢ãƒã‚¤ã‚ºã‚«ãƒƒãƒˆ
                band.frequency = 16000
                band.gain = -15
                band.bandwidth = 1.0
                band.filterType = .lowPass
                
            default:
                break
            }
            
            band.bypass = !voiceIsolationEnabled
        }
        
        print("ğŸšï¸ Voice Isolation EQ configured with \(bands.count) bands")
    }
    
    /// Voice Isolationã®æœ‰åŠ¹/ç„¡åŠ¹åˆ‡ã‚Šæ›¿ãˆ
    func toggleVoiceIsolation(_ enabled: Bool) {
        voiceIsolationEnabled = enabled
        
        guard let eqNode = voiceIsolationNode else { return }
        
        for band in eqNode.bands {
            band.bypass = !enabled
        }
        
        print("ğŸšï¸ Voice Isolation \(enabled ? "enabled" : "disabled")")
    }
    
    /// ãƒã‚¤ã‚ºãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒ¬ãƒ™ãƒ«ã®èª¿æ•´
    func setNoiseReductionLevel(_ level: Float) {
        noiseReductionLevel = max(0.0, min(1.0, level))
        
        guard let eqNode = voiceIsolationNode else { return }
        
        // ãƒã‚¤ã‚ºãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ã¦EQã®ã‚²ã‚¤ãƒ³ã‚’èª¿æ•´
        let multiplier = noiseReductionLevel
        
        for (index, band) in eqNode.bands.enumerated() {
            switch index {
            case 0, 1: // ä½å‘¨æ³¢ãƒã‚¤ã‚ºã‚«ãƒƒãƒˆå¼·åº¦èª¿æ•´
                band.gain = -12 * multiplier
            case 8, 9: // é«˜å‘¨æ³¢ãƒã‚¤ã‚ºã‚«ãƒƒãƒˆå¼·åº¦èª¿æ•´
                band.gain = -15 * multiplier
            default:
                // éŸ³å£°å¸¯åŸŸã¯èª¿æ•´ã—ãªã„
                break
            }
        }
        
        print("ğŸšï¸ Noise reduction level set to: \(String(format: "%.2f", noiseReductionLevel))")
    }
    
    private func setupAudioSessionOnDemand(recordingMode: RecordingMode = .balanced) {
        let session = AVAudioSession.sharedInstance()
        do {
            print("ğŸ”Š Setting up audio session for mode: \(recordingMode.displayName)")
            
            // æ—¢å­˜ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’éã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«ã™ã‚‹ï¼ˆè¨­å®šå¤‰æ›´ã®ãŸã‚ï¼‰
            if session.isOtherAudioPlaying {
                try session.setActive(false, options: .notifyOthersOnDeactivation)
            }
            
            // ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šï¼ˆéŒ²éŸ³å°‚ç”¨ã«æœ€é©åŒ–ï¼‰
            let sessionMode = recordingMode.audioSessionMode
            var options: AVAudioSession.CategoryOptions = [
                .allowBluetooth,
                .duckOthers,
                .interruptSpokenAudioAndMixWithOthers
            ]
            
            // éŒ²éŸ³æ™‚ã¯.defaultToSpeakerã‚’ä½¿ç”¨ã—ãªã„ï¼ˆãƒã‚¤ã‚¯å„ªå…ˆã®ãŸã‚ï¼‰
            
            // éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®è¿½åŠ ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            switch recordingMode {
            case .conversation, .meeting:
                // éŸ³å£°é€šè©±æœ€é©åŒ–
                options.insert(.allowBluetoothA2DP)
            case .ambient:
                // ç’°å¢ƒéŸ³éŒ²éŸ³ã§ã¯å¤–éƒ¨ãƒã‚¤ã‚¯ã‚’å„ªå…ˆ
                options.insert(.allowAirPlay)
            case .voiceOver:
                // ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŒ²éŸ³ã§ã¯é«˜å“è³ªè¨­å®š
                options.insert(.overrideMutedMicrophoneInterruption)
            case .balanced:
                // ãƒãƒ©ãƒ³ã‚¹ãƒ¢ãƒ¼ãƒ‰ - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨
                break
            }
            
            try session.setCategory(.playAndRecord, mode: sessionMode, options: options)
            print("ğŸ”Š Audio session configured: category=\(session.category), mode=\(sessionMode)")
            
            // WhisperKitæœ€é©åŒ–ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã¨å“è³ªè¨­å®š
            try session.setPreferredSampleRate(16000.0) // WhisperKitæ¨å¥¨ï¼š16kHz
            try session.setPreferredIOBufferDuration(0.010) // 10ms bufferï¼ˆ16kHzã«æœ€é©åŒ–ï¼‰
            
            // ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã®ç¢ºèªã¨è¦æ±‚ï¼ˆiOS17+å¯¾å¿œï¼‰
            if #available(iOS 17.0, *) {
                let currentPermission = AVAudioApplication.shared.recordPermission
                print("ğŸ¤ Current record permission: \(currentPermission.rawValue)")
                
                if currentPermission == .denied {
                    print("âŒ Record permission denied - user must enable in Settings")
                    throw NSError(domain: "AudioService", code: -1, userInfo: [NSLocalizedDescriptionKey: "Microphone permission denied"])
                }
            } else {
                let currentPermission = session.recordPermission
                print("ğŸ¤ Current record permission: \(currentPermission.rawValue)")
                
                if currentPermission == .denied {
                    print("âŒ Record permission denied - user must enable in Settings")
                    throw NSError(domain: "AudioService", code: -1, userInfo: [NSLocalizedDescriptionKey: "Microphone permission denied"])
                }
            }
            
            // æŒ‡å‘æ€§ãƒã‚¤ã‚¯è¨­å®šï¼ˆå¯¾å¿œãƒ‡ãƒã‚¤ã‚¹ã®ã¿ï¼‰
            configureDirectionalMicrophone(for: recordingMode, session: session)
            
            try session.setActive(true)
            print("ğŸ”Š Audio session activated successfully")
            print("ğŸ”Š Actual sample rate: \(session.sampleRate)")
            print("ğŸ”Š Actual IO buffer duration: \(session.ioBufferDuration)")
            
            // ãƒã‚¤ã‚¯ã‚²ã‚¤ãƒ³è¨­å®šï¼ˆãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ã§ã®éŸ³é‡å‘ä¸Šï¼‰
            if session.isInputGainSettable {
                let targetGain: Float = 0.8 // 80%ã®ã‚²ã‚¤ãƒ³ï¼ˆæœ€å¤§éŸ³é‡ã®80%ï¼‰
                try session.setInputGain(targetGain)
                print("ğŸ”Š Input gain set to: \(targetGain) (was: \(session.inputGain))")
            } else {
                print("ğŸ”Š Input gain not settable on this device")
            }
            
            // è¿½åŠ ã®çŠ¶æ…‹ç¢ºèª
            print("ğŸ”Š Input available: \(session.isInputAvailable)")
            print("ğŸ”Š Input gain settable: \(session.isInputGainSettable)")
            if let inputDataSource = session.inputDataSource {
                print("ğŸ”Š Input data source: \(inputDataSource)")
            }
            
        } catch {
            print("âŒ Failed to set up audio session: \(error.localizedDescription)")
            
            // ã‚ˆã‚Šè©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±
            if let nsError = error as NSError? {
                print("âŒ Error domain: \(nsError.domain)")
                print("âŒ Error code: \(nsError.code)")
                print("âŒ Error info: \(nsError.userInfo)")
            }
        }
    }
    
    func requestMicrophonePermission() async -> Bool {
        // æ—¢ã«æ¨©é™ãŒåˆ¤æ˜ã—ã¦ã„ã‚‹å ´åˆã¯ã€éåŒæœŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—
        if #available(iOS 17.0, *) {
            let currentStatus = AVAudioApplication.shared.recordPermission
            
            switch currentStatus {
            case .granted:
                permissionGranted = true
                return true
            case .denied:
                permissionGranted = false
                return false
            case .undetermined:
                // æœªæ±ºå®šã®å ´åˆã®ã¿éåŒæœŸã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
                return await withCheckedContinuation { continuation in
                    AVAudioApplication.requestRecordPermission { granted in
                        DispatchQueue.main.async {
                            self.permissionGranted = granted
                            continuation.resume(returning: granted)
                        }
                    }
                }
            @unknown default:
                permissionGranted = false
                return false
            }
        } else {
            let currentStatus = AVAudioSession.sharedInstance().recordPermission
            
            switch currentStatus {
            case .granted:
                permissionGranted = true
                return true
            case .denied:
                permissionGranted = false
                return false
            case .undetermined:
                // æœªæ±ºå®šã®å ´åˆã®ã¿éåŒæœŸã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
                return await withCheckedContinuation { continuation in
                    AVAudioSession.sharedInstance().requestRecordPermission { granted in
                        DispatchQueue.main.async {
                            self.permissionGranted = granted
                            continuation.resume(returning: granted)
                        }
                    }
                }
            @unknown default:
                permissionGranted = false
                return false
            }
        }
    }

    // MARK: - Enhanced Recording with Error Handling
    
    func startRecording(fileName: String) -> URL? {
        do {
            return try startRecordingWithErrorHandling(fileName: fileName)
        } catch {
            print("âŒ Recording failed: \(error.localizedDescription)")
            // ã‚¨ãƒ©ãƒ¼é€šçŸ¥ã‚’ãƒã‚¹ãƒˆ
            NotificationCenter.default.post(
                name: .audioServiceRecordingError,
                object: self,
                userInfo: ["error": error]
            )
            return nil
        }
    }
    
    private func startRecordingWithErrorHandling(fileName: String) throws -> URL {
        // Pre-flight checks with specific error types
        guard permissionGranted else {
            throw AudioServiceError.permissionDenied
        }
        
        guard !isRecording else {
            throw AudioServiceError.recordingInProgress
        }
        
        // AudioSessionåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
        let session = AVAudioSession.sharedInstance()
        guard session.isInputAvailable else {
            throw AudioServiceError.microphoneNotAvailable
        }
        
        // ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã®è©³ç´°ãƒã‚§ãƒƒã‚¯
        let availableSpace = getAvailableDiskSpace()
        let requiredSpace: Int64 = 100 * 1024 * 1024 // 100MB minimum
        guard availableSpace >= requiredSpace else {
            throw AudioServiceError.diskSpaceInsufficient(
                available: availableSpace,
                required: requiredSpace
            )
        }
        
        let url = getDocumentsDirectory().appendingPathComponent(fileName)
        
        // Voice Isolationè¨­å®šã«åŸºã¥ãéŒ²éŸ³æ–¹å¼é¸æŠ
        if voiceIsolationEnabled {
            print("ğŸ›ï¸ Using AVAudioEngine with Voice Isolation")
            return try startEngineRecordingWithErrorHandling(url: url)
        } else {
            print("ğŸ™ï¸ Using Traditional Recording (Voice Isolation OFF)")
            return try startTraditionalRecordingWithErrorHandling(fileName: fileName, url: url)
        }
    }
    
    // MARK: - Error Handling Wrappers
    
    private func startEngineRecordingWithErrorHandling(url: URL) throws -> URL {
        guard let result = startEngineRecording(url: url) else {
            throw NSError(domain: "AudioService", code: 1, userInfo: [NSLocalizedDescriptionKey: "Failed to start engine recording"])
        }
        return result
    }
    
    private func startTraditionalRecordingWithErrorHandling(fileName: String, url: URL) throws -> URL {
        guard let result = startTraditionalRecording(fileName: fileName, url: url) else {
            throw NSError(domain: "AudioService", code: 2, userInfo: [NSLocalizedDescriptionKey: "Failed to start traditional recording"])
        }
        return result
    }
    
    // MARK: - AVAudioEngine Recording
    
    /// AVAudioEngineã‚’ä½¿ç”¨ã—ãŸé«˜å“è³ªéŒ²éŸ³
    private func startEngineRecording(url: URL, isLongRecording: Bool = false) -> URL? {
        // é•·æ™‚é–“éŒ²éŸ³ã®å ´åˆã¯å¼·åŒ–ç›£è¦–ã‚’é–‹å§‹
        if isLongRecording {
            memoryMonitor.startIntensiveMonitoring()
            print("ğŸ–¥ï¸ Intensive memory monitoring started for long recording")
        }
        
        guard let engine = audioEngine,
              let inputNode = inputNode,
              let eqNode = voiceIsolationNode else {
            print("âŒ AVAudioEngine not properly initialized")
            return startTraditionalRecording(fileName: url.lastPathComponent, url: url)
        }
        
        // ã‚¨ãƒ³ã‚¸ãƒ³ãŒå‹•ä½œä¸­ãªã‚‰åœæ­¢
        if engine.isRunning {
            print("ğŸ”„ AudioEngine is running, stopping first...")
            eqNode.removeTap(onBus: 0)
            engine.stop()
        }
        
        do {
            // æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤
            if FileManager.default.fileExists(atPath: url.path) {
                try FileManager.default.removeItem(at: url)
                print("ğŸ—‘ï¸ Existing file removed: \(url.lastPathComponent)")
            }
            
            // AudioSessionè¨­å®š - ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚’ç¢ºå®Ÿã«æœ‰åŠ¹åŒ–
            setupAudioSessionOnDemand()
            
            // ãƒã‚¤ã‚¯ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
            let session = AVAudioSession.sharedInstance()
            print("ğŸ¤ Microphone available: \(session.isInputAvailable)")
            print("ğŸ¤ Input gain settable: \(session.isInputGainSettable)")
            print("ğŸ¤ Current input gain: \(session.inputGain)")
            
            // æ¨©é™ã®æœ€çµ‚ç¢ºèªï¼ˆiOS17+å¯¾å¿œï¼‰
            if #available(iOS 17.0, *) {
                guard AVAudioApplication.shared.recordPermission == .granted else {
                    print("âŒ Record permission not granted at engine start")
                    throw NSError(domain: "AudioService", code: -2, userInfo: [NSLocalizedDescriptionKey: "Microphone access required for recording"])
                }
            } else {
                guard session.recordPermission == .granted else {
                    print("âŒ Record permission not granted at engine start")
                    throw NSError(domain: "AudioService", code: -2, userInfo: [NSLocalizedDescriptionKey: "Microphone access required for recording"])
                }
            }
            
            // ãƒã‚¤ã‚¯ãŒå®Ÿéš›ã«åˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
            guard session.isInputAvailable else {
                print("âŒ No input available at engine start")
                throw NSError(domain: "AudioService", code: -3, userInfo: [NSLocalizedDescriptionKey: "No microphone input available"])
            }
            
            // inputNodeã®å®Ÿéš›ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä½¿ç”¨ï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¸ä¸€è‡´ã‚’é˜²ãï¼‰
            let inputFormat = inputNode.inputFormat(forBus: 0)
            print("ğŸ” Using input format for recording: \(inputFormat)")
            print("ğŸ” Input format details: sampleRate=\(inputFormat.sampleRate), channels=\(inputFormat.channelCount), isInterleaved=\(inputFormat.isInterleaved)")
            
            // WhisperKitæœ€é©åŒ–è¨­å®šï¼ˆ16kHz Linear PCMï¼‰
            let recordingSettings: [String: Any] = [
                AVFormatIDKey: Int(kAudioFormatLinearPCM),  // éåœ§ç¸®PCMï¼ˆç¢ºå®Ÿï¼‰
                AVSampleRateKey: 16000.0,  // WhisperKitæ¨å¥¨
                AVNumberOfChannelsKey: 1,  // ãƒ¢ãƒãƒ©ãƒ«
                AVLinearPCMBitDepthKey: 16,  // 16bit
                AVLinearPCMIsBigEndianKey: false,
                AVLinearPCMIsFloatKey: false,
                AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
            ]
            
            print("ğŸµ AudioEngine recording settings: \(recordingSettings)")
            
            // éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆWhisperKitæœ€é©åŒ–è¨­å®šï¼‰
            recordingFile = try AVAudioFile(forWriting: url, settings: recordingSettings)
            
            // éŸ³å£°å‡¦ç†ãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰
            setupAudioProcessingChain(inputNode: inputNode, eqNode: eqNode, format: inputFormat)
            
            // ã‚¨ãƒ³ã‚¸ãƒ³é–‹å§‹è¨ºæ–­
            print("ğŸ™ï¸ AudioEngine recording diagnostics:")
            print("   - Engine running: \(engine.isRunning)")
            print("   - Input available: \(AVAudioSession.sharedInstance().isInputAvailable)")
            print("   - Recording file: \(url)")
            print("   - Input format: \(inputFormat)")
            
            // ã‚¨ãƒ³ã‚¸ãƒ³é–‹å§‹
            try engine.start()
            isEngineRecording = true
            
            print("   - Engine started: \(engine.isRunning)")
            print("   - Recording started: \(isEngineRecording)")
            
            // AudioEngineéŒ²éŸ³ã§ã‚‚éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚¿ã‚¤ãƒãƒ¼ã‚’é–‹å§‹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            startLevelTimer()
            
            // ãƒã‚¤ã‚¯å…¥åŠ›ã®åˆæœŸåŒ–ã‚’å¼·åˆ¶å®Ÿè¡Œ
            try forceMicrophoneActivation()
            
            // ãƒ†ã‚¹ãƒˆç’°å¢ƒï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼‰ã§ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯éŸ³å£°ãƒ¬ãƒ™ãƒ«ç”Ÿæˆ
            #if targetEnvironment(simulator)
            startSimulatedAudioForTesting()
            print("ğŸ§ª Running on simulator - started simulated audio levels")
            #endif
            
            print("ğŸ›ï¸ AVAudioEngine recording started with Voice Isolation")
            print("   - Sample Rate: \(inputFormat.sampleRate)Hz")
            print("   - Channels: \(inputFormat.channelCount)")
            print("   - Voice Isolation: \(voiceIsolationEnabled)")
            print("   - Noise Reduction: \(String(format: "%.2f", noiseReductionLevel))")
            print("ğŸšï¸ Audio level monitoring enabled for Engine recording")
            
            return url
            
        } catch {
            print("âŒ Failed to start AVAudioEngine recording: \(error)")
            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¾“æ¥ã®éŒ²éŸ³æ–¹å¼
            return startTraditionalRecording(fileName: url.lastPathComponent, url: url)
        }
    }
    
    /// éŸ³å£°å‡¦ç†ãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰
    private func setupAudioProcessingChain(inputNode: AVAudioInputNode, 
                                         eqNode: AVAudioUnitEQ, 
                                         format: AVAudioFormat) {
        guard let engine = audioEngine else { return }
        
        // inputNodeã®å®Ÿéš›ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å–å¾—
        let inputFormat = inputNode.inputFormat(forBus: 0)
        print("ğŸ” Input format: \(inputFormat)")
        print("ğŸ” Using unified input format for recording")
        
        // æ—¢å­˜ã®Tapã‚’ã‚¯ãƒªã‚¢ï¼ˆé‡è¦ï¼šã‚¯ãƒ©ãƒƒã‚·ãƒ¥é˜²æ­¢ï¼‰
        eqNode.removeTap(onBus: 0)
        
        // æ¥ç¶š: Input -> EQï¼ˆinputNodeã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä½¿ç”¨ï¼‰
        engine.connect(inputNode, to: eqNode, format: inputFormat)
        
        // éŒ²éŸ³ã‚¿ãƒƒãƒ—ã®è¨­å®šï¼ˆéŸ³å£°å¢—å¹…æ©Ÿèƒ½ä»˜ãï¼‰
        eqNode.installTap(onBus: 0, bufferSize: 4096, format: inputFormat) { [weak self] buffer, time in
            guard let self = self, let file = self.recordingFile else { 
                print("âš ï¸ Tap received but no self or recordingFile")
                return 
            }
            
            do {
                // éŸ³å£°ã‚’å‹•çš„ã«å¢—å¹…ã—ã¦ã‹ã‚‰æ›¸ãè¾¼ã¿ï¼ˆWhisperKitéŸ³æ¥½èª¤èªè­˜å¯¾ç­–ï¼‰
                let adaptiveGain = self.calculateAdaptiveGain(buffer)
                let amplifiedBuffer = self.amplifyAudioBuffer(buffer, gainFactor: adaptiveGain)
                try file.write(from: amplifiedBuffer)
                
                // å¢—å¹…åŠ¹æœã®ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼ˆæœ€åˆã®5å›ã®ã¿ï¼‰
                if self.amplificationLogCount < 5 {
                    self.amplificationLogCount += 1
                    print("ğŸ”Š Audio amplified \(self.amplificationLogCount)/5: gain=15.0x, frames=\(buffer.frameLength)")
                }
                
                // æœ€é©åŒ–ã•ã‚ŒãŸéŸ³å£°ãƒ¬ãƒ™ãƒ«å–å¾—ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ åˆ¶é™ã§è² è·è»½æ¸›ï¼‰
                self.audioLevelUpdateCounter += 1
                if self.audioLevelUpdateCounter >= 1024 { // ç´„23msé–“éš”ï¼ˆ44100Hz / 1024ï¼‰
                    self.audioLevelUpdateCounter = 0
                    DispatchQueue.main.async {
                        self.updateAudioLevelFromBuffer(buffer)
                    }
                }
            } catch {
                print("âŒ Failed to write audio buffer: \(error)")
            }
        }
        
        print("âœ… Audio tap installed successfully on EQ node")
        
        print("âœ… Audio processing chain configured")
    }
    
    /// é©å¿œçš„ã‚²ã‚¤ãƒ³è¨ˆç®—ï¼ˆéŸ³å£°ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ã¦å‹•çš„èª¿æ•´ï¼‰
    private func calculateAdaptiveGain(_ buffer: AVAudioPCMBuffer) -> Float {
        guard let floatChannelData = buffer.floatChannelData else {
            return 15.0 // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        }
        
        let frameLength = Int(buffer.frameLength)
        let channelCount = Int(buffer.format.channelCount)
        
        // RMSãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—
        var rmsSum: Float = 0.0
        var maxPeak: Float = 0.0
        var activeSamples = 0
        let silenceThreshold: Float = 0.001
        
        for channel in 0..<channelCount {
            let channelData = floatChannelData[channel]
            for frame in 0..<frameLength {
                let sample = abs(channelData[frame])
                rmsSum += sample * sample
                maxPeak = max(maxPeak, sample)
                
                if sample > silenceThreshold {
                    activeSamples += 1
                }
            }
        }
        
        let totalSamples = frameLength * channelCount
        let rmsLevel = totalSamples > 0 ? sqrt(rmsSum / Float(totalSamples)) : 0.0
        let activityRatio = totalSamples > 0 ? Float(activeSamples) / Float(totalSamples) : 0.0
        
        // é©å¿œçš„ã‚²ã‚¤ãƒ³è¨ˆç®—
        let baseGain: Float = 15.0
        let minGain: Float = 8.0
        let maxGain: Float = 25.0
        
        var adaptiveGain: Float
        
        if rmsLevel < 0.001 {
            // éå¸¸ã«ä½ã„ãƒ¬ãƒ™ãƒ« â†’ æœ€å¤§å¢—å¹…
            adaptiveGain = maxGain
        } else if rmsLevel < 0.005 {
            // ä½ã„ãƒ¬ãƒ™ãƒ« â†’ é«˜å¢—å¹…
            adaptiveGain = baseGain + (maxGain - baseGain) * (1.0 - rmsLevel / 0.005)
        } else if rmsLevel < 0.02 {
            // ä¸­ç¨‹åº¦ãƒ¬ãƒ™ãƒ« â†’ æ¨™æº–å¢—å¹…
            adaptiveGain = minGain + (baseGain - minGain) * (1.0 - (rmsLevel - 0.005) / 0.015)
        } else {
            // é«˜ã„ãƒ¬ãƒ™ãƒ« â†’ æœ€å°å¢—å¹…
            adaptiveGain = minGain
        }
        
        // ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ç‡ã«ã‚ˆã‚‹èª¿æ•´
        if activityRatio < 0.1 {
            // ç„¡éŸ³ãŒå¤šã„ â†’ ã•ã‚‰ã«å¢—å¹…
            adaptiveGain *= 1.3
        } else if activityRatio > 0.8 {
            // éŸ³å£°ãŒè±Šå¯Œ â†’ æŠ‘åˆ¶
            adaptiveGain *= 0.8
        }
        
        // ç¯„å›²åˆ¶é™
        adaptiveGain = max(minGain, min(maxGain, adaptiveGain))
        
        // è©³ç´°ãƒ­ã‚°ï¼ˆæœ€åˆã®æ•°å›ã®ã¿ï¼‰
        if adaptiveGainLogCount < 3 {
            print("ğŸ”Š Adaptive gain calculation:")
            print("   - RMS level: \(String(format: "%.4f", rmsLevel))")
            print("   - Peak level: \(String(format: "%.4f", maxPeak))")
            print("   - Activity ratio: \(String(format: "%.1f", activityRatio * 100))%")
            print("   - Calculated gain: \(String(format: "%.1f", adaptiveGain))")
            adaptiveGainLogCount += 1
        }
        
        return adaptiveGain
    }
    
    /// éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã®å¢—å¹…å‡¦ç†ï¼ˆæ­£è¦åŒ–æ©Ÿèƒ½ä»˜ãï¼‰
    private func amplifyAudioBuffer(_ buffer: AVAudioPCMBuffer, gainFactor: Float) -> AVAudioPCMBuffer {
        guard let floatChannelData = buffer.floatChannelData else {
            print("âš ï¸ Cannot amplify buffer - no float channel data")
            return buffer
        }
        
        // æ–°ã—ã„ãƒãƒƒãƒ•ã‚¡ã‚’ä½œæˆ
        guard let amplifiedBuffer = AVAudioPCMBuffer(pcmFormat: buffer.format, frameCapacity: buffer.frameCapacity) else {
            print("âš ï¸ Cannot create amplified buffer")
            return buffer
        }
        
        amplifiedBuffer.frameLength = buffer.frameLength
        
        // å„ãƒãƒ£ãƒ³ãƒãƒ«ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å¢—å¹…
        let frameLength = Int(buffer.frameLength)
        let channelCount = Int(buffer.format.channelCount)
        
        guard let amplifiedChannelData = amplifiedBuffer.floatChannelData else {
            return buffer
        }
        
        // æœ€å¤§éŸ³é‡ã‚’æ¤œå‡ºã—ã¦ã‹ã‚‰æ­£è¦åŒ–å¢—å¹…
        var maxPeak: Float = 0.0
        for channel in 0..<channelCount {
            let inputData = floatChannelData[channel]
            for frame in 0..<frameLength {
                maxPeak = max(maxPeak, abs(inputData[frame]))
            }
        }
        
        // æ­£è¦åŒ–ä¿‚æ•°ã‚’è¨ˆç®—ï¼ˆæœ€å¤§0.8ã¾ã§ä½¿ç”¨ã—ã¦ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°é˜²æ­¢ï¼‰
        let targetLevel: Float = 0.8
        let normalizedGain = maxPeak > 0.001 ? min(gainFactor, targetLevel / maxPeak) : gainFactor
        
        print("ğŸ”Š Audio amplification: original peak=\(String(format: "%.4f", maxPeak)), gain=\(String(format: "%.1f", normalizedGain)), target=\(targetLevel)")
        
        for channel in 0..<channelCount {
            let inputData = floatChannelData[channel]
            let outputData = amplifiedChannelData[channel]
            
            for frame in 0..<frameLength {
                let amplifiedValue = inputData[frame] * normalizedGain
                // ã‚½ãƒ•ãƒˆã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ï¼ˆtanhé–¢æ•°ã§è‡ªç„¶ãªæ­ªã¿ï¼‰
                outputData[frame] = tanh(amplifiedValue)
            }
        }
        
        return amplifiedBuffer
    }
    
    /// ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’å–å¾—
    private func updateAudioLevelFromBuffer(_ buffer: AVAudioPCMBuffer) {
        guard let floatChannelData = buffer.floatChannelData else { 
            print("âš ï¸ No float channel data in buffer")
            return 
        }
        
        let frameLength = Int(buffer.frameLength)
        guard frameLength > 0 else {
            print("âš ï¸ Buffer frame length is 0")
            return
        }
        
        let channelData = floatChannelData[0]
        
        var sum: Float = 0.0
        var maxSample: Float = 0.0
        for i in 0..<frameLength {
            let sample = abs(channelData[i])
            sum += sample * sample
            maxSample = max(maxSample, sample)
        }
        
        let rms = sqrt(sum / Float(frameLength))
        
        // maxSampleã‚’ä½¿ç”¨ã—ã¦ã‚ˆã‚Šæ­£ç¢ºãªdBè¨ˆç®—ï¼ˆå®Ÿæ©Ÿå‘ã‘ï¼‰
        let decibels = maxSample > 0 ? 20 * log10(maxSample) : -200.0
        
        // è©³ç´°ãƒ‡ãƒãƒƒã‚°ï¼ˆ5å›ã«1å›å‡ºåŠ›ã§æ„Ÿåº¦å‘ä¸Šï¼‰
        bufferCounter += 1
        var nonZeroSamples = 0
        for i in 0..<frameLength {
            if abs(channelData[i]) > 0.0 {
                nonZeroSamples += 1
            }
        }
        
        if bufferCounter % 5 == 0 {
            print("ğŸ¤ Buffer #\(bufferCounter): frames=\(frameLength), nonZero=\(nonZeroSamples), maxSample=\(String(format: "%.8f", maxSample)), rms=\(String(format: "%.8f", rms)), dB=\(String(format: "%.1f", decibels))")
        }
        
        // å®Ÿæ©Ÿå‘ã‘è¶…é«˜æ„Ÿåº¦ãƒ¬ãƒ™ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°
        let previousLevel = audioLevel
        var newLevel: Float = 0.0
        
        if maxSample > 0.0 {
            // -160dBã‹ã‚‰-80dBã®ç¯„å›²ã§ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå®Ÿæ©Ÿã§ã®ç’°å¢ƒéŸ³ã€œé€šå¸¸éŸ³å£°ç¯„å›²ï¼‰
            let sensitiveMapping = max(0.0, min(1.0, (decibels + 160.0) / 80.0))
            
            // ã‚ˆã‚Šä½ã„é–¾å€¤ã§ã®æ¤œå‡ºä¿è¨¼
            if rms > 0.0000001 { // 0.1ãƒã‚¤ã‚¯ãƒ­ãƒœãƒ«ãƒˆé–¾å€¤ï¼ˆè¶…é«˜æ„Ÿåº¦ï¼‰
                newLevel = max(sensitiveMapping, 0.1) // æœ€ä½10%ãƒ¬ãƒ™ãƒ«
            } else {
                newLevel = sensitiveMapping
            }
            
            // ãƒ­ã‚°ã§ã®å®Ÿæ©ŸéŸ³å£°ãƒ¬ãƒ™ãƒ«ç¯„å›²ç¢ºèª
            if bufferCounter % 10 == 0 {
                print("ğŸ” Real device audio range: dB=\(String(format: "%.1f", decibels)), mapped=\(String(format: "%.3f", newLevel))")
            }
        }
        
        DispatchQueue.main.async {
            self.audioLevel = newLevel
            
            // ãƒ¬ãƒ™ãƒ«å¤‰åŒ–ã®è©³ç´°ãƒ­ã‚°ï¼ˆéŸ³å£°æ¤œå‡ºæ™‚ã¾ãŸã¯å®šæœŸçš„ï¼‰
            self.audioLevelUpdateCounter += 1
            if newLevel > 0.01 || self.audioLevelUpdateCounter % 20 == 0 {
                print("ğŸšï¸ AudioEngine Level Update #\(self.audioLevelUpdateCounter): \(String(format: "%.3f", newLevel)) (dB: \(String(format: "%.1f", decibels)), nonZero: \(nonZeroSamples))")
            }
        }
    }
    
    /// å¾“æ¥ã®AVAudioRecorderã‚’ä½¿ç”¨ã—ãŸéŒ²éŸ³ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    private func startTraditionalRecording(fileName: String, url: URL) -> URL? {
        let audioStartTime = CFAbsoluteTimeGetCurrent()
        
        do {
            // WhisperKitå¯¾å¿œã®ç¢ºå®ŸãªéŒ²éŸ³è¨­å®šï¼ˆLinear PCMï¼‰
            let settings: [String: Any] = [
                AVFormatIDKey: Int(kAudioFormatLinearPCM),  // éåœ§ç¸®PCMï¼ˆç¢ºå®Ÿï¼‰
                AVSampleRateKey: 16000.0,  // WhisperKitæ¨å¥¨ï¼š16kHz
                AVNumberOfChannelsKey: 1,  // ãƒ¢ãƒãƒ©ãƒ«
                AVLinearPCMBitDepthKey: 16,  // 16bit
                AVLinearPCMIsBigEndianKey: false,
                AVLinearPCMIsFloatKey: false,
                AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
            ]
            
            // æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤
            if FileManager.default.fileExists(atPath: url.path) {
                try FileManager.default.removeItem(at: url)
                print("ğŸ—‘ï¸ Existing file removed: \(fileName)")
            }
            
            audioRecorder = try AVAudioRecorder(url: url, settings: settings)
            audioRecorder?.isMeteringEnabled = true
            audioRecorder?.prepareToRecord()
            
            // AudioSessionè¨­å®š
            setupAudioSessionOnDemand()
            
            let prepareResult = audioRecorder?.prepareToRecord() ?? false
            let recordStarted = audioRecorder?.record() ?? false
            
            // éŒ²éŸ³çŠ¶æ…‹ã®è©³ç´°è¨ºæ–­
            print("ğŸ™ï¸ Recording diagnostics:")
            print("   - Prepare result: \(prepareResult)")
            print("   - Record started: \(recordStarted)")
            print("   - Recorder isRecording: \(audioRecorder?.isRecording ?? false)")
            print("   - File URL: \(url)")
            print("   - Settings: \(settings)")
            
            let audioSetupDuration = (CFAbsoluteTimeGetCurrent() - audioStartTime) * 1000
            print("ğŸµ Traditional recording setup duration: \(String(format: "%.1f", audioSetupDuration))ms")
            print("ğŸ¯ Traditional recording started: \(recordStarted)")
            
            // éŒ²éŸ³é–‹å§‹å¤±æ•—æ™‚ã®å›å¾©ç­–
            if !recordStarted {
                try handleRecordingFailure(url: url, settings: settings)
            }
            
            // éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚¿ã‚¤ãƒãƒ¼ã‚’é–‹å§‹
            startLevelTimer()
            
            return url
        } catch {
            print("âŒ Failed to start traditional recording: \(error.localizedDescription)")
            return nil
        }
    }
    
    /// éŒ²éŸ³å¤±æ•—æ™‚ã®å›å¾©å‡¦ç†
    private func handleRecordingFailure(url: URL, settings: [String: Any]) throws {
        print("ğŸ”Š Attempting recording recovery...")
        
        // AudioSessionã‚’ãƒªã‚»ãƒƒãƒˆ
        try AVAudioSession.sharedInstance().setActive(false)
        try AVAudioSession.sharedInstance().setActive(true)
        
        // AudioRecorderã‚’å†ä½œæˆ
        audioRecorder = try AVAudioRecorder(url: url, settings: settings)
        audioRecorder?.isMeteringEnabled = true
        audioRecorder?.prepareToRecord()
        
        let retryResult = audioRecorder?.record() ?? false
        print("ğŸ”Š Recovery attempt result: \(retryResult)")
        
        if !retryResult {
            print("âŒ Recording recovery failed")
        }
    }

    func pauseRecording() {
        guard let recorder = audioRecorder, recorder.isRecording else { 
            print("âš ï¸ Cannot pause: No active recording")
            return 
        }
        
        print("â¸ï¸ Pausing recording...")
        recorder.pause()
        DispatchQueue.main.async {
            self.audioLevel = 0.0
        }
    }
    
    func resumeRecording() {
        guard let recorder = audioRecorder else { 
            print("âš ï¸ Cannot resume: No recorder available")
            return 
        }
        
        print("â–¶ï¸ Resuming recording...")
        let resumed = recorder.record()
        if resumed {
            print("âœ… Recording resumed successfully")
        } else {
            print("âŒ Failed to resume recording")
        }
    }
    
    func stopRecording() {
        // AVAudioEngineéŒ²éŸ³ã®å ´åˆ
        if isEngineRecording {
            stopEngineRecording()
        } else if let recorder = audioRecorder {
            stopTraditionalRecording(recorder: recorder)
        }
        
        DispatchQueue.main.async {
            self.audioLevel = 0.0
        }
        stopLevelTimer() // ã‚¿ã‚¤ãƒãƒ¼ã‚’åœæ­¢
        stopSimulatedAudioForTesting() // ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆéŸ³å£°ã‚‚åœæ­¢
        print("âœ… Recording stopped")
    }
    
    /// AVAudioEngineéŒ²éŸ³ã®åœæ­¢
    private func stopEngineRecording() {
        guard let engine = audioEngine,
              let eqNode = voiceIsolationNode else { return }
        
        print("ğŸ›‘ Stopping AVAudioEngine recording...")
        
        // ã‚¿ãƒƒãƒ—ã‚’å‰Šé™¤
        eqNode.removeTap(onBus: 0)
        
        // ã‚¨ãƒ³ã‚¸ãƒ³åœæ­¢
        engine.stop()
        isEngineRecording = false
        
        // éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®URLã‚’ä¿å­˜ã—ã¦ã‹ã‚‰é–‰ã˜ã‚‹
        let recordingURL = recordingFile?.url
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‰ã˜ã‚‹
        recordingFile = nil
        
        print("âœ… AVAudioEngine recording stopped")
        
        // ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ï¼ˆé…å»¶å®Ÿè¡Œã§ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿å®Œäº†ã‚’å¾…ã¤ï¼‰
        if let url = recordingURL {
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                self.validateRecordedFile(at: url)
                print("âœ… AudioEngine recording file validation completed")
            }
        }
    }
    
    /// å¾“æ¥éŒ²éŸ³ã®åœæ­¢
    private func stopTraditionalRecording(recorder: AVAudioRecorder) {
        let recordingURL = recorder.url
        print("ğŸ›‘ Stopping traditional recording...")
        
        recorder.stop()
        
        // éŒ²éŸ³ãŒå®Œå…¨ã«åœæ­¢ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ãŒé–‰ã˜ã‚‰ã‚Œã‚‹ã¾ã§å¾…æ©Ÿã—ã¦ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
            self.validateRecordedFile(at: recordingURL)
            print("âœ… Traditional recording stopped and file completely closed")
        }
        
        audioRecorder = nil
    }
    
    func discardRecording() {
        guard let recorder = audioRecorder else { return }
        
        let recordingURL = recorder.url
        print("ğŸ—‘ï¸ Discarding recording...")
        recorder.stop()
        DispatchQueue.main.async {
            self.audioLevel = 0.0
        }
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
            do {
                if FileManager.default.fileExists(atPath: recordingURL.path) {
                    try FileManager.default.removeItem(at: recordingURL)
                    print("ğŸ—‘ï¸ Recording file deleted successfully")
                }
            } catch {
                print("âš ï¸ Failed to delete recording file: \(error.localizedDescription)")
            }
        }
        
        audioRecorder = nil
    }
    
    var isRecording: Bool {
        return isEngineRecording || (audioRecorder?.isRecording ?? false)
    }
    
    var isPaused: Bool {
        guard let recorder = audioRecorder else { return false }
        return !recorder.isRecording && recorder.url.path.contains(".m4a")
    }
    
    func updateAudioLevel() {
        // AVAudioEngineã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã¯ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ¬ãƒ™ãƒ«ãŒæ›´æ–°ã•ã‚Œã‚‹
        if isEngineRecording {
            // updateAudioLevelFromBufferã§æ—¢ã«æ›´æ–°ã•ã‚Œã¦ã„ã‚‹ã®ã§ãã®ã¾ã¾
            return
        }
        
        // å¾“æ¥ã®AVAudioRecorderä½¿ç”¨æ™‚
        guard let recorder = audioRecorder, recorder.isRecording else {
            DispatchQueue.main.async {
                self.audioLevel = 0.0
            }
            return
        }
        
        recorder.updateMeters()
        let averagePower = recorder.averagePower(forChannel: 0)
        
        // ç„¡éŸ³é–¾å€¤ã‚’è¨­å®šï¼ˆ-55dBä»¥ä¸‹ã¯ç„¡éŸ³ã¨ã¿ãªã™ï¼‰
        let silenceThreshold: Float = -55.0
        let minDecibels: Float = -45.0
        
        if averagePower < silenceThreshold {
            DispatchQueue.main.async {
                self.audioLevel = 0.0
            }
        } else {
            let normalizedLevel = max(0.0, (averagePower - minDecibels) / -minDecibels)
            // éŸ³å£°ãŒã‚ã‚‹å ´åˆã®ã¿å¹³æ–¹æ ¹ã§åå¿œã‚’å¼·åŒ–
            let newLevel = sqrt(normalizedLevel)
            DispatchQueue.main.async {
                self.audioLevel = newLevel
            }
        }
    }
    
    // MARK: - Audio Level Timer
    
    /// éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚¿ã‚¤ãƒãƒ¼ã‚’é–‹å§‹
    private func startLevelTimer() {
        stopLevelTimer() // æ—¢å­˜ã®ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
        
        levelTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            DispatchQueue.main.async {
                self?.updateAudioLevels()
            }
        }
        
        print("ğŸšï¸ Audio level timer started")
    }
    
    /// å¾…æ©ŸçŠ¶æ…‹ã®éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚’é–‹å§‹ï¼ˆéŒ²éŸ³å‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºç”¨ï¼‰
    func startStandbyAudioMonitoring() {
        // æ¨©é™ãƒã‚§ãƒƒã‚¯
        guard permissionGranted else {
            print("âš ï¸ Cannot start audio monitoring - permission not granted")
            return
        }
        
        // AudioSessionã‚’è¨­å®š
        setupAudioSessionOnDemand()
        
        // ãƒ¬ãƒ™ãƒ«ã‚¿ã‚¤ãƒãƒ¼ã‚’é–‹å§‹ï¼ˆå¾…æ©ŸçŠ¶æ…‹ã§ã‚‚éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’å–å¾—ï¼‰
        startLevelTimer()
        
        print("ğŸšï¸ Standby audio monitoring started")
    }
    
    /// å¾…æ©ŸçŠ¶æ…‹ã®éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚’åœæ­¢
    func stopStandbyAudioMonitoring() {
        stopLevelTimer()
        DispatchQueue.main.async {
            self.audioLevel = 0.0
        }
        print("ğŸšï¸ Standby audio monitoring stopped")
    }
    
    /// éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚¿ã‚¤ãƒãƒ¼ã‚’åœæ­¢
    private func stopLevelTimer() {
        levelTimer?.invalidate()
        levelTimer = nil
    }
    
    /// éŸ³å£°ãƒ¬ãƒ™ãƒ«æ›´æ–°ï¼ˆAVAudioRecorderç”¨ + EngineéŒ²éŸ³ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    private func updateAudioLevels() {
        // EngineéŒ²éŸ³ä¸­ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯éŸ³å£°ãƒ¬ãƒ™ãƒ«å–å¾—ã‚’è©¦è¡Œ
        if isEngineRecording {
            // AudioEngineã®Tapã‹ã‚‰éŸ³å£°ãƒ¬ãƒ™ãƒ«ãŒæ›´æ–°ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
            // æ›´æ–°ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ä½•ã‚‚ã—ãªã„ï¼ˆTapã‹ã‚‰ã®æ›´æ–°ã‚’å„ªå…ˆï¼‰
            return
        }
        
        // å¾“æ¥ã®AVAudioRecorderä½¿ç”¨æ™‚
        guard let recorder = audioRecorder, recorder.isRecording else {
            DispatchQueue.main.async {
                self.audioLevel = 0.0
            }
            return
        }
        
        recorder.updateMeters()
        let averagePower = recorder.averagePower(forChannel: 0)
        
        // ç„¡éŸ³é–¾å€¤ã‚’è¨­å®šï¼ˆ-55dBä»¥ä¸‹ã¯ç„¡éŸ³ã¨ã¿ãªã™ï¼‰
        let silenceThreshold: Float = -55.0
        let minDecibels: Float = -45.0
        
        let previousLevel = audioLevel
        
        if averagePower < silenceThreshold {
            DispatchQueue.main.async {
                self.audioLevel = 0.0
            }
        } else {
            let normalizedLevel = max(0.0, (averagePower - minDecibels) / -minDecibels)
            // éŸ³å£°ãŒã‚ã‚‹å ´åˆã®ã¿å¹³æ–¹æ ¹ã§åå¿œã‚’å¼·åŒ–
            let newLevel = sqrt(normalizedLevel)
            DispatchQueue.main.async {
                self.audioLevel = newLevel
            }
        }
        
        // ãƒ‡ãƒãƒƒã‚°: AVAudioRecorderã®éŸ³å£°ãƒ¬ãƒ™ãƒ«æ›´æ–°ãƒ­ã‚°ï¼ˆå¤‰åŒ–ãŒã‚ã£ãŸå ´åˆï¼‰
        if abs(audioLevel - previousLevel) > 0.05 || audioLevel > 0.1 {
            print("ğŸšï¸ AVAudioRecorder Level Update: \(String(format: "%.3f", audioLevel)) (dB: \(String(format: "%.1f", averagePower)))")
        }
    }

    func getDocumentsDirectory() -> URL {
        let paths = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)
        return paths[0]
    }
    
    /// éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
    private func validateRecordedFile(at url: URL) {
        do {
            // ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            guard FileManager.default.fileExists(atPath: url.path) else {
                print("âŒ Recorded file does not exist: \(url.path)")
                return
            }
            
            // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
            let attributes = try FileManager.default.attributesOfItem(atPath: url.path)
            let fileSize = attributes[.size] as? UInt64 ?? 0
            
            if fileSize == 0 {
                print("âŒ Recorded file is empty: \(url.lastPathComponent)")
                return
            }
            
            if fileSize < 1024 { // 1KBæœªæº€ã¯ç•°å¸¸ã«å°ã•ã„
                print("âš ï¸ Recorded file is very small (\(fileSize) bytes): \(url.lastPathComponent)")
            }
            
            // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
            let asset = AVURLAsset(url: url)
            let duration = asset.duration.seconds
            
            print("ğŸ“Š Recording validation:")
            print("   - File size: \(fileSize) bytes")
            print("   - Duration: \(String(format: "%.2f", duration)) seconds")
            print("   - Estimated bitrate: \(fileSize > 0 && duration > 0 ? Int((Double(fileSize) * 8) / duration) : 0) bps")
            
            // éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ã®ç¢ºèª
            let audioTracks = asset.tracks(withMediaType: .audio)
            if audioTracks.isEmpty {
                print("âŒ No audio tracks found in recorded file")
            } else {
                for (index, track) in audioTracks.enumerated() {
                    print("   - Audio track \(index): \(track.formatDescriptions.count) format(s)")
                }
            }
            
            // æœ€çµ‚æ¤œè¨¼
            if duration > 0 {
                print("âœ… Recorded file validation passed: \(fileSize) bytes, \(String(format: "%.2f", duration))s")
            } else {
                print("âŒ Recorded file has invalid duration: \(url.lastPathComponent)")
            }
            
        } catch {
            print("âŒ Failed to validate recorded file: \(error.localizedDescription)")
        }
    }
    
    /// éŒ²éŸ³å¤±æ•—æ™‚ã®è¨ºæ–­
    private func diagnoseRecordingFailure(recorder: AVAudioRecorder) {
        print("ğŸ” --- Recording Failure Diagnosis ---")
        
        // AudioRecorderã®çŠ¶æ…‹
        print("ğŸ” Recorder metering enabled: \(recorder.isMeteringEnabled)")
        print("ğŸ” Recorder format: \(recorder.format.description)")
        print("ğŸ” Recorder settings: \(recorder.settings)")
        
        // AudioSessionã®è©³ç´°çŠ¶æ…‹
        let session = AVAudioSession.sharedInstance()
        print("ğŸ” Session category: \(session.category)")
        print("ğŸ” Session mode: \(session.mode)")
        print("ğŸ” Session options: \(session.categoryOptions)")
        print("ğŸ” Session active: \(session.isOtherAudioPlaying)")
        print("ğŸ” Input available: \(session.isInputAvailable)")
        print("ğŸ” Input routes: \(session.availableInputs?.map { $0.portName } ?? [])")
        print("ğŸ” Current route inputs: \(session.currentRoute.inputs.map { $0.portName })")
        print("ğŸ” Current route outputs: \(session.currentRoute.outputs.map { $0.portName })")
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
        let url = recorder.url
        print("ğŸ” File path: \(url.path)")
        print("ğŸ” File exists: \(FileManager.default.fileExists(atPath: url.path))")
        print("ğŸ” Directory writable: \(FileManager.default.isWritableFile(atPath: url.deletingLastPathComponent().path))")
        
        // å†è©¦è¡Œ
        print("ğŸ” Attempting to restart recording...")
        let retryResult = recorder.record()
        print("ğŸ” Retry result: \(retryResult)")
        print("ğŸ” --- End Diagnosis ---")
    }
    
    // MARK: - æŒ‡å‘æ€§ãƒã‚¤ã‚¯è¨­å®š
    
    /// æŒ‡å‘æ€§ãƒã‚¤ã‚¯ã®è¨­å®šï¼ˆiPhoneå¯¾å¿œï¼‰
    private func configureDirectionalMicrophone(for mode: RecordingMode, session: AVAudioSession) {
        do {
            // åˆ©ç”¨å¯èƒ½ãªå…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ã‚’ç¢ºèª
            guard let availableInputs = session.availableInputs else {
                print("ğŸ¤ No available inputs found")
                return
            }
            
            print("ğŸ¤ Available inputs: \(availableInputs.map { $0.portName })")
            
            // å†…è”µãƒã‚¤ã‚¯ã‚’æ¢ã™
            let builtInMic = availableInputs.first { input in
                input.portType == .builtInMic
            }
            
            guard let builtIn = builtInMic else {
                print("ğŸ¤ Built-in microphone not found")
                return
            }
            
            // å†…è”µãƒã‚¤ã‚¯ã‚’å„ªå…ˆå…¥åŠ›ã«è¨­å®š
            try session.setPreferredInput(builtIn)
            print("ğŸ¤ Preferred input set to: \(builtIn.portName)")
            
            // ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¨­å®šï¼ˆæŒ‡å‘æ€§å¯¾å¿œï¼‰
            if let dataSources = builtIn.dataSources, !dataSources.isEmpty {
                print("ğŸ¤ Available data sources: \(dataSources.map { $0.dataSourceName })")
                
                // ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠ
                let preferredDataSource = selectDataSource(for: mode, from: dataSources)
                
                if let preferred = preferredDataSource {
                    try builtIn.setPreferredDataSource(preferred)
                    print("ğŸ¤ Preferred data source set to: \(preferred.dataSourceName)")
                }
            }
            
            // å…¥åŠ›ã‚²ã‚¤ãƒ³è¨­å®š
            if session.isInputGainSettable {
                let targetGain = getTargetGain(for: mode)
                try session.setInputGain(targetGain)
                print("ğŸ¤ Input gain set to: \(targetGain)")
            }
            
        } catch {
            print("âŒ Failed to configure directional microphone: \(error)")
        }
    }
    
    /// ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠ
    private func selectDataSource(for mode: RecordingMode, from dataSources: [AVAudioSessionDataSourceDescription]) -> AVAudioSessionDataSourceDescription? {
        switch mode {
        case .conversation, .meeting:
            // ãƒ•ãƒ­ãƒ³ãƒˆå‘ããƒã‚¤ã‚¯ï¼ˆãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°å¯¾å¿œï¼‰
            return dataSources.first { $0.dataSourceName.contains("Front") || $0.dataSourceName.contains("Top") }
        case .ambient:
            // å…¨æ–¹å‘ãƒã‚¤ã‚¯
            return dataSources.first { $0.dataSourceName.contains("Back") || $0.dataSourceName.contains("Bottom") }
        case .voiceOver:
            // é«˜æ„Ÿåº¦ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¤ã‚¯
            return dataSources.first { $0.dataSourceName.contains("Front") }
        case .balanced:
            // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            return dataSources.first
        }
    }
    
    /// ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®å…¥åŠ›ã‚²ã‚¤ãƒ³è¨­å®š
    private func getTargetGain(for mode: RecordingMode) -> Float {
        switch mode {
        case .conversation, .voiceOver:
            return 0.8  // é«˜æ„Ÿåº¦
        case .ambient:
            return 0.6  // æ¨™æº–æ„Ÿåº¦
        case .meeting:
            return 0.7  // ä¸­ï½é«˜æ„Ÿåº¦
        case .balanced:
            return 0.65 // ãƒãƒ©ãƒ³ã‚¹
        }
    }
    
    // MARK: - AudioSessionä¸­æ–­å‡¦ç†
    
    /// AudioSessionä¸­æ–­å‡¦ç†ã®è¨­å®š
    private func setupAudioSessionInterruptionHandling() {
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleAudioSessionInterruption),
            name: AVAudioSession.interruptionNotification,
            object: nil
        )
        
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleAudioSessionRouteChange),
            name: AVAudioSession.routeChangeNotification,
            object: nil
        )
        
        print("ğŸ”” AudioSession interruption handling setup completed")
    }
    
    /// AudioSessionä¸­æ–­é€šçŸ¥ã®å‡¦ç†ï¼ˆå¼·åŒ–ç‰ˆï¼‰
    @objc private func handleAudioSessionInterruption(notification: Notification) {
        guard let userInfo = notification.userInfo,
              let typeValue = userInfo[AVAudioSessionInterruptionTypeKey] as? UInt,
              let type = AVAudioSession.InterruptionType(rawValue: typeValue) else {
            print("âŒ Invalid interruption notification")
            return
        }
        
        print("ğŸš« AudioSession interruption detected: \(type)")
        
        switch type {
        case .began:
            handleInterruptionBegan(userInfo: userInfo)
            
        case .ended:
            handleInterruptionEnded(userInfo: userInfo)
            
        @unknown default:
            print("âš ï¸ Unknown interruption type: \(type)")
            break
        }
    }
    
    /// ä¸­æ–­é–‹å§‹å‡¦ç†
    private func handleInterruptionBegan(userInfo: [AnyHashable: Any]) {
        print("ğŸš« Audio session interrupted - recording will be paused")
        
        // ä¸­æ–­ã®åŸå› ã‚’ç‰¹å®š
        if let reasonValue = userInfo[AVAudioSessionInterruptionReasonKey] as? UInt,
           let reason = AVAudioSession.InterruptionReason(rawValue: reasonValue) {
            print("ğŸš« Interruption reason: \(reason)")
        }
        
        // éŒ²éŸ³çŠ¶æ…‹ã®è¨˜éŒ²
        let wasRecording = (audioRecorder?.isRecording ?? false) || isEngineRecording
        if wasRecording {
            print("ğŸ“ Recording was active during interruption")
            // ä¸­æ–­å‰ã®çŠ¶æ…‹ã‚’è¨˜éŒ²ï¼ˆå¾©å¸°æ™‚ã«ä½¿ç”¨ï¼‰
            UserDefaults.standard.set(true, forKey: "wasRecordingBeforeInterruption")
        }
        
        // AudioEngineéŒ²éŸ³ã®å ´åˆã¯æ‰‹å‹•åœæ­¢ãŒå¿…è¦
        if isEngineRecording {
            print("ğŸ›‘ Stopping AudioEngine due to interruption")
            stopEngineRecording()
        }
    }
    
    /// ä¸­æ–­çµ‚äº†å‡¦ç†
    private func handleInterruptionEnded(userInfo: [AnyHashable: Any]) {
        print("ğŸ”„ Audio session interruption ended")
        
        if let optionsValue = userInfo[AVAudioSessionInterruptionOptionKey] as? UInt {
            let options = AVAudioSession.InterruptionOptions(rawValue: optionsValue)
            
            if options.contains(.shouldResume) {
                print("ğŸ”„ System suggests resuming audio")
                
                // ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãã®å¾©å¸°å‡¦ç†
                resumeAudioSessionWithRetry(maxRetries: 3)
            } else {
                print("âš ï¸ System does not suggest resuming audio")
            }
        }
    }
    
    /// AudioSessionãƒ«ãƒ¼ãƒˆå¤‰æ›´é€šçŸ¥ã®å‡¦ç†
    @objc private func handleAudioSessionRouteChange(notification: Notification) {
        guard let userInfo = notification.userInfo,
              let reasonValue = userInfo[AVAudioSessionRouteChangeReasonKey] as? UInt,
              let reason = AVAudioSession.RouteChangeReason(rawValue: reasonValue) else {
            return
        }
        
        print("ğŸ”„ AudioSession route changed: \(reason)")
        
        switch reason {
        case .newDeviceAvailable:
            print("ğŸ§ New audio device connected")
        case .oldDeviceUnavailable:
            print("ğŸ§ Audio device disconnected")
        case .categoryChange:
            print("ğŸ“± Audio category changed")
        case .override:
            print("ğŸ”„ Audio route override")
        case .wakeFromSleep:
            print("ğŸ˜´ Audio route changed due to wake from sleep")
        case .noSuitableRouteForCategory:
            print("âŒ No suitable route for current category")
        case .routeConfigurationChange:
            print("âš™ï¸ Route configuration changed")
        @unknown default:
            print("â“ Unknown route change reason: \(reason)")
        }
    }
    
    /// ä¸­æ–­å¾Œã®AudioSessionå¾©å¸°å‡¦ç†
    /// ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãAudioSessionå¾©å¸°å‡¦ç†
    private func resumeAudioSessionWithRetry(maxRetries: Int, currentRetry: Int = 0) {
        guard currentRetry < maxRetries else {
            print("âŒ Failed to resume after \(maxRetries) retries")
            // æœ€çµ‚çš„ã«å¤±æ•—ã—ãŸå ´åˆã®å‡¦ç†
            handleRecordingRecoveryFailure()
            return
        }
        
        print("ğŸ”„ Attempting to resume audio session (retry \(currentRetry + 1)/\(maxRetries))")
        
        // é…å»¶å®Ÿè¡Œï¼ˆã‚·ã‚¹ãƒ†ãƒ ãŒå®‰å®šã™ã‚‹ã¾ã§å¾…æ©Ÿï¼‰
        DispatchQueue.main.asyncAfter(deadline: .now() + Double(currentRetry) * 0.5) {
            do {
                // AudioSessionå†ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
                try self.setupLongRecordingAudioSession()
                print("âœ… AudioSession reactivated after interruption")
                
                // éŒ²éŸ³å¾©å¸°å‡¦ç†
                self.attemptRecordingResume()
                
            } catch {
                print("âŒ Retry \(currentRetry + 1) failed: \(error.localizedDescription)")
                
                // æ¬¡ã®ãƒªãƒˆãƒ©ã‚¤ã‚’å®Ÿè¡Œ
                self.resumeAudioSessionWithRetry(maxRetries: maxRetries, currentRetry: currentRetry + 1)
            }
        }
    }
    
    /// éŒ²éŸ³å¾©å¸°å‡¦ç†
    private func attemptRecordingResume() {
        let wasRecording = UserDefaults.standard.bool(forKey: "wasRecordingBeforeInterruption")
        
        guard wasRecording else {
            print("ğŸ“ No recording to resume")
            return
        }
        
        // å¾“æ¥éŒ²éŸ³ã®å¾©å¸°
        if let recorder = audioRecorder, !recorder.isRecording {
            print("ğŸ”„ Attempting to resume AVAudioRecorder")
            let resumed = recorder.record()
            print("ğŸ“± AVAudioRecorder resume result: \(resumed)")
            
            if resumed {
                print("âœ… Recording successfully resumed")
                UserDefaults.standard.removeObject(forKey: "wasRecordingBeforeInterruption")
            }
        }
        
        // AudioEngineéŒ²éŸ³ã®å¾©å¸°ï¼ˆå¿…è¦ã«å¿œã˜ã¦å†åˆæœŸåŒ–ï¼‰
        if !isEngineRecording && wasRecording {
            print("ğŸ”„ Attempting to restart AudioEngine recording")
            // å¿…è¦ã«å¿œã˜ã¦éŒ²éŸ³ã‚’å†é–‹
            // startEngineRecording(url: lastRecordingURL) ãªã©ã®å®Ÿè£…
        }
    }
    
    /// éŒ²éŸ³å¾©å¸°å¤±æ•—æ™‚ã®å‡¦ç†
    private func handleRecordingRecoveryFailure() {
        print("âŒ Recording recovery failed completely")
        
        // ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é€šçŸ¥ï¼ˆå¾Œã§å®Ÿè£…ï¼‰
        // NotificationCenter.default.post(name: .recordingRecoveryFailed, object: nil)
        
        // çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
        UserDefaults.standard.removeObject(forKey: "wasRecordingBeforeInterruption")
        
        // å¿…è¦ã«å¿œã˜ã¦éŒ²éŸ³ã‚’å®Œå…¨ã«åœæ­¢
        stopRecording()
    }
    
    // MARK: - ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–
    
    /// ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹å…¨ä½“ã®ç›£è¦–é–‹å§‹
    func startSystemResourceMonitoring() {
        // ãƒ¡ãƒ¢ãƒªç›£è¦–ã¯ã™ã§ã«é–‹å§‹æ¸ˆã¿
        startBatteryMonitoring()
        startDiskSpaceMonitoring()
        print("ğŸ”‹ System resource monitoring started")
    }
    
    /// ãƒãƒƒãƒ†ãƒªãƒ¼ç›£è¦–é–‹å§‹
    private func startBatteryMonitoring() {
        UIDevice.current.isBatteryMonitoringEnabled = true
        
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(batteryLevelChanged),
            name: UIDevice.batteryLevelDidChangeNotification,
            object: nil
        )
        
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(batteryStateChanged),
            name: UIDevice.batteryStateDidChangeNotification,
            object: nil
        )
    }
    
    /// ãƒãƒƒãƒ†ãƒªãƒ¼æ®‹é‡å¤‰åŒ–é€šçŸ¥
    @objc private func batteryLevelChanged() {
        let level = UIDevice.current.batteryLevel
        print("ğŸ”‹ Battery level: \(Int(level * 100))%")
        
        // ä½ãƒãƒƒãƒ†ãƒªãƒ¼è­¦å‘Šï¼ˆ20%ä»¥ä¸‹ï¼‰
        if level < 0.2 && level > 0.0 {
            print("âš ï¸ Low battery warning for long recording")
            // å¿…è¦ã«å¿œã˜ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è­¦å‘Š
        }
    }
    
    /// ãƒãƒƒãƒ†ãƒªãƒ¼çŠ¶æ…‹å¤‰åŒ–é€šçŸ¥
    @objc private func batteryStateChanged() {
        let state = UIDevice.current.batteryState
        print("ğŸ”‹ Battery state changed: \(state)")
        
        switch state {
        case .charging:
            print("ğŸ”Œ Device is charging - good for long recording")
        case .unplugged:
            print("ğŸ”‹ Device unplugged - monitor battery usage")
        case .full:
            print("ğŸ”‹ Battery full - optimal for long recording")
        case .unknown:
            print("ğŸ”‹ Battery state unknown")
        @unknown default:
            break
        }
    }
    
    /// ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ç›£è¦–é–‹å§‹
    private func startDiskSpaceMonitoring() {
        Timer.scheduledTimer(withTimeInterval: 60.0, repeats: true) { _ in
            self.checkDiskSpaceAndWarn()
        }
    }
    
    /// ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãƒã‚§ãƒƒã‚¯ã¨è­¦å‘Š
    private func checkDiskSpaceAndWarn() {
        let availableSpace = getAvailableDiskSpace()
        let requiredSpace: Int64 = 500 * 1024 * 1024 // 500MB
        
        if availableSpace < requiredSpace {
            print("âš ï¸ Low disk space warning: \(availableSpace / 1024 / 1024)MB available")
            // ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è­¦å‘Šã‚’è¡¨ç¤º
        }
    }
    
    /// åˆ©ç”¨å¯èƒ½ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡å–å¾—
    private func getAvailableDiskSpace() -> Int64 {
        do {
            let attributes = try FileManager.default.attributesOfFileSystem(forPath: NSHomeDirectory())
            if let freeSize = attributes[.systemFreeSize] as? NSNumber {
                return freeSize.int64Value
            }
        } catch {
            print("âŒ Failed to get disk space: \(error)")
        }
        return 0
    }
    
    // MARK: - ãƒ¡ãƒ¢ãƒªç®¡ç†ãƒ»æœ€é©åŒ–
    
    /// ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ç›£è¦–
    private func checkAvailableDiskSpace() -> Bool {
        do {
            let documentDirectory = getDocumentsDirectory()
            let systemAttributes = try FileManager.default.attributesOfFileSystem(forPath: documentDirectory.path)
            
            if let freeSize = systemAttributes[.systemFreeSize] as? NSNumber {
                let freeSizeGB = freeSize.doubleValue / (1024 * 1024 * 1024)
                print("ğŸ’¾ Available disk space: \(String(format: "%.1f", freeSizeGB))GB")
                
                // 1GBæœªæº€ã®å ´åˆã¯è­¦å‘Š
                if freeSizeGB < 1.0 {
                    print("âš ï¸ Low disk space warning: \(String(format: "%.1f", freeSizeGB))GB remaining")
                    return false
                }
                return true
            }
        } catch {
            print("âŒ Failed to check disk space: \(error)")
        }
        return false
    }
    
    /// ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å–å¾—
    private func getMemoryUsage() -> UInt64 {
        var info = mach_task_basic_info()
        var count = mach_msg_type_number_t(MemoryLayout<mach_task_basic_info>.size)/4
        
        let result = withUnsafeMutablePointer(to: &info) {
            $0.withMemoryRebound(to: integer_t.self, capacity: 1) {
                task_info(mach_task_self_,
                         task_flavor_t(MACH_TASK_BASIC_INFO),
                         $0,
                         &count)
            }
        }
        
        if result == KERN_SUCCESS {
            return info.resident_size
        } else {
            return 0
        }
    }
    
    // MARK: - Background Recording Support
    
    /// ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰éŒ²éŸ³ç”¨ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®š
    func setupBackgroundRecording() throws {
        let session = AVAudioSession.sharedInstance()
        
        print("ğŸ“± Setting up background recording capability...")
        
        do {
            // ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰éŒ²éŸ³ç”¨ã‚«ãƒ†ã‚´ãƒªè¨­å®šï¼ˆ.defaultToSpeakerã‚’å‰Šé™¤ï¼‰
            try session.setCategory(
                .record,                    // éŒ²éŸ³å°‚ç”¨ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å¯¾å¿œï¼‰
                mode: .default,             // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ¼ãƒ‰
                options: [.mixWithOthers, .allowBluetooth]
            )
            
            // ã‚»ãƒƒã‚·ãƒ§ãƒ³æœ‰åŠ¹åŒ–
            try session.setActive(true)
            
            isBackgroundRecordingEnabled = true
            
            print("âœ… Background recording enabled successfully")
            print("   - Category: \(session.category)")
            print("   - Mode: \(session.mode)")
            print("   - Input available: \(session.isInputAvailable)")
            
        } catch {
            isBackgroundRecordingEnabled = false
            print("âŒ Failed to enable background recording: \(error)")
            throw error
        }
    }
    
    /// é€šå¸¸éŒ²éŸ³ç”¨ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šã«æˆ»ã™
    func setupStandardRecording(recordingMode: RecordingMode = .balanced) throws {
        let session = AVAudioSession.sharedInstance()
        
        print("ğŸ“± Setting up standard recording mode...")
        
        do {
            let sessionMode = recordingMode.audioSessionMode
            var options: AVAudioSession.CategoryOptions = [.defaultToSpeaker, .allowBluetooth]
            
            // æ¨™æº–éŒ²éŸ³ç”¨ã‚«ãƒ†ã‚´ãƒªè¨­å®š
            try session.setCategory(.playAndRecord, mode: sessionMode, options: options)
            try session.setActive(true)
            
            isBackgroundRecordingEnabled = false
            
            print("âœ… Standard recording enabled successfully")
            
        } catch {
            print("âŒ Failed to enable standard recording: \(error)")
            throw error
        }
    }
    
    /// ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯é–‹å§‹
    private func startBackgroundTask() {
        guard backgroundTaskID == .invalid else {
            print("âš ï¸ Background task already running")
            return
        }
        
        backgroundTaskID = UIApplication.shared.beginBackgroundTask(
            withName: "AudioRecording"
        ) { [weak self] in
            print("ğŸ”„ Background task expiring - ending task")
            self?.endBackgroundTask()
        }
        
        print("ğŸ“± Background task started: \(backgroundTaskID.rawValue)")
    }
    
    /// ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯çµ‚äº†
    private func endBackgroundTask() {
        guard backgroundTaskID != .invalid else { return }
        
        UIApplication.shared.endBackgroundTask(backgroundTaskID)
        backgroundTaskID = .invalid
        
        print("ğŸ“± Background task ended")
    }
    
    /// é•·æ™‚é–“éŒ²éŸ³ç”¨ã®AudioSessionæœ€é©åŒ–è¨­å®š
    private func setupLongRecordingAudioSession() throws {
        let session = AVAudioSession.sharedInstance()
        
        print("ğŸ”Š Setting up optimized audio session for long recording")
        
        // é•·æ™‚é–“éŒ²éŸ³ç”¨ã®æœ€é©è¨­å®š
        try session.setCategory(.playAndRecord,
                               mode: .default,
                               options: [.defaultToSpeaker,
                                       .allowBluetoothA2DP,
                                       .allowAirPlay])
        
        // é•·æ™‚é–“éŒ²éŸ³ç”¨ãƒãƒƒãƒ•ã‚¡è¨­å®šï¼ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æœ€é©åŒ–ï¼‰
        try session.setPreferredIOBufferDuration(0.1) // 100msãƒãƒƒãƒ•ã‚¡
        try session.setPreferredSampleRate(44100) // é«˜å“è³ªã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ
        
        // ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³ã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
        try session.setPreferredInputNumberOfChannels(1)
        try session.setPreferredOutputNumberOfChannels(2)
        
        // ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
        try session.setActive(true)
        
        print("âœ… Long recording audio session configured:")
        print("   - Buffer Duration: \(session.ioBufferDuration)s")
        print("   - Sample Rate: \(session.sampleRate)Hz")
        print("   - Input Channels: \(session.inputNumberOfChannels)")
        print("   - Output Channels: \(session.outputNumberOfChannels)")
    }
    
    /// éŒ²éŸ³é–‹å§‹æ™‚ã«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã‚’è‡ªå‹•é–‹å§‹
    func startRecordingWithBackgroundSupport(at url: URL, settings: [String: Any]) throws {
        // ãƒ¡ãƒ¢ãƒªç›£è¦–é–‹å§‹
        memoryMonitor.startRecordingMonitoring()
        
        // é•·æ™‚é–“éŒ²éŸ³ç”¨AudioSessionè¨­å®š
        try setupLongRecordingAudioSession()
        
        // ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯é–‹å§‹
        startBackgroundTask()
        
        // é€šå¸¸ã®éŒ²éŸ³é–‹å§‹
        audioRecorder = try AVAudioRecorder(url: url, settings: settings)
        audioRecorder?.record()
        
        print("ğŸ™ï¸ Recording started with background support")
    }
    
    /// éŒ²éŸ³åœæ­¢æ™‚ã«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã‚’çµ‚äº†
    func stopRecordingWithBackgroundSupport() {
        audioRecorder?.stop()
        audioRecorder = nil
        
        // ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯çµ‚äº†
        endBackgroundTask()
        
        // ãƒ¡ãƒ¢ãƒªç›£è¦–åœæ­¢
        memoryMonitor.stopRecordingMonitoring()
        
        print("ğŸ™ï¸ Recording stopped and background task ended")
    }
    
    deinit {
        NotificationCenter.default.removeObserver(self)
        memoryMonitor.stopRecordingMonitoring()
        UIDevice.current.isBatteryMonitoringEnabled = false
        endBackgroundTask()
    }
}

// MARK: - AudioService Error Definitions

enum AudioServiceError: LocalizedError {
    case permissionDenied
    case diskSpaceInsufficient(available: Int64, required: Int64)
    case sessionConfigurationFailed(Error)
    case microphoneNotAvailable
    case recordingInProgress
    case recordingSetupFailed(Error)
    case audioEngineStartFailed(Error)
    case fileWriteError(Error)
    
    var errorDescription: String? {
        switch self {
        case .permissionDenied:
            return "ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒå¿…è¦ã§ã™ã€‚è¨­å®šã‹ã‚‰è¨±å¯ã—ã¦ãã ã•ã„ã€‚"
        case .diskSpaceInsufficient(let available, let required):
            let shortfall = required - available
            let formatter = ByteCountFormatter()
            formatter.countStyle = .file
            return "ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡ä¸è¶³ã§ã™ã€‚\(formatter.string(fromByteCount: shortfall))ã®ç©ºãå®¹é‡ãŒå¿…è¦ã§ã™ã€‚"
        case .sessionConfigurationFailed(let error):
            return "éŒ²éŸ³è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ: \(error.localizedDescription)"
        case .microphoneNotAvailable:
            return "ãƒã‚¤ã‚¯ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ä»–ã®ã‚¢ãƒ—ãƒªã§ä½¿ç”¨ä¸­ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
        case .recordingInProgress:
            return "æ—¢ã«éŒ²éŸ³ä¸­ã§ã™ã€‚"
        case .recordingSetupFailed(let error):
            return "éŒ²éŸ³ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸ: \(error.localizedDescription)"
        case .audioEngineStartFailed(let error):
            return "ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¨ãƒ³ã‚¸ãƒ³ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ: \(error.localizedDescription)"
        case .fileWriteError(let error):
            return "éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: \(error.localizedDescription)"
        }
    }
    
    var recoverySuggestion: String? {
        switch self {
        case .permissionDenied:
            return "è¨­å®šã‚¢ãƒ—ãƒªã§ãƒã‚¤ã‚¯ã®æ¨©é™ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„"
        case .diskSpaceInsufficient:
            return "ä¸è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¦å®¹é‡ã‚’ç¢ºä¿ã—ã¦ãã ã•ã„"
        case .sessionConfigurationFailed:
            return "ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã—ã¦ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„"
        case .microphoneNotAvailable:
            return "ä»–ã®ã‚¢ãƒ—ãƒªã‚’çµ‚äº†ã—ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„"
        case .recordingInProgress:
            return "ç¾åœ¨ã®éŒ²éŸ³ã‚’åœæ­¢ã—ã¦ã‹ã‚‰æ–°ã—ã„éŒ²éŸ³ã‚’é–‹å§‹ã—ã¦ãã ã•ã„"
        case .recordingSetupFailed, .audioEngineStartFailed:
            return "ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã—ã¦ã€éŒ²éŸ³è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„"
        case .fileWriteError:
            return "ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡ã‚’ç¢ºèªã—ã€ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„"
        }
    }
    
    var shouldRetry: Bool {
        switch self {
        case .permissionDenied, .diskSpaceInsufficient, .recordingInProgress:
            return false
        default:
            return true
        }
    }
}

// MARK: - Notification Names

extension Notification.Name {
    static let audioServiceRecordingError = Notification.Name("audioServiceRecordingError")
    static let audioServiceMemoryWarning = Notification.Name("audioServiceMemoryWarning")
    static let audioServiceDiskSpaceWarning = Notification.Name("audioServiceDiskSpaceWarning")
}
