
import Foundation
import AVFoundation
import UIKit

/// éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰å®šç¾©
enum RecordingMode: String, CaseIterable {
    case conversation = "conversation"     // ä¼šè©±ç‰¹åŒ–
    case ambient = "ambient"              // ç’°å¢ƒéŸ³å…¨ä½“
    case voiceOver = "voiceOver"          // ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŒ²éŸ³
    case meeting = "meeting"              // ä¼šè­°éŒ²éŸ³
    case balanced = "balanced"            // ãƒãƒ©ãƒ³ã‚¹å‹
    
    var displayName: String {
        switch self {
        case .conversation: return "ä¼šè©±ãƒ¢ãƒ¼ãƒ‰"
        case .ambient: return "ç’°å¢ƒéŸ³ãƒ¢ãƒ¼ãƒ‰"
        case .voiceOver: return "ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰"
        case .meeting: return "ä¼šè­°ãƒ¢ãƒ¼ãƒ‰"
        case .balanced: return "ãƒãƒ©ãƒ³ã‚¹ãƒ¢ãƒ¼ãƒ‰"
        }
    }
    
    var audioSessionMode: AVAudioSession.Mode {
        switch self {
        case .conversation: return .voiceChat
        case .ambient: return .default
        case .voiceOver: return .measurement
        case .meeting: return .videoRecording
        case .balanced: return .default
        }
    }
    
    var description: String {
        switch self {
        case .conversation: return "äººã®å£°ã‚’æ˜ç­ã«éŒ²éŸ³ã€èƒŒæ™¯ãƒã‚¤ã‚ºæŠ‘åˆ¶"
        case .ambient: return "ã™ã¹ã¦ã®éŸ³ã‚’å¿ å®Ÿã«éŒ²éŸ³ã€è‡ªç„¶ãªéŸ³éŸ¿"
        case .voiceOver: return "é«˜å“è³ªãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŒ²éŸ³ã€ãƒã‚¤ã‚ºæœ€å°åŒ–"
        case .meeting: return "è¤‡æ•°è©±è€…å¯¾å¿œã€ä¼šè­°å®¤éŸ³éŸ¿æœ€é©åŒ–"
        case .balanced: return "éŸ³å£°ã¨ç’°å¢ƒéŸ³ã®ä¸¡ç«‹ã€æ±ç”¨çš„"
        }
    }
}

class AudioService: ObservableObject {
    var audioRecorder: AVAudioRecorder?
    var audioPlayer: AVAudioPlayer?
    @Published var permissionGranted = false
    @Published var audioLevel: Float = 0.0
    
    // ãƒ‡ãƒãƒƒã‚°ç”¨: éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’ç›´æ¥è¨­å®š
    func setTestAudioLevel(_ level: Float) {
        DispatchQueue.main.async {
            self.audioLevel = max(0.0, min(1.0, level))
        }
    }
    
    // ãƒ‡ãƒãƒƒã‚°ç”¨: AudioEngineéŒ²éŸ³æ™‚ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆéŸ³å£°ãƒ¬ãƒ™ãƒ«
    private var simulatedAudioTimer: Timer?
    
    func startSimulatedAudioForTesting() {
        stopSimulatedAudioForTesting()
        
        simulatedAudioTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            guard let self = self, self.isEngineRecording else { return }
            
            // ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆéŸ³å£°ãƒ¬ãƒ™ãƒ«ï¼ˆå®Ÿéš›ã®ãƒã‚¤ã‚¯ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            let simulatedLevel = Float.random(in: 0.1...0.8)
            DispatchQueue.main.async {
                self.audioLevel = simulatedLevel
                print("ğŸ§ª Simulated AudioEngine level: \(String(format: "%.3f", simulatedLevel))")
            }
        }
        
        print("ğŸ§ª Started simulated audio for AudioEngine testing")
    }
    
    func stopSimulatedAudioForTesting() {
        simulatedAudioTimer?.invalidate()
        simulatedAudioTimer = nil
    }
    
    /// ãƒã‚¤ã‚¯å…¥åŠ›ã®å¼·åˆ¶ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³
    private func forceMicrophoneActivation() throws {
        guard let inputNode = inputNode else {
            throw NSError(domain: "AudioService", code: -4, userInfo: [NSLocalizedDescriptionKey: "Input node not available"])
        }
        
        print("ğŸ¤ Forcing microphone activation...")
        
        // inputNodeã®å…¥åŠ›ã‚’æœ‰åŠ¹åŒ–
        let inputFormat = inputNode.inputFormat(forBus: 0)
        
        // ä¸€æ™‚çš„ãªTapã‚’è¨­å®šã—ã¦ãƒã‚¤ã‚¯å…¥åŠ›ã‚’æ´»æ€§åŒ–
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: inputFormat) { _, _ in
            // ä½•ã‚‚ã—ãªã„ï¼ˆã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ç›®çš„ã®ã¿ï¼‰
        }
        
        // çŸ­æ™‚é–“å¾…æ©Ÿã—ã¦ã‹ã‚‰Tapã‚’å‰Šé™¤
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) {
            inputNode.removeTap(onBus: 0)
            print("ğŸ¤ Microphone activation tap removed")
        }
        
        print("ğŸ¤ Microphone activation initiated")
    }
    @Published var isBackgroundRecordingEnabled = false
    
    // AVAudioEngineé–¢é€£
    private var audioEngine: AVAudioEngine?
    private var inputNode: AVAudioInputNode?
    private var voiceIsolationNode: AVAudioUnitEQ?
    private var recordingFile: AVAudioFile?
    private var isEngineRecording = false
    @Published var voiceIsolationEnabled = false  // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç„¡åŠ¹ï¼ˆEQã«ã‚ˆã‚‹éŸ³å£°é™¤å»å•é¡Œã®ãŸã‚ï¼‰
    @Published var noiseReductionLevel: Float = 0.6
    
    // ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ç®¡ç†
    private var backgroundTaskID: UIBackgroundTaskIdentifier = .invalid
    
    // éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚¿ã‚¤ãƒãƒ¼
    private var levelTimer: Timer?
    
    // ãƒ‡ãƒãƒƒã‚°ç”¨ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    private var audioLevelUpdateCounter: Int = 0
    private var bufferCounter: Int = 0
    private var amplificationLogCount: Int = 0
    
    init() {
        // åˆæœŸåŒ–æ™‚ã¯AudioSessionè¨­å®šã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰
        setupAudioSessionInterruptionHandling()
        setupAudioEngine()
    }
    
    // MARK: - AVAudioEngine Setup
    
    /// AVAudioEngineã¨Voice Isolationã®åˆæœŸåŒ–
    private func setupAudioEngine() {
        print("ğŸ›ï¸ Setting up AVAudioEngine with Voice Isolation")
        
        audioEngine = AVAudioEngine()
        
        guard let engine = audioEngine else {
            print("âŒ Failed to create AVAudioEngine")
            return
        }
        
        inputNode = engine.inputNode
        print("ğŸ›ï¸ AudioEngine input node: \(String(describing: inputNode))")
        
        // inputNodeã®åˆæœŸãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ç¢ºèª
        if let inputNode = inputNode {
            let initialInputFormat = inputNode.inputFormat(forBus: 0)
            print("ğŸ›ï¸ Initial input format: \(initialInputFormat)")
        }
        
        // Voice Isolationç”¨EQãƒãƒ¼ãƒ‰ã‚’ä½œæˆ
        setupVoiceIsolationNode()
        
        print("âœ… AVAudioEngine setup completed")
    }
    
    /// Voice Isolationç”¨ã®EQãƒãƒ¼ãƒ‰ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    private func setupVoiceIsolationNode() {
        guard let engine = audioEngine else { return }
        
        // EQãƒãƒ¼ãƒ‰ã‚’ä½œæˆï¼ˆVoice Isolationã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        voiceIsolationNode = AVAudioUnitEQ(numberOfBands: 10)
        
        guard let eqNode = voiceIsolationNode else {
            print("âŒ Failed to create EQ node for voice isolation")
            return
        }
        
        // éŸ³å£°å‘¨æ³¢æ•°å¸¯åŸŸï¼ˆ300Hz-3400Hzï¼‰ã®å¼·èª¿è¨­å®š
        configureVoiceIsolationEQ(eqNode)
        
        // ãƒãƒ¼ãƒ‰ã‚’ã‚¨ãƒ³ã‚¸ãƒ³ã«è¿½åŠ 
        engine.attach(eqNode)
        
        print("âœ… Voice Isolation EQ node configured")
    }
    
    /// Voice Isolation EQã®è¨­å®š
    private func configureVoiceIsolationEQ(_ eqNode: AVAudioUnitEQ) {
        let bands = eqNode.bands
        
        // 10ãƒãƒ³ãƒ‰EQã§éŸ³å£°å¼·èª¿è¨­å®š
        for (index, band) in bands.enumerated() {
            switch index {
            case 0: // 60Hz - ä½å‘¨æ³¢ãƒã‚¤ã‚ºã‚«ãƒƒãƒˆ
                band.frequency = 60
                band.gain = -12
                band.bandwidth = 1.0
                band.filterType = .highPass
                
            case 1: // 120Hz - ä½å‘¨æ³¢ãƒã‚¤ã‚ºã‚«ãƒƒãƒˆ
                band.frequency = 120
                band.gain = -8
                band.bandwidth = 1.0
                band.filterType = .bandPass
                
            case 2: // 250Hz - éŸ³å£°å¸¯åŸŸå‰ã®èª¿æ•´
                band.frequency = 250
                band.gain = 2
                band.bandwidth = 1.0
                band.filterType = .bandPass
                
            case 3: // 500Hz - åŸºæœ¬éŸ³å£°å‘¨æ³¢æ•°å¼·èª¿
                band.frequency = 500
                band.gain = 4
                band.bandwidth = 1.0
                band.filterType = .bandPass
                
            case 4: // 1kHz - ä¸»è¦éŸ³å£°å‘¨æ³¢æ•°å¼·èª¿
                band.frequency = 1000
                band.gain = 6
                band.bandwidth = 1.0
                band.filterType = .bandPass
                
            case 5: // 2kHz - å­éŸ³ã®æ˜ç­ã•å‘ä¸Š
                band.frequency = 2000
                band.gain = 5
                band.bandwidth = 1.0
                band.filterType = .bandPass
                
            case 6: // 3kHz - éŸ³å£°æ˜ç­åº¦å‘ä¸Š
                band.frequency = 3000
                band.gain = 3
                band.bandwidth = 1.0
                band.filterType = .bandPass
                
            case 7: // 4kHz - é«˜å‘¨æ³¢éŸ³å£°èª¿æ•´
                band.frequency = 4000
                band.gain = 1
                band.bandwidth = 1.0
                band.filterType = .bandPass
                
            case 8: // 8kHz - ä¸è¦ãªé«˜å‘¨æ³¢ã‚«ãƒƒãƒˆ
                band.frequency = 8000
                band.gain = -6
                band.bandwidth = 1.0
                band.filterType = .bandPass
                
            case 9: // 16kHz - é«˜å‘¨æ³¢ãƒã‚¤ã‚ºã‚«ãƒƒãƒˆ
                band.frequency = 16000
                band.gain = -15
                band.bandwidth = 1.0
                band.filterType = .lowPass
                
            default:
                break
            }
            
            band.bypass = !voiceIsolationEnabled
        }
        
        print("ğŸšï¸ Voice Isolation EQ configured with \(bands.count) bands")
    }
    
    /// Voice Isolationã®æœ‰åŠ¹/ç„¡åŠ¹åˆ‡ã‚Šæ›¿ãˆ
    func toggleVoiceIsolation(_ enabled: Bool) {
        voiceIsolationEnabled = enabled
        
        guard let eqNode = voiceIsolationNode else { return }
        
        for band in eqNode.bands {
            band.bypass = !enabled
        }
        
        print("ğŸšï¸ Voice Isolation \(enabled ? "enabled" : "disabled")")
    }
    
    /// ãƒã‚¤ã‚ºãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒ¬ãƒ™ãƒ«ã®èª¿æ•´
    func setNoiseReductionLevel(_ level: Float) {
        noiseReductionLevel = max(0.0, min(1.0, level))
        
        guard let eqNode = voiceIsolationNode else { return }
        
        // ãƒã‚¤ã‚ºãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ã¦EQã®ã‚²ã‚¤ãƒ³ã‚’èª¿æ•´
        let multiplier = noiseReductionLevel
        
        for (index, band) in eqNode.bands.enumerated() {
            switch index {
            case 0, 1: // ä½å‘¨æ³¢ãƒã‚¤ã‚ºã‚«ãƒƒãƒˆå¼·åº¦èª¿æ•´
                band.gain = -12 * multiplier
            case 8, 9: // é«˜å‘¨æ³¢ãƒã‚¤ã‚ºã‚«ãƒƒãƒˆå¼·åº¦èª¿æ•´
                band.gain = -15 * multiplier
            default:
                // éŸ³å£°å¸¯åŸŸã¯èª¿æ•´ã—ãªã„
                break
            }
        }
        
        print("ğŸšï¸ Noise reduction level set to: \(String(format: "%.2f", noiseReductionLevel))")
    }
    
    private func setupAudioSessionOnDemand(recordingMode: RecordingMode = .balanced) {
        let session = AVAudioSession.sharedInstance()
        do {
            print("ğŸ”Š Setting up audio session for mode: \(recordingMode.displayName)")
            
            // æ—¢å­˜ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’éã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«ã™ã‚‹ï¼ˆè¨­å®šå¤‰æ›´ã®ãŸã‚ï¼‰
            if session.isOtherAudioPlaying {
                try session.setActive(false, options: .notifyOthersOnDeactivation)
            }
            
            // ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šï¼ˆéŒ²éŸ³å°‚ç”¨ã«æœ€é©åŒ–ï¼‰
            let sessionMode = recordingMode.audioSessionMode
            var options: AVAudioSession.CategoryOptions = [
                .allowBluetooth,
                .duckOthers,
                .interruptSpokenAudioAndMixWithOthers
            ]
            
            // éŒ²éŸ³æ™‚ã¯.defaultToSpeakerã‚’ä½¿ç”¨ã—ãªã„ï¼ˆãƒã‚¤ã‚¯å„ªå…ˆã®ãŸã‚ï¼‰
            
            // éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®è¿½åŠ ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            switch recordingMode {
            case .conversation, .meeting:
                // éŸ³å£°é€šè©±æœ€é©åŒ–
                options.insert(.allowBluetoothA2DP)
            case .ambient:
                // ç’°å¢ƒéŸ³éŒ²éŸ³ã§ã¯å¤–éƒ¨ãƒã‚¤ã‚¯ã‚’å„ªå…ˆ
                options.insert(.allowAirPlay)
            case .voiceOver:
                // ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŒ²éŸ³ã§ã¯é«˜å“è³ªè¨­å®š
                options.insert(.overrideMutedMicrophoneInterruption)
            case .balanced:
                // ãƒãƒ©ãƒ³ã‚¹ãƒ¢ãƒ¼ãƒ‰ - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨
                break
            }
            
            try session.setCategory(.playAndRecord, mode: sessionMode, options: options)
            print("ğŸ”Š Audio session configured: category=\(session.category), mode=\(sessionMode)")
            
            // WhisperKitæœ€é©åŒ–ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã¨å“è³ªè¨­å®š
            try session.setPreferredSampleRate(16000.0) // WhisperKitæ¨å¥¨ï¼š16kHz
            try session.setPreferredIOBufferDuration(0.010) // 10ms bufferï¼ˆ16kHzã«æœ€é©åŒ–ï¼‰
            
            // ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã®ç¢ºèªã¨è¦æ±‚ï¼ˆiOS17+å¯¾å¿œï¼‰
            if #available(iOS 17.0, *) {
                let currentPermission = AVAudioApplication.shared.recordPermission
                print("ğŸ¤ Current record permission: \(currentPermission.rawValue)")
                
                if currentPermission == .denied {
                    print("âŒ Record permission denied - user must enable in Settings")
                    throw NSError(domain: "AudioService", code: -1, userInfo: [NSLocalizedDescriptionKey: "Microphone permission denied"])
                }
            } else {
                let currentPermission = session.recordPermission
                print("ğŸ¤ Current record permission: \(currentPermission.rawValue)")
                
                if currentPermission == .denied {
                    print("âŒ Record permission denied - user must enable in Settings")
                    throw NSError(domain: "AudioService", code: -1, userInfo: [NSLocalizedDescriptionKey: "Microphone permission denied"])
                }
            }
            
            // æŒ‡å‘æ€§ãƒã‚¤ã‚¯è¨­å®šï¼ˆå¯¾å¿œãƒ‡ãƒã‚¤ã‚¹ã®ã¿ï¼‰
            configureDirectionalMicrophone(for: recordingMode, session: session)
            
            try session.setActive(true)
            print("ğŸ”Š Audio session activated successfully")
            print("ğŸ”Š Actual sample rate: \(session.sampleRate)")
            print("ğŸ”Š Actual IO buffer duration: \(session.ioBufferDuration)")
            
            // ãƒã‚¤ã‚¯ã‚²ã‚¤ãƒ³è¨­å®šï¼ˆãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ã§ã®éŸ³é‡å‘ä¸Šï¼‰
            if session.isInputGainSettable {
                let targetGain: Float = 0.8 // 80%ã®ã‚²ã‚¤ãƒ³ï¼ˆæœ€å¤§éŸ³é‡ã®80%ï¼‰
                try session.setInputGain(targetGain)
                print("ğŸ”Š Input gain set to: \(targetGain) (was: \(session.inputGain))")
            } else {
                print("ğŸ”Š Input gain not settable on this device")
            }
            
            // è¿½åŠ ã®çŠ¶æ…‹ç¢ºèª
            print("ğŸ”Š Input available: \(session.isInputAvailable)")
            print("ğŸ”Š Input gain settable: \(session.isInputGainSettable)")
            if let inputDataSource = session.inputDataSource {
                print("ğŸ”Š Input data source: \(inputDataSource)")
            }
            
        } catch {
            print("âŒ Failed to set up audio session: \(error.localizedDescription)")
            
            // ã‚ˆã‚Šè©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±
            if let nsError = error as NSError? {
                print("âŒ Error domain: \(nsError.domain)")
                print("âŒ Error code: \(nsError.code)")
                print("âŒ Error info: \(nsError.userInfo)")
            }
        }
    }
    
    func requestMicrophonePermission() async -> Bool {
        // æ—¢ã«æ¨©é™ãŒåˆ¤æ˜ã—ã¦ã„ã‚‹å ´åˆã¯ã€éåŒæœŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—
        if #available(iOS 17.0, *) {
            let currentStatus = AVAudioApplication.shared.recordPermission
            
            switch currentStatus {
            case .granted:
                permissionGranted = true
                return true
            case .denied:
                permissionGranted = false
                return false
            case .undetermined:
                // æœªæ±ºå®šã®å ´åˆã®ã¿éåŒæœŸã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
                return await withCheckedContinuation { continuation in
                    AVAudioApplication.requestRecordPermission { granted in
                        DispatchQueue.main.async {
                            self.permissionGranted = granted
                            continuation.resume(returning: granted)
                        }
                    }
                }
            @unknown default:
                permissionGranted = false
                return false
            }
        } else {
            let currentStatus = AVAudioSession.sharedInstance().recordPermission
            
            switch currentStatus {
            case .granted:
                permissionGranted = true
                return true
            case .denied:
                permissionGranted = false
                return false
            case .undetermined:
                // æœªæ±ºå®šã®å ´åˆã®ã¿éåŒæœŸã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
                return await withCheckedContinuation { continuation in
                    AVAudioSession.sharedInstance().requestRecordPermission { granted in
                        DispatchQueue.main.async {
                            self.permissionGranted = granted
                            continuation.resume(returning: granted)
                        }
                    }
                }
            @unknown default:
                permissionGranted = false
                return false
            }
        }
    }

    func startRecording(fileName: String) -> URL? {
        guard permissionGranted else {
            print("âŒ Microphone permission not granted")
            return nil
        }
        
        // ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãƒã‚§ãƒƒã‚¯
        guard checkAvailableDiskSpace() else {
            print("âŒ Insufficient disk space for recording")
            return nil
        }
        
        let url = getDocumentsDirectory().appendingPathComponent(fileName)
        
        // Voice Isolationè¨­å®šã«åŸºã¥ãéŒ²éŸ³æ–¹å¼é¸æŠ
        if voiceIsolationEnabled {
            print("ğŸ›ï¸ Using AVAudioEngine with Voice Isolation")
            return startEngineRecording(url: url)
        } else {
            print("ğŸ™ï¸ Using Traditional Recording (Voice Isolation OFF)")
            return startTraditionalRecording(fileName: fileName, url: url)
        }
    }
    
    // MARK: - AVAudioEngine Recording
    
    /// AVAudioEngineã‚’ä½¿ç”¨ã—ãŸé«˜å“è³ªéŒ²éŸ³
    private func startEngineRecording(url: URL) -> URL? {
        guard let engine = audioEngine,
              let inputNode = inputNode,
              let eqNode = voiceIsolationNode else {
            print("âŒ AVAudioEngine not properly initialized")
            return startTraditionalRecording(fileName: url.lastPathComponent, url: url)
        }
        
        // ã‚¨ãƒ³ã‚¸ãƒ³ãŒå‹•ä½œä¸­ãªã‚‰åœæ­¢
        if engine.isRunning {
            print("ğŸ”„ AudioEngine is running, stopping first...")
            eqNode.removeTap(onBus: 0)
            engine.stop()
        }
        
        do {
            // æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤
            if FileManager.default.fileExists(atPath: url.path) {
                try FileManager.default.removeItem(at: url)
                print("ğŸ—‘ï¸ Existing file removed: \(url.lastPathComponent)")
            }
            
            // AudioSessionè¨­å®š - ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚’ç¢ºå®Ÿã«æœ‰åŠ¹åŒ–
            setupAudioSessionOnDemand()
            
            // ãƒã‚¤ã‚¯ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
            let session = AVAudioSession.sharedInstance()
            print("ğŸ¤ Microphone available: \(session.isInputAvailable)")
            print("ğŸ¤ Input gain settable: \(session.isInputGainSettable)")
            print("ğŸ¤ Current input gain: \(session.inputGain)")
            
            // æ¨©é™ã®æœ€çµ‚ç¢ºèªï¼ˆiOS17+å¯¾å¿œï¼‰
            if #available(iOS 17.0, *) {
                guard AVAudioApplication.shared.recordPermission == .granted else {
                    print("âŒ Record permission not granted at engine start")
                    throw NSError(domain: "AudioService", code: -2, userInfo: [NSLocalizedDescriptionKey: "Microphone access required for recording"])
                }
            } else {
                guard session.recordPermission == .granted else {
                    print("âŒ Record permission not granted at engine start")
                    throw NSError(domain: "AudioService", code: -2, userInfo: [NSLocalizedDescriptionKey: "Microphone access required for recording"])
                }
            }
            
            // ãƒã‚¤ã‚¯ãŒå®Ÿéš›ã«åˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
            guard session.isInputAvailable else {
                print("âŒ No input available at engine start")
                throw NSError(domain: "AudioService", code: -3, userInfo: [NSLocalizedDescriptionKey: "No microphone input available"])
            }
            
            // inputNodeã®å®Ÿéš›ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä½¿ç”¨ï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¸ä¸€è‡´ã‚’é˜²ãï¼‰
            let inputFormat = inputNode.inputFormat(forBus: 0)
            print("ğŸ” Using input format for recording: \(inputFormat)")
            print("ğŸ” Input format details: sampleRate=\(inputFormat.sampleRate), channels=\(inputFormat.channelCount), isInterleaved=\(inputFormat.isInterleaved)")
            
            // WhisperKitæœ€é©åŒ–è¨­å®šï¼ˆ16kHz Linear PCMï¼‰
            let recordingSettings: [String: Any] = [
                AVFormatIDKey: Int(kAudioFormatLinearPCM),  // éåœ§ç¸®PCMï¼ˆç¢ºå®Ÿï¼‰
                AVSampleRateKey: 16000.0,  // WhisperKitæ¨å¥¨
                AVNumberOfChannelsKey: 1,  // ãƒ¢ãƒãƒ©ãƒ«
                AVLinearPCMBitDepthKey: 16,  // 16bit
                AVLinearPCMIsBigEndianKey: false,
                AVLinearPCMIsFloatKey: false,
                AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
            ]
            
            print("ğŸµ AudioEngine recording settings: \(recordingSettings)")
            
            // éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆWhisperKitæœ€é©åŒ–è¨­å®šï¼‰
            recordingFile = try AVAudioFile(forWriting: url, settings: recordingSettings)
            
            // éŸ³å£°å‡¦ç†ãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰
            setupAudioProcessingChain(inputNode: inputNode, eqNode: eqNode, format: inputFormat)
            
            // ã‚¨ãƒ³ã‚¸ãƒ³é–‹å§‹è¨ºæ–­
            print("ğŸ™ï¸ AudioEngine recording diagnostics:")
            print("   - Engine running: \(engine.isRunning)")
            print("   - Input available: \(AVAudioSession.sharedInstance().isInputAvailable)")
            print("   - Recording file: \(url)")
            print("   - Input format: \(inputFormat)")
            
            // ã‚¨ãƒ³ã‚¸ãƒ³é–‹å§‹
            try engine.start()
            isEngineRecording = true
            
            print("   - Engine started: \(engine.isRunning)")
            print("   - Recording started: \(isEngineRecording)")
            
            // AudioEngineéŒ²éŸ³ã§ã‚‚éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚¿ã‚¤ãƒãƒ¼ã‚’é–‹å§‹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            startLevelTimer()
            
            // ãƒã‚¤ã‚¯å…¥åŠ›ã®åˆæœŸåŒ–ã‚’å¼·åˆ¶å®Ÿè¡Œ
            try forceMicrophoneActivation()
            
            // ãƒ†ã‚¹ãƒˆç’°å¢ƒï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼‰ã§ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯éŸ³å£°ãƒ¬ãƒ™ãƒ«ç”Ÿæˆ
            #if targetEnvironment(simulator)
            startSimulatedAudioForTesting()
            print("ğŸ§ª Running on simulator - started simulated audio levels")
            #endif
            
            print("ğŸ›ï¸ AVAudioEngine recording started with Voice Isolation")
            print("   - Sample Rate: \(inputFormat.sampleRate)Hz")
            print("   - Channels: \(inputFormat.channelCount)")
            print("   - Voice Isolation: \(voiceIsolationEnabled)")
            print("   - Noise Reduction: \(String(format: "%.2f", noiseReductionLevel))")
            print("ğŸšï¸ Audio level monitoring enabled for Engine recording")
            
            return url
            
        } catch {
            print("âŒ Failed to start AVAudioEngine recording: \(error)")
            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¾“æ¥ã®éŒ²éŸ³æ–¹å¼
            return startTraditionalRecording(fileName: url.lastPathComponent, url: url)
        }
    }
    
    /// éŸ³å£°å‡¦ç†ãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰
    private func setupAudioProcessingChain(inputNode: AVAudioInputNode, 
                                         eqNode: AVAudioUnitEQ, 
                                         format: AVAudioFormat) {
        guard let engine = audioEngine else { return }
        
        // inputNodeã®å®Ÿéš›ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å–å¾—
        let inputFormat = inputNode.inputFormat(forBus: 0)
        print("ğŸ” Input format: \(inputFormat)")
        print("ğŸ” Using unified input format for recording")
        
        // æ—¢å­˜ã®Tapã‚’ã‚¯ãƒªã‚¢ï¼ˆé‡è¦ï¼šã‚¯ãƒ©ãƒƒã‚·ãƒ¥é˜²æ­¢ï¼‰
        eqNode.removeTap(onBus: 0)
        
        // æ¥ç¶š: Input -> EQï¼ˆinputNodeã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä½¿ç”¨ï¼‰
        engine.connect(inputNode, to: eqNode, format: inputFormat)
        
        // éŒ²éŸ³ã‚¿ãƒƒãƒ—ã®è¨­å®šï¼ˆéŸ³å£°å¢—å¹…æ©Ÿèƒ½ä»˜ãï¼‰
        eqNode.installTap(onBus: 0, bufferSize: 4096, format: inputFormat) { [weak self] buffer, time in
            guard let self = self, let file = self.recordingFile else { 
                print("âš ï¸ Tap received but no self or recordingFile")
                return 
            }
            
            do {
                // éŸ³å£°ã‚’å¢—å¹…ã—ã¦ã‹ã‚‰æ›¸ãè¾¼ã¿ï¼ˆå¢—å¹…ã‚’å‰Šæ¸›ï¼šWhisperKitèªè­˜æ”¹å–„ã®ãŸã‚ï¼‰
                let amplifiedBuffer = self.amplifyAudioBuffer(buffer, gainFactor: 3.0)
                try file.write(from: amplifiedBuffer)
                
                // å¢—å¹…åŠ¹æœã®ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼ˆæœ€åˆã®5å›ã®ã¿ï¼‰
                if self.amplificationLogCount < 5 {
                    self.amplificationLogCount += 1
                    print("ğŸ”Š Audio amplified \(self.amplificationLogCount)/5: gain=10.0x, frames=\(buffer.frameLength)")
                }
                
                // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ãƒ¬ãƒ™ãƒ«å–å¾—ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§æ›´æ–°ï¼‰
                DispatchQueue.main.async {
                    self.updateAudioLevelFromBuffer(buffer)
                }
            } catch {
                print("âŒ Failed to write audio buffer: \(error)")
            }
        }
        
        print("âœ… Audio tap installed successfully on EQ node")
        
        print("âœ… Audio processing chain configured")
    }
    
    /// éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã®å¢—å¹…å‡¦ç†ï¼ˆæ­£è¦åŒ–æ©Ÿèƒ½ä»˜ãï¼‰
    private func amplifyAudioBuffer(_ buffer: AVAudioPCMBuffer, gainFactor: Float) -> AVAudioPCMBuffer {
        guard let floatChannelData = buffer.floatChannelData else {
            print("âš ï¸ Cannot amplify buffer - no float channel data")
            return buffer
        }
        
        // æ–°ã—ã„ãƒãƒƒãƒ•ã‚¡ã‚’ä½œæˆ
        guard let amplifiedBuffer = AVAudioPCMBuffer(pcmFormat: buffer.format, frameCapacity: buffer.frameCapacity) else {
            print("âš ï¸ Cannot create amplified buffer")
            return buffer
        }
        
        amplifiedBuffer.frameLength = buffer.frameLength
        
        // å„ãƒãƒ£ãƒ³ãƒãƒ«ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å¢—å¹…
        let frameLength = Int(buffer.frameLength)
        let channelCount = Int(buffer.format.channelCount)
        
        guard let amplifiedChannelData = amplifiedBuffer.floatChannelData else {
            return buffer
        }
        
        // æœ€å¤§éŸ³é‡ã‚’æ¤œå‡ºã—ã¦ã‹ã‚‰æ­£è¦åŒ–å¢—å¹…
        var maxPeak: Float = 0.0
        for channel in 0..<channelCount {
            let inputData = floatChannelData[channel]
            for frame in 0..<frameLength {
                maxPeak = max(maxPeak, abs(inputData[frame]))
            }
        }
        
        // æ­£è¦åŒ–ä¿‚æ•°ã‚’è¨ˆç®—ï¼ˆæœ€å¤§0.8ã¾ã§ä½¿ç”¨ã—ã¦ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°é˜²æ­¢ï¼‰
        let targetLevel: Float = 0.8
        let normalizedGain = maxPeak > 0.001 ? min(gainFactor, targetLevel / maxPeak) : gainFactor
        
        print("ğŸ”Š Audio amplification: original peak=\(maxPeak), gain=\(normalizedGain), target=\(targetLevel)")
        
        for channel in 0..<channelCount {
            let inputData = floatChannelData[channel]
            let outputData = amplifiedChannelData[channel]
            
            for frame in 0..<frameLength {
                let amplifiedValue = inputData[frame] * normalizedGain
                // ã‚½ãƒ•ãƒˆã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ï¼ˆtanhé–¢æ•°ã§è‡ªç„¶ãªæ­ªã¿ï¼‰
                outputData[frame] = tanh(amplifiedValue)
            }
        }
        
        return amplifiedBuffer
    }
    
    /// ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’å–å¾—
    private func updateAudioLevelFromBuffer(_ buffer: AVAudioPCMBuffer) {
        guard let floatChannelData = buffer.floatChannelData else { 
            print("âš ï¸ No float channel data in buffer")
            return 
        }
        
        let frameLength = Int(buffer.frameLength)
        guard frameLength > 0 else {
            print("âš ï¸ Buffer frame length is 0")
            return
        }
        
        let channelData = floatChannelData[0]
        
        var sum: Float = 0.0
        var maxSample: Float = 0.0
        for i in 0..<frameLength {
            let sample = abs(channelData[i])
            sum += sample * sample
            maxSample = max(maxSample, sample)
        }
        
        let rms = sqrt(sum / Float(frameLength))
        
        // maxSampleã‚’ä½¿ç”¨ã—ã¦ã‚ˆã‚Šæ­£ç¢ºãªdBè¨ˆç®—ï¼ˆå®Ÿæ©Ÿå‘ã‘ï¼‰
        let decibels = maxSample > 0 ? 20 * log10(maxSample) : -200.0
        
        // è©³ç´°ãƒ‡ãƒãƒƒã‚°ï¼ˆ5å›ã«1å›å‡ºåŠ›ã§æ„Ÿåº¦å‘ä¸Šï¼‰
        bufferCounter += 1
        var nonZeroSamples = 0
        for i in 0..<frameLength {
            if abs(channelData[i]) > 0.0 {
                nonZeroSamples += 1
            }
        }
        
        if bufferCounter % 5 == 0 {
            print("ğŸ¤ Buffer #\(bufferCounter): frames=\(frameLength), nonZero=\(nonZeroSamples), maxSample=\(String(format: "%.8f", maxSample)), rms=\(String(format: "%.8f", rms)), dB=\(String(format: "%.1f", decibels))")
        }
        
        // å®Ÿæ©Ÿå‘ã‘è¶…é«˜æ„Ÿåº¦ãƒ¬ãƒ™ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°
        let previousLevel = audioLevel
        var newLevel: Float = 0.0
        
        if maxSample > 0.0 {
            // -160dBã‹ã‚‰-80dBã®ç¯„å›²ã§ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå®Ÿæ©Ÿã§ã®ç’°å¢ƒéŸ³ã€œé€šå¸¸éŸ³å£°ç¯„å›²ï¼‰
            let sensitiveMapping = max(0.0, min(1.0, (decibels + 160.0) / 80.0))
            
            // ã‚ˆã‚Šä½ã„é–¾å€¤ã§ã®æ¤œå‡ºä¿è¨¼
            if rms > 0.0000001 { // 0.1ãƒã‚¤ã‚¯ãƒ­ãƒœãƒ«ãƒˆé–¾å€¤ï¼ˆè¶…é«˜æ„Ÿåº¦ï¼‰
                newLevel = max(sensitiveMapping, 0.1) // æœ€ä½10%ãƒ¬ãƒ™ãƒ«
            } else {
                newLevel = sensitiveMapping
            }
            
            // ãƒ­ã‚°ã§ã®å®Ÿæ©ŸéŸ³å£°ãƒ¬ãƒ™ãƒ«ç¯„å›²ç¢ºèª
            if bufferCounter % 10 == 0 {
                print("ğŸ” Real device audio range: dB=\(String(format: "%.1f", decibels)), mapped=\(String(format: "%.3f", newLevel))")
            }
        }
        
        DispatchQueue.main.async {
            self.audioLevel = newLevel
            
            // ãƒ¬ãƒ™ãƒ«å¤‰åŒ–ã®è©³ç´°ãƒ­ã‚°ï¼ˆéŸ³å£°æ¤œå‡ºæ™‚ã¾ãŸã¯å®šæœŸçš„ï¼‰
            self.audioLevelUpdateCounter += 1
            if newLevel > 0.01 || self.audioLevelUpdateCounter % 20 == 0 {
                print("ğŸšï¸ AudioEngine Level Update #\(self.audioLevelUpdateCounter): \(String(format: "%.3f", newLevel)) (dB: \(String(format: "%.1f", decibels)), nonZero: \(nonZeroSamples))")
            }
        }
    }
    
    /// å¾“æ¥ã®AVAudioRecorderã‚’ä½¿ç”¨ã—ãŸéŒ²éŸ³ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    private func startTraditionalRecording(fileName: String, url: URL) -> URL? {
        let audioStartTime = CFAbsoluteTimeGetCurrent()
        
        do {
            // WhisperKitå¯¾å¿œã®ç¢ºå®ŸãªéŒ²éŸ³è¨­å®šï¼ˆLinear PCMï¼‰
            let settings: [String: Any] = [
                AVFormatIDKey: Int(kAudioFormatLinearPCM),  // éåœ§ç¸®PCMï¼ˆç¢ºå®Ÿï¼‰
                AVSampleRateKey: 16000.0,  // WhisperKitæ¨å¥¨ï¼š16kHz
                AVNumberOfChannelsKey: 1,  // ãƒ¢ãƒãƒ©ãƒ«
                AVLinearPCMBitDepthKey: 16,  // 16bit
                AVLinearPCMIsBigEndianKey: false,
                AVLinearPCMIsFloatKey: false,
                AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
            ]
            
            // æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤
            if FileManager.default.fileExists(atPath: url.path) {
                try FileManager.default.removeItem(at: url)
                print("ğŸ—‘ï¸ Existing file removed: \(fileName)")
            }
            
            audioRecorder = try AVAudioRecorder(url: url, settings: settings)
            audioRecorder?.isMeteringEnabled = true
            audioRecorder?.prepareToRecord()
            
            // AudioSessionè¨­å®š
            setupAudioSessionOnDemand()
            
            let prepareResult = audioRecorder?.prepareToRecord() ?? false
            let recordStarted = audioRecorder?.record() ?? false
            
            // éŒ²éŸ³çŠ¶æ…‹ã®è©³ç´°è¨ºæ–­
            print("ğŸ™ï¸ Recording diagnostics:")
            print("   - Prepare result: \(prepareResult)")
            print("   - Record started: \(recordStarted)")
            print("   - Recorder isRecording: \(audioRecorder?.isRecording ?? false)")
            print("   - File URL: \(url)")
            print("   - Settings: \(settings)")
            
            let audioSetupDuration = (CFAbsoluteTimeGetCurrent() - audioStartTime) * 1000
            print("ğŸµ Traditional recording setup duration: \(String(format: "%.1f", audioSetupDuration))ms")
            print("ğŸ¯ Traditional recording started: \(recordStarted)")
            
            // éŒ²éŸ³é–‹å§‹å¤±æ•—æ™‚ã®å›å¾©ç­–
            if !recordStarted {
                try handleRecordingFailure(url: url, settings: settings)
            }
            
            // éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚¿ã‚¤ãƒãƒ¼ã‚’é–‹å§‹
            startLevelTimer()
            
            return url
        } catch {
            print("âŒ Failed to start traditional recording: \(error.localizedDescription)")
            return nil
        }
    }
    
    /// éŒ²éŸ³å¤±æ•—æ™‚ã®å›å¾©å‡¦ç†
    private func handleRecordingFailure(url: URL, settings: [String: Any]) throws {
        print("ğŸ”Š Attempting recording recovery...")
        
        // AudioSessionã‚’ãƒªã‚»ãƒƒãƒˆ
        try AVAudioSession.sharedInstance().setActive(false)
        try AVAudioSession.sharedInstance().setActive(true)
        
        // AudioRecorderã‚’å†ä½œæˆ
        audioRecorder = try AVAudioRecorder(url: url, settings: settings)
        audioRecorder?.isMeteringEnabled = true
        audioRecorder?.prepareToRecord()
        
        let retryResult = audioRecorder?.record() ?? false
        print("ğŸ”Š Recovery attempt result: \(retryResult)")
        
        if !retryResult {
            print("âŒ Recording recovery failed")
        }
    }

    func pauseRecording() {
        guard let recorder = audioRecorder, recorder.isRecording else { 
            print("âš ï¸ Cannot pause: No active recording")
            return 
        }
        
        print("â¸ï¸ Pausing recording...")
        recorder.pause()
        audioLevel = 0.0
    }
    
    func resumeRecording() {
        guard let recorder = audioRecorder else { 
            print("âš ï¸ Cannot resume: No recorder available")
            return 
        }
        
        print("â–¶ï¸ Resuming recording...")
        let resumed = recorder.record()
        if resumed {
            print("âœ… Recording resumed successfully")
        } else {
            print("âŒ Failed to resume recording")
        }
    }
    
    func stopRecording() {
        // AVAudioEngineéŒ²éŸ³ã®å ´åˆ
        if isEngineRecording {
            stopEngineRecording()
        } else if let recorder = audioRecorder {
            stopTraditionalRecording(recorder: recorder)
        }
        
        audioLevel = 0.0
        stopLevelTimer() // ã‚¿ã‚¤ãƒãƒ¼ã‚’åœæ­¢
        stopSimulatedAudioForTesting() // ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆéŸ³å£°ã‚‚åœæ­¢
        print("âœ… Recording stopped")
    }
    
    /// AVAudioEngineéŒ²éŸ³ã®åœæ­¢
    private func stopEngineRecording() {
        guard let engine = audioEngine,
              let eqNode = voiceIsolationNode else { return }
        
        print("ğŸ›‘ Stopping AVAudioEngine recording...")
        
        // ã‚¿ãƒƒãƒ—ã‚’å‰Šé™¤
        eqNode.removeTap(onBus: 0)
        
        // ã‚¨ãƒ³ã‚¸ãƒ³åœæ­¢
        engine.stop()
        isEngineRecording = false
        
        // éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®URLã‚’ä¿å­˜ã—ã¦ã‹ã‚‰é–‰ã˜ã‚‹
        let recordingURL = recordingFile?.url
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‰ã˜ã‚‹
        recordingFile = nil
        
        print("âœ… AVAudioEngine recording stopped")
        
        // ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ï¼ˆé…å»¶å®Ÿè¡Œã§ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿å®Œäº†ã‚’å¾…ã¤ï¼‰
        if let url = recordingURL {
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                self.validateRecordedFile(at: url)
                print("âœ… AudioEngine recording file validation completed")
            }
        }
    }
    
    /// å¾“æ¥éŒ²éŸ³ã®åœæ­¢
    private func stopTraditionalRecording(recorder: AVAudioRecorder) {
        let recordingURL = recorder.url
        print("ğŸ›‘ Stopping traditional recording...")
        
        recorder.stop()
        
        // éŒ²éŸ³ãŒå®Œå…¨ã«åœæ­¢ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ãŒé–‰ã˜ã‚‰ã‚Œã‚‹ã¾ã§å¾…æ©Ÿã—ã¦ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
            self.validateRecordedFile(at: recordingURL)
            print("âœ… Traditional recording stopped and file completely closed")
        }
        
        audioRecorder = nil
    }
    
    func discardRecording() {
        guard let recorder = audioRecorder else { return }
        
        let recordingURL = recorder.url
        print("ğŸ—‘ï¸ Discarding recording...")
        recorder.stop()
        audioLevel = 0.0
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
            do {
                if FileManager.default.fileExists(atPath: recordingURL.path) {
                    try FileManager.default.removeItem(at: recordingURL)
                    print("ğŸ—‘ï¸ Recording file deleted successfully")
                }
            } catch {
                print("âš ï¸ Failed to delete recording file: \(error.localizedDescription)")
            }
        }
        
        audioRecorder = nil
    }
    
    var isRecording: Bool {
        return isEngineRecording || (audioRecorder?.isRecording ?? false)
    }
    
    var isPaused: Bool {
        guard let recorder = audioRecorder else { return false }
        return !recorder.isRecording && recorder.url.path.contains(".m4a")
    }
    
    func updateAudioLevel() {
        // AVAudioEngineã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã¯ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ¬ãƒ™ãƒ«ãŒæ›´æ–°ã•ã‚Œã‚‹
        if isEngineRecording {
            // updateAudioLevelFromBufferã§æ—¢ã«æ›´æ–°ã•ã‚Œã¦ã„ã‚‹ã®ã§ãã®ã¾ã¾
            return
        }
        
        // å¾“æ¥ã®AVAudioRecorderä½¿ç”¨æ™‚
        guard let recorder = audioRecorder, recorder.isRecording else {
            audioLevel = 0.0
            return
        }
        
        recorder.updateMeters()
        let averagePower = recorder.averagePower(forChannel: 0)
        
        // ç„¡éŸ³é–¾å€¤ã‚’è¨­å®šï¼ˆ-55dBä»¥ä¸‹ã¯ç„¡éŸ³ã¨ã¿ãªã™ï¼‰
        let silenceThreshold: Float = -55.0
        let minDecibels: Float = -45.0
        
        if averagePower < silenceThreshold {
            audioLevel = 0.0
        } else {
            let normalizedLevel = max(0.0, (averagePower - minDecibels) / -minDecibels)
            // éŸ³å£°ãŒã‚ã‚‹å ´åˆã®ã¿å¹³æ–¹æ ¹ã§åå¿œã‚’å¼·åŒ–
            audioLevel = sqrt(normalizedLevel)
        }
    }
    
    // MARK: - Audio Level Timer
    
    /// éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚¿ã‚¤ãƒãƒ¼ã‚’é–‹å§‹
    private func startLevelTimer() {
        stopLevelTimer() // æ—¢å­˜ã®ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
        
        levelTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            DispatchQueue.main.async {
                self?.updateAudioLevels()
            }
        }
        
        print("ğŸšï¸ Audio level timer started")
    }
    
    /// å¾…æ©ŸçŠ¶æ…‹ã®éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚’é–‹å§‹ï¼ˆéŒ²éŸ³å‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºç”¨ï¼‰
    func startStandbyAudioMonitoring() {
        // æ¨©é™ãƒã‚§ãƒƒã‚¯
        guard permissionGranted else {
            print("âš ï¸ Cannot start audio monitoring - permission not granted")
            return
        }
        
        // AudioSessionã‚’è¨­å®š
        setupAudioSessionOnDemand()
        
        // ãƒ¬ãƒ™ãƒ«ã‚¿ã‚¤ãƒãƒ¼ã‚’é–‹å§‹ï¼ˆå¾…æ©ŸçŠ¶æ…‹ã§ã‚‚éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’å–å¾—ï¼‰
        startLevelTimer()
        
        print("ğŸšï¸ Standby audio monitoring started")
    }
    
    /// å¾…æ©ŸçŠ¶æ…‹ã®éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚’åœæ­¢
    func stopStandbyAudioMonitoring() {
        stopLevelTimer()
        audioLevel = 0.0
        print("ğŸšï¸ Standby audio monitoring stopped")
    }
    
    /// éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚¿ã‚¤ãƒãƒ¼ã‚’åœæ­¢
    private func stopLevelTimer() {
        levelTimer?.invalidate()
        levelTimer = nil
    }
    
    /// éŸ³å£°ãƒ¬ãƒ™ãƒ«æ›´æ–°ï¼ˆAVAudioRecorderç”¨ + EngineéŒ²éŸ³ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    private func updateAudioLevels() {
        // EngineéŒ²éŸ³ä¸­ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯éŸ³å£°ãƒ¬ãƒ™ãƒ«å–å¾—ã‚’è©¦è¡Œ
        if isEngineRecording {
            // AudioEngineã®Tapã‹ã‚‰éŸ³å£°ãƒ¬ãƒ™ãƒ«ãŒæ›´æ–°ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
            // æ›´æ–°ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ä½•ã‚‚ã—ãªã„ï¼ˆTapã‹ã‚‰ã®æ›´æ–°ã‚’å„ªå…ˆï¼‰
            return
        }
        
        // å¾“æ¥ã®AVAudioRecorderä½¿ç”¨æ™‚
        guard let recorder = audioRecorder, recorder.isRecording else {
            audioLevel = 0.0
            return
        }
        
        recorder.updateMeters()
        let averagePower = recorder.averagePower(forChannel: 0)
        
        // ç„¡éŸ³é–¾å€¤ã‚’è¨­å®šï¼ˆ-55dBä»¥ä¸‹ã¯ç„¡éŸ³ã¨ã¿ãªã™ï¼‰
        let silenceThreshold: Float = -55.0
        let minDecibels: Float = -45.0
        
        let previousLevel = audioLevel
        
        if averagePower < silenceThreshold {
            audioLevel = 0.0
        } else {
            let normalizedLevel = max(0.0, (averagePower - minDecibels) / -minDecibels)
            // éŸ³å£°ãŒã‚ã‚‹å ´åˆã®ã¿å¹³æ–¹æ ¹ã§åå¿œã‚’å¼·åŒ–
            audioLevel = sqrt(normalizedLevel)
        }
        
        // ãƒ‡ãƒãƒƒã‚°: AVAudioRecorderã®éŸ³å£°ãƒ¬ãƒ™ãƒ«æ›´æ–°ãƒ­ã‚°ï¼ˆå¤‰åŒ–ãŒã‚ã£ãŸå ´åˆï¼‰
        if abs(audioLevel - previousLevel) > 0.05 || audioLevel > 0.1 {
            print("ğŸšï¸ AVAudioRecorder Level Update: \(String(format: "%.3f", audioLevel)) (dB: \(String(format: "%.1f", averagePower)))")
        }
    }

    func getDocumentsDirectory() -> URL {
        let paths = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)
        return paths[0]
    }
    
    /// éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
    private func validateRecordedFile(at url: URL) {
        do {
            // ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            guard FileManager.default.fileExists(atPath: url.path) else {
                print("âŒ Recorded file does not exist: \(url.path)")
                return
            }
            
            // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
            let attributes = try FileManager.default.attributesOfItem(atPath: url.path)
            let fileSize = attributes[.size] as? UInt64 ?? 0
            
            if fileSize == 0 {
                print("âŒ Recorded file is empty: \(url.lastPathComponent)")
                return
            }
            
            if fileSize < 1024 { // 1KBæœªæº€ã¯ç•°å¸¸ã«å°ã•ã„
                print("âš ï¸ Recorded file is very small (\(fileSize) bytes): \(url.lastPathComponent)")
            }
            
            // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
            let asset = AVURLAsset(url: url)
            let duration = asset.duration.seconds
            
            print("ğŸ“Š Recording validation:")
            print("   - File size: \(fileSize) bytes")
            print("   - Duration: \(String(format: "%.2f", duration)) seconds")
            print("   - Estimated bitrate: \(fileSize > 0 && duration > 0 ? Int((Double(fileSize) * 8) / duration) : 0) bps")
            
            // éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ã®ç¢ºèª
            let audioTracks = asset.tracks(withMediaType: .audio)
            if audioTracks.isEmpty {
                print("âŒ No audio tracks found in recorded file")
            } else {
                for (index, track) in audioTracks.enumerated() {
                    print("   - Audio track \(index): \(track.formatDescriptions.count) format(s)")
                }
            }
            
            // æœ€çµ‚æ¤œè¨¼
            if duration > 0 {
                print("âœ… Recorded file validation passed: \(fileSize) bytes, \(String(format: "%.2f", duration))s")
            } else {
                print("âŒ Recorded file has invalid duration: \(url.lastPathComponent)")
            }
            
        } catch {
            print("âŒ Failed to validate recorded file: \(error.localizedDescription)")
        }
    }
    
    /// éŒ²éŸ³å¤±æ•—æ™‚ã®è¨ºæ–­
    private func diagnoseRecordingFailure(recorder: AVAudioRecorder) {
        print("ğŸ” --- Recording Failure Diagnosis ---")
        
        // AudioRecorderã®çŠ¶æ…‹
        print("ğŸ” Recorder metering enabled: \(recorder.isMeteringEnabled)")
        print("ğŸ” Recorder format: \(recorder.format.description)")
        print("ğŸ” Recorder settings: \(recorder.settings)")
        
        // AudioSessionã®è©³ç´°çŠ¶æ…‹
        let session = AVAudioSession.sharedInstance()
        print("ğŸ” Session category: \(session.category)")
        print("ğŸ” Session mode: \(session.mode)")
        print("ğŸ” Session options: \(session.categoryOptions)")
        print("ğŸ” Session active: \(session.isOtherAudioPlaying)")
        print("ğŸ” Input available: \(session.isInputAvailable)")
        print("ğŸ” Input routes: \(session.availableInputs?.map { $0.portName } ?? [])")
        print("ğŸ” Current route inputs: \(session.currentRoute.inputs.map { $0.portName })")
        print("ğŸ” Current route outputs: \(session.currentRoute.outputs.map { $0.portName })")
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
        let url = recorder.url
        print("ğŸ” File path: \(url.path)")
        print("ğŸ” File exists: \(FileManager.default.fileExists(atPath: url.path))")
        print("ğŸ” Directory writable: \(FileManager.default.isWritableFile(atPath: url.deletingLastPathComponent().path))")
        
        // å†è©¦è¡Œ
        print("ğŸ” Attempting to restart recording...")
        let retryResult = recorder.record()
        print("ğŸ” Retry result: \(retryResult)")
        print("ğŸ” --- End Diagnosis ---")
    }
    
    // MARK: - æŒ‡å‘æ€§ãƒã‚¤ã‚¯è¨­å®š
    
    /// æŒ‡å‘æ€§ãƒã‚¤ã‚¯ã®è¨­å®šï¼ˆiPhoneå¯¾å¿œï¼‰
    private func configureDirectionalMicrophone(for mode: RecordingMode, session: AVAudioSession) {
        do {
            // åˆ©ç”¨å¯èƒ½ãªå…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ã‚’ç¢ºèª
            guard let availableInputs = session.availableInputs else {
                print("ğŸ¤ No available inputs found")
                return
            }
            
            print("ğŸ¤ Available inputs: \(availableInputs.map { $0.portName })")
            
            // å†…è”µãƒã‚¤ã‚¯ã‚’æ¢ã™
            let builtInMic = availableInputs.first { input in
                input.portType == .builtInMic
            }
            
            guard let builtIn = builtInMic else {
                print("ğŸ¤ Built-in microphone not found")
                return
            }
            
            // å†…è”µãƒã‚¤ã‚¯ã‚’å„ªå…ˆå…¥åŠ›ã«è¨­å®š
            try session.setPreferredInput(builtIn)
            print("ğŸ¤ Preferred input set to: \(builtIn.portName)")
            
            // ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¨­å®šï¼ˆæŒ‡å‘æ€§å¯¾å¿œï¼‰
            if let dataSources = builtIn.dataSources, !dataSources.isEmpty {
                print("ğŸ¤ Available data sources: \(dataSources.map { $0.dataSourceName })")
                
                // ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠ
                let preferredDataSource = selectDataSource(for: mode, from: dataSources)
                
                if let preferred = preferredDataSource {
                    try builtIn.setPreferredDataSource(preferred)
                    print("ğŸ¤ Preferred data source set to: \(preferred.dataSourceName)")
                }
            }
            
            // å…¥åŠ›ã‚²ã‚¤ãƒ³è¨­å®š
            if session.isInputGainSettable {
                let targetGain = getTargetGain(for: mode)
                try session.setInputGain(targetGain)
                print("ğŸ¤ Input gain set to: \(targetGain)")
            }
            
        } catch {
            print("âŒ Failed to configure directional microphone: \(error)")
        }
    }
    
    /// ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠ
    private func selectDataSource(for mode: RecordingMode, from dataSources: [AVAudioSessionDataSourceDescription]) -> AVAudioSessionDataSourceDescription? {
        switch mode {
        case .conversation, .meeting:
            // ãƒ•ãƒ­ãƒ³ãƒˆå‘ããƒã‚¤ã‚¯ï¼ˆãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°å¯¾å¿œï¼‰
            return dataSources.first { $0.dataSourceName.contains("Front") || $0.dataSourceName.contains("Top") }
        case .ambient:
            // å…¨æ–¹å‘ãƒã‚¤ã‚¯
            return dataSources.first { $0.dataSourceName.contains("Back") || $0.dataSourceName.contains("Bottom") }
        case .voiceOver:
            // é«˜æ„Ÿåº¦ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¤ã‚¯
            return dataSources.first { $0.dataSourceName.contains("Front") }
        case .balanced:
            // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            return dataSources.first
        }
    }
    
    /// ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®å…¥åŠ›ã‚²ã‚¤ãƒ³è¨­å®š
    private func getTargetGain(for mode: RecordingMode) -> Float {
        switch mode {
        case .conversation, .voiceOver:
            return 0.8  // é«˜æ„Ÿåº¦
        case .ambient:
            return 0.6  // æ¨™æº–æ„Ÿåº¦
        case .meeting:
            return 0.7  // ä¸­ï½é«˜æ„Ÿåº¦
        case .balanced:
            return 0.65 // ãƒãƒ©ãƒ³ã‚¹
        }
    }
    
    // MARK: - AudioSessionä¸­æ–­å‡¦ç†
    
    /// AudioSessionä¸­æ–­å‡¦ç†ã®è¨­å®š
    private func setupAudioSessionInterruptionHandling() {
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleAudioSessionInterruption),
            name: AVAudioSession.interruptionNotification,
            object: nil
        )
        
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleAudioSessionRouteChange),
            name: AVAudioSession.routeChangeNotification,
            object: nil
        )
        
        print("ğŸ”” AudioSession interruption handling setup completed")
    }
    
    /// AudioSessionä¸­æ–­é€šçŸ¥ã®å‡¦ç†
    @objc private func handleAudioSessionInterruption(notification: Notification) {
        guard let userInfo = notification.userInfo,
              let typeValue = userInfo[AVAudioSessionInterruptionTypeKey] as? UInt,
              let type = AVAudioSession.InterruptionType(rawValue: typeValue) else {
            return
        }
        
        print("ğŸš« AudioSession interruption detected: \(type)")
        
        switch type {
        case .began:
            print("ğŸš« Audio session interrupted - recording will be paused")
            // éŒ²éŸ³ä¸­æ–­ã‚’è¨˜éŒ²ï¼ˆè‡ªå‹•çš„ã«AVAudioRecorderãŒä¸€æ™‚åœæ­¢ï¼‰
            
        case .ended:
            if let optionsValue = userInfo[AVAudioSessionInterruptionOptionKey] as? UInt {
                let options = AVAudioSession.InterruptionOptions(rawValue: optionsValue)
                if options.contains(.shouldResume) {
                    print("ğŸ”„ Audio session interruption ended - attempting to resume")
                    resumeAudioSessionAfterInterruption()
                } else {
                    print("âš ï¸ Audio session interruption ended but should not resume")
                }
            }
        @unknown default:
            print("âš ï¸ Unknown interruption type: \(type)")
            break
        }
    }
    
    /// AudioSessionãƒ«ãƒ¼ãƒˆå¤‰æ›´é€šçŸ¥ã®å‡¦ç†
    @objc private func handleAudioSessionRouteChange(notification: Notification) {
        guard let userInfo = notification.userInfo,
              let reasonValue = userInfo[AVAudioSessionRouteChangeReasonKey] as? UInt,
              let reason = AVAudioSession.RouteChangeReason(rawValue: reasonValue) else {
            return
        }
        
        print("ğŸ”„ AudioSession route changed: \(reason)")
        
        switch reason {
        case .newDeviceAvailable:
            print("ğŸ§ New audio device connected")
        case .oldDeviceUnavailable:
            print("ğŸ§ Audio device disconnected")
        case .categoryChange:
            print("ğŸ“± Audio category changed")
        case .override:
            print("ğŸ”„ Audio route override")
        case .wakeFromSleep:
            print("ğŸ˜´ Audio route changed due to wake from sleep")
        case .noSuitableRouteForCategory:
            print("âŒ No suitable route for current category")
        case .routeConfigurationChange:
            print("âš™ï¸ Route configuration changed")
        @unknown default:
            print("â“ Unknown route change reason: \(reason)")
        }
    }
    
    /// ä¸­æ–­å¾Œã®AudioSessionå¾©å¸°å‡¦ç†
    private func resumeAudioSessionAfterInterruption() {
        do {
            try AVAudioSession.sharedInstance().setActive(true)
            print("âœ… AudioSession reactivated after interruption")
            
            // éŒ²éŸ³ãŒç¶™ç¶šã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if let recorder = audioRecorder, !recorder.isRecording {
                print("ğŸ”„ Attempting to resume recording after interruption")
                let resumed = recorder.record()
                print("ğŸ“± Recording resume result: \(resumed)")
            }
            
        } catch {
            print("âŒ Failed to reactivate AudioSession after interruption: \(error)")
        }
    }
    
    // MARK: - ãƒ¡ãƒ¢ãƒªç®¡ç†ãƒ»æœ€é©åŒ–
    
    /// ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ç›£è¦–
    private func checkAvailableDiskSpace() -> Bool {
        do {
            let documentDirectory = getDocumentsDirectory()
            let systemAttributes = try FileManager.default.attributesOfFileSystem(forPath: documentDirectory.path)
            
            if let freeSize = systemAttributes[.systemFreeSize] as? NSNumber {
                let freeSizeGB = freeSize.doubleValue / (1024 * 1024 * 1024)
                print("ğŸ’¾ Available disk space: \(String(format: "%.1f", freeSizeGB))GB")
                
                // 1GBæœªæº€ã®å ´åˆã¯è­¦å‘Š
                if freeSizeGB < 1.0 {
                    print("âš ï¸ Low disk space warning: \(String(format: "%.1f", freeSizeGB))GB remaining")
                    return false
                }
                return true
            }
        } catch {
            print("âŒ Failed to check disk space: \(error)")
        }
        return false
    }
    
    /// ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å–å¾—
    private func getMemoryUsage() -> UInt64 {
        var info = mach_task_basic_info()
        var count = mach_msg_type_number_t(MemoryLayout<mach_task_basic_info>.size)/4
        
        let result = withUnsafeMutablePointer(to: &info) {
            $0.withMemoryRebound(to: integer_t.self, capacity: 1) {
                task_info(mach_task_self_,
                         task_flavor_t(MACH_TASK_BASIC_INFO),
                         $0,
                         &count)
            }
        }
        
        if result == KERN_SUCCESS {
            return info.resident_size
        } else {
            return 0
        }
    }
    
    // MARK: - Background Recording Support
    
    /// ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰éŒ²éŸ³ç”¨ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®š
    func setupBackgroundRecording() throws {
        let session = AVAudioSession.sharedInstance()
        
        print("ğŸ“± Setting up background recording capability...")
        
        do {
            // ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰éŒ²éŸ³ç”¨ã‚«ãƒ†ã‚´ãƒªè¨­å®šï¼ˆ.defaultToSpeakerã‚’å‰Šé™¤ï¼‰
            try session.setCategory(
                .record,                    // éŒ²éŸ³å°‚ç”¨ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å¯¾å¿œï¼‰
                mode: .default,             // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ¼ãƒ‰
                options: [.mixWithOthers, .allowBluetooth]
            )
            
            // ã‚»ãƒƒã‚·ãƒ§ãƒ³æœ‰åŠ¹åŒ–
            try session.setActive(true)
            
            isBackgroundRecordingEnabled = true
            
            print("âœ… Background recording enabled successfully")
            print("   - Category: \(session.category)")
            print("   - Mode: \(session.mode)")
            print("   - Input available: \(session.isInputAvailable)")
            
        } catch {
            isBackgroundRecordingEnabled = false
            print("âŒ Failed to enable background recording: \(error)")
            throw error
        }
    }
    
    /// é€šå¸¸éŒ²éŸ³ç”¨ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šã«æˆ»ã™
    func setupStandardRecording(recordingMode: RecordingMode = .balanced) throws {
        let session = AVAudioSession.sharedInstance()
        
        print("ğŸ“± Setting up standard recording mode...")
        
        do {
            let sessionMode = recordingMode.audioSessionMode
            var options: AVAudioSession.CategoryOptions = [.defaultToSpeaker, .allowBluetooth]
            
            // æ¨™æº–éŒ²éŸ³ç”¨ã‚«ãƒ†ã‚´ãƒªè¨­å®š
            try session.setCategory(.playAndRecord, mode: sessionMode, options: options)
            try session.setActive(true)
            
            isBackgroundRecordingEnabled = false
            
            print("âœ… Standard recording enabled successfully")
            
        } catch {
            print("âŒ Failed to enable standard recording: \(error)")
            throw error
        }
    }
    
    /// ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯é–‹å§‹
    private func startBackgroundTask() {
        guard backgroundTaskID == .invalid else {
            print("âš ï¸ Background task already running")
            return
        }
        
        backgroundTaskID = UIApplication.shared.beginBackgroundTask(
            withName: "AudioRecording"
        ) { [weak self] in
            print("ğŸ”„ Background task expiring - ending task")
            self?.endBackgroundTask()
        }
        
        print("ğŸ“± Background task started: \(backgroundTaskID.rawValue)")
    }
    
    /// ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯çµ‚äº†
    private func endBackgroundTask() {
        guard backgroundTaskID != .invalid else { return }
        
        UIApplication.shared.endBackgroundTask(backgroundTaskID)
        backgroundTaskID = .invalid
        
        print("ğŸ“± Background task ended")
    }
    
    /// éŒ²éŸ³é–‹å§‹æ™‚ã«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã‚’è‡ªå‹•é–‹å§‹
    func startRecordingWithBackgroundSupport(at url: URL, settings: [String: Any]) throws {
        // ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯é–‹å§‹
        startBackgroundTask()
        
        // é€šå¸¸ã®éŒ²éŸ³é–‹å§‹
        audioRecorder = try AVAudioRecorder(url: url, settings: settings)
        audioRecorder?.record()
        
        print("ğŸ™ï¸ Recording started with background support")
    }
    
    /// éŒ²éŸ³åœæ­¢æ™‚ã«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã‚’çµ‚äº†
    func stopRecordingWithBackgroundSupport() {
        audioRecorder?.stop()
        audioRecorder = nil
        
        // ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯çµ‚äº†
        endBackgroundTask()
        
        print("ğŸ™ï¸ Recording stopped and background task ended")
    }
    
    deinit {
        NotificationCenter.default.removeObserver(self)
        endBackgroundTask()
    }
}
