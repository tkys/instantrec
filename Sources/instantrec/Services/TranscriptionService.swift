import Foundation
import Speech
import AVFoundation
import CoreMedia

#if canImport(UIKit)
import UIKit
#endif

/// Simulatoræ¤œå‡ºã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
private extension TranscriptionService {
    static var isSimulator: Bool {
        // ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ãƒã‚§ãƒƒã‚¯
        #if targetEnvironment(simulator)
        return true
        #else
        // å®Ÿè¡Œæ™‚ãƒã‚§ãƒƒã‚¯ï¼ˆè¤‡æ•°ã®æ–¹æ³•ã§ç¢ºå®Ÿã«æ¤œå‡ºï¼‰
        #if canImport(UIKit)
        if UIDevice.current.model.contains("Simulator") {
            return true
        }
        #endif
        
        let env = ProcessInfo.processInfo.environment
        return env["SIMULATOR_DEVICE_NAME"] != nil ||
               env["SIMULATOR_UDID"] != nil ||
               env["SIMULATOR_ROOT"] != nil
        #endif
    }
}

/// Apple Speech Frameworkã‚’ä½¿ç”¨ã—ãŸæ–‡å­—èµ·ã“ã—ã‚µãƒ¼ãƒ“ã‚¹
/// ãƒ‡ãƒãƒƒã‚°POCç”¨ã®å®Ÿè£…
class TranscriptionService: ObservableObject {
    
    // MARK: - Published Properties
    
    /// éŸ³å£°èªè­˜æ¨©é™ã®çŠ¶æ…‹
    @Published var authorizationStatus: SFSpeechRecognizerAuthorizationStatus = .notDetermined
    
    /// æ–‡å­—èµ·ã“ã—çµæœ
    @Published var transcriptionText: String = ""
    
    /// å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°
    @Published var isTranscribing: Bool = false
    
    /// ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    @Published var errorMessage: String?
    
    /// å‡¦ç†æ™‚é–“ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    @Published var processingTime: TimeInterval = 0.0
    
    // MARK: - Private Properties
    
    /// éŸ³å£°èªè­˜ã‚¨ãƒ³ã‚¸ãƒ³
    private let speechRecognizer: SFSpeechRecognizer?
    
    /// èªè­˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    
    /// èªè­˜ã‚¿ã‚¹ã‚¯
    private var recognitionTask: SFSpeechRecognitionTask?
    
    // MARK: - Singleton
    
    static let shared = TranscriptionService()
    
    private init() {
        let simulatorCheck = Self.isSimulator
        print("ğŸ” Simulator detection: \(simulatorCheck)")
        
        if simulatorCheck {
            // iOS Simulatorã§ã¯éŸ³å£°èªè­˜ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–ã›ãšã€æ¨©é™ã‚’è‡ªå‹•è¨±å¯
            speechRecognizer = nil
            authorizationStatus = .authorized
            print("ğŸ—£ï¸ TranscriptionService initialized for iOS Simulator with mock mode")
        } else {
            // æ—¥æœ¬èªã®éŸ³å£°èªè­˜ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–
            speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "ja-JP"))
            authorizationStatus = SFSpeechRecognizer.authorizationStatus()
            print("ğŸ—£ï¸ TranscriptionService initialized with locale: ja-JP")
            print("ğŸ” Current authorization status: \(authorizationStatus.rawValue)")
        }
    }
    
    // MARK: - Authorization
    
    /// éŸ³å£°èªè­˜æ¨©é™ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    func requestAuthorization() async -> Bool {
        if Self.isSimulator {
            // iOS Simulatorã§ã¯æ¨©é™ã‚’è‡ªå‹•çš„ã«è¨±å¯ã¨ã—ã¦æ‰±ã†
            print("ğŸ“± iOS Simulator: Auto-granting speech recognition permission")
            await MainActor.run {
                self.authorizationStatus = .authorized
            }
            return true
        } else {
            return await withCheckedContinuation { continuation in
                SFSpeechRecognizer.requestAuthorization { [weak self] status in
                    DispatchQueue.main.async {
                        self?.authorizationStatus = status
                        let isGranted = status == .authorized
                        print("ğŸ” Speech recognition authorization: \(isGranted ? "granted" : "denied")")
                        continuation.resume(returning: isGranted)
                    }
                }
            }
        }
    }
    
    // MARK: - Transcription
    
    /// éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—
    /// - Parameter audioURL: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®URL
    func transcribeAudioFile(at audioURL: URL) async throws {
        print("ğŸ—£ï¸ Starting transcription for file: \(audioURL.lastPathComponent)")
        
        await MainActor.run {
            isTranscribing = true
            transcriptionText = ""
            errorMessage = nil
            processingTime = 0.0
        }
        
        let startTime = Date()
        
        // æ¨©é™ãƒã‚§ãƒƒã‚¯
        guard authorizationStatus == .authorized else {
            throw TranscriptionError.authorizationDenied
        }
        
        // iOS Simulatorãƒã‚§ãƒƒã‚¯
        if Self.isSimulator {
            // ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ã¯éŸ³å£°èªè­˜ã‚µãƒ¼ãƒ“ã‚¹ã«åˆ¶é™ãŒã‚ã‚‹ãŸã‚ã€ãƒ¢ãƒƒã‚¯çµæœã‚’è¿”ã™
            print("ğŸ“± Running on iOS Simulator - using mock transcription")
            try await simulatorMockTranscription(audioURL: audioURL, startTime: startTime)
            return
        }
        
        // ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        guard FileManager.default.fileExists(atPath: audioURL.path) else {
            throw TranscriptionError.fileNotFound
        }
        
        do {
            // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
            let audioFileInfo = try await getAudioFileInfo(url: audioURL)
            print("ğŸµ Audio file info: duration=\(audioFileInfo.duration)s, format=\(audioFileInfo.format)")
            
            // éŸ³å£°èªè­˜ã‚¨ãƒ³ã‚¸ãƒ³ã®æº–å‚™çŠ¶æ³ã‚’ç¢ºèª
            guard let recognizer = speechRecognizer else {
                throw TranscriptionError.recognizerUnavailable
            }
            
            // éŸ³å£°èªè­˜ã‚¨ãƒ³ã‚¸ãƒ³ã®çŠ¶æ…‹ã‚’ç¢ºèª
            if !recognizer.isAvailable {
                print("âš ï¸ Speech recognizer is not available, waiting...")
                // çŸ­æ™‚é–“å¾…æ©Ÿã—ã¦ã‹ã‚‰å†è©¦è¡Œ
                try await Task.sleep(nanoseconds: 1_000_000_000) // 1ç§’å¾…æ©Ÿ
                
                if !recognizer.isAvailable {
                    throw TranscriptionError.recognizerUnavailable
                }
                print("âœ… Speech recognizer became available")
            }
            
            // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
            let recognitionRequest = SFSpeechURLRecognitionRequest(url: audioURL)
            recognitionRequest.shouldReportPartialResults = false // æœ€çµ‚çµæœã®ã¿
            recognitionRequest.taskHint = .dictation // éŸ³å£°ãƒ¡ãƒ¢ç”¨ã«æœ€é©åŒ–
            
            // éŸ³å£°èªè­˜ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹è¨­å®š
            if #available(iOS 16.0, *) {
                recognitionRequest.addsPunctuation = true
            }
            
            print("ğŸ¯ Starting speech recognition with enhanced settings")
            let result = try await performRecognition(with: recognitionRequest)
            
            let endTime = Date()
            let duration = endTime.timeIntervalSince(startTime)
            
            await MainActor.run {
                self.transcriptionText = result
                self.processingTime = duration
                self.isTranscribing = false
            }
            
            print("âœ… Transcription completed in \(String(format: "%.2f", duration))s")
            print("ğŸ“ Result: '\(result)' (\(result.count) characters)")
            
        } catch {
            let endTime = Date()
            let duration = endTime.timeIntervalSince(startTime)
            
            print("âŒ Transcription failed after \(String(format: "%.2f", duration))s: \(error)")
            
            // kAFAssistantErrorDomain Code=1101 ã‚¨ãƒ©ãƒ¼ã‚„ãã®ä»–ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
            if let nsError = error as NSError? {
                if (nsError.domain == "kAFAssistantErrorDomain" && nsError.code == 1101) ||
                   nsError.domain.contains("Speech") {
                    print("âš ï¸ Speech recognition service issue (domain: \(nsError.domain), code: \(nsError.code)) - using fallback")
                    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ¢ãƒƒã‚¯çµæœã‚’æä¾›
                    try await simulatorMockTranscription(audioURL: audioURL, startTime: startTime)
                    return
                }
            }
            
            await MainActor.run {
                self.errorMessage = error.localizedDescription
                self.isTranscribing = false
            }
            
            print("âŒ Transcription failed: \(error)")
            throw error
        }
    }
    
    /// iOS Simulatorã§ã®ãƒ¢ãƒƒã‚¯æ–‡å­—èµ·ã“ã—å‡¦ç†
    private func simulatorMockTranscription(audioURL: URL, startTime: Date) async throws {
        // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·ã•ã‚’æ¨å®šï¼ˆå®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«è§£æã¯è¡Œã‚ãªã„ï¼‰
        await MainActor.run {
            self.transcriptionText = "ã“ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã§ã™ã€‚"
        }
        
        // ãƒªã‚¢ãƒ«ãªå‡¦ç†æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆ1-3ç§’ï¼‰
        try await Task.sleep(nanoseconds: UInt64.random(in: 1_000_000_000...3_000_000_000))
        
        let endTime = Date()
        let duration = endTime.timeIntervalSince(startTime)
        
        // ãƒ•ã‚¡ã‚¤ãƒ«åã«åŸºã¥ã„ã¦ã‚ˆã‚Šå…·ä½“çš„ãªãƒ¢ãƒƒã‚¯çµæœã‚’ç”Ÿæˆ
        let fileName = audioURL.lastPathComponent
        let mockText = generateMockTranscription(for: fileName)
        
        await MainActor.run {
            self.transcriptionText = mockText
            self.processingTime = duration
            self.isTranscribing = false
        }
        
        print("âœ… Mock transcription completed in \(String(format: "%.2f", duration))s")
        print("ğŸ“ Mock result: \(mockText)")
    }
    
    /// ãƒ•ã‚¡ã‚¤ãƒ«åã«åŸºã¥ã„ã¦ãƒ¢ãƒƒã‚¯æ–‡å­—èµ·ã“ã—çµæœã‚’ç”Ÿæˆ
    private func generateMockTranscription(for fileName: String) -> String {
        let mockTexts = [
            "ã“ã‚“ã«ã¡ã¯ã€ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆç”¨ã®éŸ³å£°éŒ²éŸ³ã§ã™ã€‚ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã­ã€‚",
            "ä¼šè­°ã®å†…å®¹ã«ã¤ã„ã¦è©±ã—åˆã„ãŸã„ã¨æ€ã„ã¾ã™ã€‚ã¾ãšæœ€åˆã« agenda ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚",
            "ä»Šæ—¥ã®ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã‚’ç¢ºèªã—ã¾ã™ã€‚ç¬¬ä¸€ã«ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®é€²æ—çŠ¶æ³ã«ã¤ã„ã¦è©±ã—åˆã„ã¾ã™ã€‚",
            "éŸ³å£°èªè­˜ã®ãƒ†ã‚¹ãƒˆã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚ã“ã®æ©Ÿèƒ½ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚",
            "æ–°ã—ã„æ©Ÿèƒ½ã®é–‹ç™ºã«ã¤ã„ã¦è­°è«–ã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ã®å‘ä¸ŠãŒä¸»ãªç›®æ¨™ã§ã™ã€‚"
        ]
        
        // ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒãƒƒã‚·ãƒ¥ã«åŸºã¥ã„ã¦ä¸€è²«ã—ãŸçµæœã‚’è¿”ã™
        let index = abs(fileName.hashValue) % mockTexts.count
        return mockTexts[index]
    }
    
    /// éŸ³å£°èªè­˜ã‚’å®Ÿè¡Œï¼ˆå†…éƒ¨ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰
    private func performRecognition(with request: SFSpeechRecognitionRequest) async throws -> String {
        // Simulatorç’°å¢ƒã§ã¯çµ¶å¯¾ã«å®Ÿè¡Œã—ãªã„
        if Self.isSimulator {
            print("âš ï¸ performRecognition called on Simulator - should not happen!")
            throw TranscriptionError.recognizerUnavailable
        }
        
        return try await withThrowingTaskGroup(of: String.self) { group in
            group.addTask {
                try await withCheckedThrowingContinuation { continuation in
                    guard let recognizer = self.speechRecognizer else {
                        continuation.resume(throwing: TranscriptionError.recognizerUnavailable)
                        return
                    }
                    
                    var finalResult: String = ""
                    var hasResumed = false
                    
                    self.recognitionTask = recognizer.recognitionTask(with: request) { result, error in
                        
                        if let result = result {
                            finalResult = result.bestTranscription.formattedString
                            
                            // éƒ¨åˆ†çµæœã‚’UIã«åæ˜ ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                            DispatchQueue.main.async {
                                self.transcriptionText = finalResult
                            }
                            
                            // æœ€çµ‚çµæœã®å ´åˆ
                            if result.isFinal && !hasResumed {
                                hasResumed = true
                                continuation.resume(returning: finalResult)
                            }
                        }
                        
                        if let error = error, !hasResumed {
                            hasResumed = true
                            print("ğŸ”´ Speech recognition error: \(error)")
                            continuation.resume(throwing: error)
                        }
                    }
                    
                    // ã‚¿ã‚¹ã‚¯ãŒæ­£å¸¸ã«é–‹å§‹ã•ã‚Œãªã„å ´åˆã®æ¤œå‡º
                    DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
                        if !hasResumed && self.recognitionTask?.state == .starting {
                            print("âš ï¸ Recognition task stuck in starting state")
                        }
                    }
                }
            }
            
            // 30ç§’ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¿½åŠ 
            group.addTask {
                try await Task.sleep(nanoseconds: 30 * 1_000_000_000)
                throw TranscriptionError.timeout
            }
            
            for try await result in group {
                group.cancelAll()
                return result
            }
            
            throw TranscriptionError.recognizerUnavailable
        }
    }
    
    /// éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
    private func getAudioFileInfo(url: URL) async throws -> (duration: TimeInterval, format: String) {
        let asset = AVURLAsset(url: url)
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã®åŸºæœ¬æƒ…å ±ã‚’éåŒæœŸã§å–å¾—
        let duration = try await asset.load(.duration)
        let durationSeconds = CMTimeGetSeconds(duration)
        
        // ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼æƒ…å ±ã‚’å–å¾—
        let tracks = try await asset.loadTracks(withMediaType: .audio)
        let format = tracks.first?.naturalTimeScale.description ?? "Unknown"
        
        return (duration: durationSeconds, format: format)
    }
    
    /// å®Ÿè¡Œä¸­ã®æ–‡å­—èµ·ã“ã—ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
    func cancelTranscription() {
        recognitionTask?.cancel()
        recognitionTask = nil
        recognitionRequest = nil
        
        DispatchQueue.main.async {
            self.isTranscribing = false
        }
        
        print("â¹ï¸ Transcription cancelled")
    }
}

// MARK: - Error Types

enum TranscriptionError: LocalizedError {
    case authorizationDenied
    case recognizerUnavailable
    case fileNotFound
    case processingFailed
    case timeout
    
    var errorDescription: String? {
        switch self {
        case .authorizationDenied:
            return "éŸ³å£°èªè­˜ã®æ¨©é™ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        case .recognizerUnavailable:
            return "éŸ³å£°èªè­˜ã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
        case .fileNotFound:
            return "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        case .processingFailed:
            return "æ–‡å­—èµ·ã“ã—å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ"
        case .timeout:
            return "æ–‡å­—èµ·ã“ã—å‡¦ç†ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ"
        }
    }
}